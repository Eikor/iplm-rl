{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.8391906283280086,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0007099751508697196,
      "grad_norm": 1.3238474130630493,
      "learning_rate": 1e-08,
      "logits/chosen": 340.13543701171875,
      "logits/rejected": 340.7073974609375,
      "logps/chosen": -202.08551025390625,
      "logps/rejected": -206.22341918945312,
      "loss": 1.5705,
      "nll_loss": 0.9559416770935059,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.007099751508697196,
      "grad_norm": 1.6152925491333008,
      "learning_rate": 1.0000000000000001e-07,
      "logits/chosen": 338.60772705078125,
      "logits/rejected": 339.6987609863281,
      "logps/chosen": -178.22653198242188,
      "logps/rejected": -189.37506103515625,
      "loss": 1.992,
      "nll_loss": 0.804703414440155,
      "rewards/accuracies": 0.4097222089767456,
      "rewards/chosen": 0.004591643810272217,
      "rewards/margins": 0.2158118635416031,
      "rewards/rejected": -0.21122020483016968,
      "step": 10
    },
    {
      "epoch": 0.014199503017394392,
      "grad_norm": 1.8255435228347778,
      "learning_rate": 2.0000000000000002e-07,
      "logits/chosen": 339.6589050292969,
      "logits/rejected": 340.173828125,
      "logps/chosen": -201.53314208984375,
      "logps/rejected": -206.6122589111328,
      "loss": 2.4789,
      "nll_loss": 0.8639963269233704,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": -0.02481912449002266,
      "rewards/margins": 0.006384497974067926,
      "rewards/rejected": -0.03120361641049385,
      "step": 20
    },
    {
      "epoch": 0.021299254526091587,
      "grad_norm": 1.7981668710708618,
      "learning_rate": 3.0000000000000004e-07,
      "logits/chosen": 338.6505432128906,
      "logits/rejected": 339.36871337890625,
      "logps/chosen": -189.89341735839844,
      "logps/rejected": -186.81790161132812,
      "loss": 2.4798,
      "nll_loss": 0.870562732219696,
      "rewards/accuracies": 0.46875,
      "rewards/chosen": -0.2526920735836029,
      "rewards/margins": -0.08510597050189972,
      "rewards/rejected": -0.16758613288402557,
      "step": 30
    },
    {
      "epoch": 0.028399006034788784,
      "grad_norm": 1.8037787675857544,
      "learning_rate": 4.0000000000000003e-07,
      "logits/chosen": 340.02874755859375,
      "logits/rejected": 340.6310119628906,
      "logps/chosen": -189.51211547851562,
      "logps/rejected": -191.9576416015625,
      "loss": 2.438,
      "nll_loss": 0.9116948246955872,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.1636762171983719,
      "rewards/margins": 0.6990482211112976,
      "rewards/rejected": -0.5353720784187317,
      "step": 40
    },
    {
      "epoch": 0.03549875754348598,
      "grad_norm": 1.6790813207626343,
      "learning_rate": 5.000000000000001e-07,
      "logits/chosen": 338.54248046875,
      "logits/rejected": 339.3207702636719,
      "logps/chosen": -181.82737731933594,
      "logps/rejected": -192.5267333984375,
      "loss": 2.3567,
      "nll_loss": 0.8148854374885559,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.15099948644638062,
      "rewards/margins": 0.12818963825702667,
      "rewards/rejected": 0.022809838876128197,
      "step": 50
    },
    {
      "epoch": 0.042598509052183174,
      "grad_norm": 1.6382420063018799,
      "learning_rate": 6.000000000000001e-07,
      "logits/chosen": 337.4966735839844,
      "logits/rejected": 338.75421142578125,
      "logps/chosen": -185.32870483398438,
      "logps/rejected": -195.03067016601562,
      "loss": 2.5098,
      "nll_loss": 0.7805558443069458,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 0.00013476013555191457,
      "rewards/margins": -0.09110788255929947,
      "rewards/rejected": 0.09124263375997543,
      "step": 60
    },
    {
      "epoch": 0.04969826056088037,
      "grad_norm": 1.7439416646957397,
      "learning_rate": 7.000000000000001e-07,
      "logits/chosen": 339.9931945800781,
      "logits/rejected": 339.8520812988281,
      "logps/chosen": -193.9906463623047,
      "logps/rejected": -190.15048217773438,
      "loss": 2.3734,
      "nll_loss": 0.837800145149231,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.12028076499700546,
      "rewards/margins": 0.04704800248146057,
      "rewards/rejected": 0.07323276996612549,
      "step": 70
    },
    {
      "epoch": 0.05679801206957757,
      "grad_norm": 1.7081608772277832,
      "learning_rate": 8.000000000000001e-07,
      "logits/chosen": 338.73394775390625,
      "logits/rejected": 340.5476379394531,
      "logps/chosen": -188.64205932617188,
      "logps/rejected": -206.23892211914062,
      "loss": 2.3745,
      "nll_loss": 0.7879456877708435,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 0.08180633932352066,
      "rewards/margins": 0.18102720379829407,
      "rewards/rejected": -0.099220871925354,
      "step": 80
    },
    {
      "epoch": 0.06389776357827476,
      "grad_norm": 1.5356698036193848,
      "learning_rate": 9.000000000000001e-07,
      "logits/chosen": 339.3187561035156,
      "logits/rejected": 340.42767333984375,
      "logps/chosen": -187.0331573486328,
      "logps/rejected": -202.88040161132812,
      "loss": 2.4763,
      "nll_loss": 0.8908950686454773,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": -0.1418309360742569,
      "rewards/margins": 0.10261373221874237,
      "rewards/rejected": -0.24444468319416046,
      "step": 90
    },
    {
      "epoch": 0.07099751508697195,
      "grad_norm": 1.5595941543579102,
      "learning_rate": 1.0000000000000002e-06,
      "logits/chosen": 340.02813720703125,
      "logits/rejected": 340.59564208984375,
      "logps/chosen": -192.72055053710938,
      "logps/rejected": -202.81167602539062,
      "loss": 2.3852,
      "nll_loss": 0.8320151567459106,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 0.20893318951129913,
      "rewards/margins": 0.2433445155620575,
      "rewards/rejected": -0.03441134840250015,
      "step": 100
    },
    {
      "epoch": 0.07809726659566915,
      "grad_norm": 1.9847335815429688,
      "learning_rate": 1.1e-06,
      "logits/chosen": 337.7236022949219,
      "logits/rejected": 338.90570068359375,
      "logps/chosen": -180.41525268554688,
      "logps/rejected": -186.6021728515625,
      "loss": 2.484,
      "nll_loss": 0.7562658190727234,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -0.1885034590959549,
      "rewards/margins": -0.5845131874084473,
      "rewards/rejected": 0.3960098624229431,
      "step": 110
    },
    {
      "epoch": 0.08519701810436635,
      "grad_norm": 1.7392451763153076,
      "learning_rate": 1.2000000000000002e-06,
      "logits/chosen": 339.83660888671875,
      "logits/rejected": 340.48455810546875,
      "logps/chosen": -198.46231079101562,
      "logps/rejected": -205.1187744140625,
      "loss": 2.4975,
      "nll_loss": 0.8808525800704956,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": -0.3458765149116516,
      "rewards/margins": -0.15656891465187073,
      "rewards/rejected": -0.18930761516094208,
      "step": 120
    },
    {
      "epoch": 0.09229676961306355,
      "grad_norm": 1.8719254732131958,
      "learning_rate": 1.3e-06,
      "logits/chosen": 339.0807800292969,
      "logits/rejected": 340.27801513671875,
      "logps/chosen": -185.30490112304688,
      "logps/rejected": -195.83761596679688,
      "loss": 2.551,
      "nll_loss": 0.8434147834777832,
      "rewards/accuracies": 0.46875,
      "rewards/chosen": -0.014748346991837025,
      "rewards/margins": -0.09791596233844757,
      "rewards/rejected": 0.08316762745380402,
      "step": 130
    },
    {
      "epoch": 0.09939652112176074,
      "grad_norm": 2.4095423221588135,
      "learning_rate": 1.4000000000000001e-06,
      "logits/chosen": 337.4243469238281,
      "logits/rejected": 338.6798400878906,
      "logps/chosen": -191.10708618164062,
      "logps/rejected": -196.83157348632812,
      "loss": 2.4464,
      "nll_loss": 0.8172541856765747,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.1431962251663208,
      "rewards/margins": -0.0014548897743225098,
      "rewards/rejected": 0.1446511149406433,
      "step": 140
    },
    {
      "epoch": 0.10649627263045794,
      "grad_norm": 2.0141255855560303,
      "learning_rate": 1.5e-06,
      "logits/chosen": 339.1732177734375,
      "logits/rejected": 339.75299072265625,
      "logps/chosen": -204.63809204101562,
      "logps/rejected": -210.77578735351562,
      "loss": 2.3576,
      "nll_loss": 0.8688190579414368,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.058436375111341476,
      "rewards/margins": 0.6206287741661072,
      "rewards/rejected": -0.5621923208236694,
      "step": 150
    },
    {
      "epoch": 0.11359602413915514,
      "grad_norm": 1.8838350772857666,
      "learning_rate": 1.6000000000000001e-06,
      "logits/chosen": 339.49993896484375,
      "logits/rejected": 340.32745361328125,
      "logps/chosen": -185.9063720703125,
      "logps/rejected": -197.11795043945312,
      "loss": 2.4824,
      "nll_loss": 0.8657313585281372,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.38739290833473206,
      "rewards/margins": 0.6947816014289856,
      "rewards/rejected": -0.30738866329193115,
      "step": 160
    },
    {
      "epoch": 0.12069577564785232,
      "grad_norm": 1.8169636726379395,
      "learning_rate": 1.7000000000000002e-06,
      "logits/chosen": 340.4045715332031,
      "logits/rejected": 340.3962707519531,
      "logps/chosen": -214.55166625976562,
      "logps/rejected": -211.07559204101562,
      "loss": 2.5753,
      "nll_loss": 0.8999565839767456,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": -0.03438723832368851,
      "rewards/margins": -0.05820932984352112,
      "rewards/rejected": 0.023822104558348656,
      "step": 170
    },
    {
      "epoch": 0.12779552715654952,
      "grad_norm": 1.7652807235717773,
      "learning_rate": 1.8000000000000001e-06,
      "logits/chosen": 338.072265625,
      "logits/rejected": 338.1926574707031,
      "logps/chosen": -189.74444580078125,
      "logps/rejected": -198.989013671875,
      "loss": 2.5301,
      "nll_loss": 0.8068310022354126,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": -0.19313684105873108,
      "rewards/margins": -0.18086464703083038,
      "rewards/rejected": -0.01227219682186842,
      "step": 180
    },
    {
      "epoch": 0.13489527866524673,
      "grad_norm": 1.9069539308547974,
      "learning_rate": 1.9000000000000002e-06,
      "logits/chosen": 340.00689697265625,
      "logits/rejected": 340.06903076171875,
      "logps/chosen": -192.9817657470703,
      "logps/rejected": -195.61279296875,
      "loss": 2.435,
      "nll_loss": 0.884818434715271,
      "rewards/accuracies": 0.4625000059604645,
      "rewards/chosen": -0.24244841933250427,
      "rewards/margins": -0.2552177608013153,
      "rewards/rejected": 0.012769341468811035,
      "step": 190
    },
    {
      "epoch": 0.1419950301739439,
      "grad_norm": 2.0721077919006348,
      "learning_rate": 2.0000000000000003e-06,
      "logits/chosen": 338.5013122558594,
      "logits/rejected": 338.9306640625,
      "logps/chosen": -191.0260772705078,
      "logps/rejected": -195.60433959960938,
      "loss": 2.4748,
      "nll_loss": 0.8274983167648315,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.06286092102527618,
      "rewards/margins": 0.2847598195075989,
      "rewards/rejected": -0.34762072563171387,
      "step": 200
    },
    {
      "epoch": 0.14909478168264112,
      "grad_norm": 1.8571683168411255,
      "learning_rate": 2.1000000000000002e-06,
      "logits/chosen": 339.2579650878906,
      "logits/rejected": 340.066650390625,
      "logps/chosen": -184.5540313720703,
      "logps/rejected": -194.82630920410156,
      "loss": 2.3845,
      "nll_loss": 0.8177035450935364,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 0.4710632860660553,
      "rewards/margins": 0.4810877740383148,
      "rewards/rejected": -0.010024523362517357,
      "step": 210
    },
    {
      "epoch": 0.1561945331913383,
      "grad_norm": 2.3777964115142822,
      "learning_rate": 2.2e-06,
      "logits/chosen": 339.20306396484375,
      "logits/rejected": 340.37890625,
      "logps/chosen": -190.9158477783203,
      "logps/rejected": -197.59051513671875,
      "loss": 2.5073,
      "nll_loss": 0.8188886642456055,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.24814927577972412,
      "rewards/margins": 0.5249361395835876,
      "rewards/rejected": -0.27678683400154114,
      "step": 220
    },
    {
      "epoch": 0.16329428470003549,
      "grad_norm": 1.9534544944763184,
      "learning_rate": 2.3000000000000004e-06,
      "logits/chosen": 339.63250732421875,
      "logits/rejected": 340.0209655761719,
      "logps/chosen": -187.476318359375,
      "logps/rejected": -196.3662567138672,
      "loss": 2.3731,
      "nll_loss": 0.8115895390510559,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.09063263237476349,
      "rewards/margins": 0.39218729734420776,
      "rewards/rejected": -0.3015546500682831,
      "step": 230
    },
    {
      "epoch": 0.1703940362087327,
      "grad_norm": 2.7848520278930664,
      "learning_rate": 2.4000000000000003e-06,
      "logits/chosen": 338.1067199707031,
      "logits/rejected": 339.01934814453125,
      "logps/chosen": -178.28622436523438,
      "logps/rejected": -185.5330047607422,
      "loss": 2.5343,
      "nll_loss": 0.8019847869873047,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 0.4688454568386078,
      "rewards/margins": -0.010862219147384167,
      "rewards/rejected": 0.47970765829086304,
      "step": 240
    },
    {
      "epoch": 0.17749378771742988,
      "grad_norm": 2.3004214763641357,
      "learning_rate": 2.5e-06,
      "logits/chosen": 340.4195556640625,
      "logits/rejected": 341.70233154296875,
      "logps/chosen": -204.35145568847656,
      "logps/rejected": -212.9271697998047,
      "loss": 2.4893,
      "nll_loss": 0.8900715112686157,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 0.14615070819854736,
      "rewards/margins": -0.22138094902038574,
      "rewards/rejected": 0.3675316870212555,
      "step": 250
    },
    {
      "epoch": 0.1845935392261271,
      "grad_norm": 2.203998565673828,
      "learning_rate": 2.6e-06,
      "logits/chosen": 339.6943664550781,
      "logits/rejected": 340.8922119140625,
      "logps/chosen": -202.7097930908203,
      "logps/rejected": -205.4705352783203,
      "loss": 2.6338,
      "nll_loss": 0.8778322339057922,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -0.3348273038864136,
      "rewards/margins": -0.5427966117858887,
      "rewards/rejected": 0.20796933770179749,
      "step": 260
    },
    {
      "epoch": 0.19169329073482427,
      "grad_norm": 2.444676637649536,
      "learning_rate": 2.7000000000000004e-06,
      "logits/chosen": 338.11676025390625,
      "logits/rejected": 338.77667236328125,
      "logps/chosen": -180.27804565429688,
      "logps/rejected": -188.98452758789062,
      "loss": 2.4638,
      "nll_loss": 0.8151909708976746,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -0.15390673279762268,
      "rewards/margins": -0.12485547363758087,
      "rewards/rejected": -0.02905125543475151,
      "step": 270
    },
    {
      "epoch": 0.19879304224352148,
      "grad_norm": 2.345236301422119,
      "learning_rate": 2.8000000000000003e-06,
      "logits/chosen": 341.25238037109375,
      "logits/rejected": 341.7157897949219,
      "logps/chosen": -206.8812713623047,
      "logps/rejected": -208.06787109375,
      "loss": 2.5373,
      "nll_loss": 0.8808386921882629,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -0.18106691539287567,
      "rewards/margins": -0.16525106132030487,
      "rewards/rejected": -0.015815842896699905,
      "step": 280
    },
    {
      "epoch": 0.20589279375221867,
      "grad_norm": 2.384336471557617,
      "learning_rate": 2.9e-06,
      "logits/chosen": 339.4432067871094,
      "logits/rejected": 340.2669982910156,
      "logps/chosen": -199.83375549316406,
      "logps/rejected": -210.8101806640625,
      "loss": 2.5949,
      "nll_loss": 0.8567080497741699,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 0.13324818015098572,
      "rewards/margins": 0.2523995041847229,
      "rewards/rejected": -0.11915133893489838,
      "step": 290
    },
    {
      "epoch": 0.21299254526091588,
      "grad_norm": 2.6652345657348633,
      "learning_rate": 3e-06,
      "logits/chosen": 338.2361755371094,
      "logits/rejected": 338.37896728515625,
      "logps/chosen": -196.88870239257812,
      "logps/rejected": -200.708251953125,
      "loss": 2.6393,
      "nll_loss": 0.8630288243293762,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 0.124908946454525,
      "rewards/margins": -0.19758519530296326,
      "rewards/rejected": 0.32249414920806885,
      "step": 300
    },
    {
      "epoch": 0.22009229676961306,
      "grad_norm": 2.9024031162261963,
      "learning_rate": 3.1000000000000004e-06,
      "logits/chosen": 340.40142822265625,
      "logits/rejected": 339.79217529296875,
      "logps/chosen": -197.24801635742188,
      "logps/rejected": -190.13400268554688,
      "loss": 2.7568,
      "nll_loss": 0.8385151624679565,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.6020660400390625,
      "rewards/margins": 0.3818400204181671,
      "rewards/rejected": 0.22022601962089539,
      "step": 310
    },
    {
      "epoch": 0.22719204827831027,
      "grad_norm": 3.1120266914367676,
      "learning_rate": 3.2000000000000003e-06,
      "logits/chosen": 338.1318359375,
      "logits/rejected": 339.1023254394531,
      "logps/chosen": -188.79261779785156,
      "logps/rejected": -200.00149536132812,
      "loss": 2.7523,
      "nll_loss": 0.807671844959259,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.45749396085739136,
      "rewards/margins": 0.4199341833591461,
      "rewards/rejected": 0.03755979612469673,
      "step": 320
    },
    {
      "epoch": 0.23429179978700745,
      "grad_norm": 2.8717122077941895,
      "learning_rate": 3.3000000000000006e-06,
      "logits/chosen": 338.60546875,
      "logits/rejected": 338.4476013183594,
      "logps/chosen": -175.55259704589844,
      "logps/rejected": -184.751708984375,
      "loss": 2.6559,
      "nll_loss": 0.7961900234222412,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.4108050465583801,
      "rewards/margins": 0.36720365285873413,
      "rewards/rejected": 0.043601393699645996,
      "step": 330
    },
    {
      "epoch": 0.24139155129570464,
      "grad_norm": 3.058720827102661,
      "learning_rate": 3.4000000000000005e-06,
      "logits/chosen": 339.46905517578125,
      "logits/rejected": 339.4175720214844,
      "logps/chosen": -200.61056518554688,
      "logps/rejected": -207.07373046875,
      "loss": 2.8436,
      "nll_loss": 0.8524311780929565,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 0.33912140130996704,
      "rewards/margins": -0.5793748497962952,
      "rewards/rejected": 0.9184961318969727,
      "step": 340
    },
    {
      "epoch": 0.24849130280440185,
      "grad_norm": 3.0162012577056885,
      "learning_rate": 3.5e-06,
      "logits/chosen": 339.01959228515625,
      "logits/rejected": 339.612548828125,
      "logps/chosen": -192.42251586914062,
      "logps/rejected": -197.10617065429688,
      "loss": 2.8706,
      "nll_loss": 0.8231920003890991,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 0.7743174433708191,
      "rewards/margins": 0.8315085172653198,
      "rewards/rejected": -0.05719112232327461,
      "step": 350
    },
    {
      "epoch": 0.25559105431309903,
      "grad_norm": 3.972588539123535,
      "learning_rate": 3.6000000000000003e-06,
      "logits/chosen": 338.5516357421875,
      "logits/rejected": 339.471923828125,
      "logps/chosen": -180.5130615234375,
      "logps/rejected": -191.01809692382812,
      "loss": 2.8392,
      "nll_loss": 0.8229354619979858,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.2168076038360596,
      "rewards/margins": 0.524196982383728,
      "rewards/rejected": 0.6926105618476868,
      "step": 360
    },
    {
      "epoch": 0.2626908058217962,
      "grad_norm": 3.6199753284454346,
      "learning_rate": 3.7e-06,
      "logits/chosen": 338.3177185058594,
      "logits/rejected": 338.6867370605469,
      "logps/chosen": -194.34536743164062,
      "logps/rejected": -203.44253540039062,
      "loss": 2.8827,
      "nll_loss": 0.82256019115448,
      "rewards/accuracies": 0.4625000059604645,
      "rewards/chosen": 0.7993243932723999,
      "rewards/margins": 0.011778521351516247,
      "rewards/rejected": 0.7875458598136902,
      "step": 370
    },
    {
      "epoch": 0.26979055733049345,
      "grad_norm": 3.8385095596313477,
      "learning_rate": 3.8000000000000005e-06,
      "logits/chosen": 337.4386901855469,
      "logits/rejected": 337.6139221191406,
      "logps/chosen": -195.974853515625,
      "logps/rejected": -205.179931640625,
      "loss": 3.0966,
      "nll_loss": 0.8314449191093445,
      "rewards/accuracies": 0.4625000059604645,
      "rewards/chosen": 1.0176688432693481,
      "rewards/margins": 0.4473652243614197,
      "rewards/rejected": 0.5703036189079285,
      "step": 380
    },
    {
      "epoch": 0.27689030883919064,
      "grad_norm": 3.626697063446045,
      "learning_rate": 3.900000000000001e-06,
      "logits/chosen": 336.17584228515625,
      "logits/rejected": 336.253662109375,
      "logps/chosen": -181.14578247070312,
      "logps/rejected": -192.6756134033203,
      "loss": 2.8102,
      "nll_loss": 0.793580949306488,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.4128342866897583,
      "rewards/margins": 1.013692021369934,
      "rewards/rejected": 0.39914238452911377,
      "step": 390
    },
    {
      "epoch": 0.2839900603478878,
      "grad_norm": 4.400166034698486,
      "learning_rate": 4.000000000000001e-06,
      "logits/chosen": 337.2663879394531,
      "logits/rejected": 337.99530029296875,
      "logps/chosen": -190.14773559570312,
      "logps/rejected": -201.2169189453125,
      "loss": 3.1042,
      "nll_loss": 0.7875582575798035,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": 0.7978003621101379,
      "rewards/margins": -0.08222451061010361,
      "rewards/rejected": 0.8800249099731445,
      "step": 400
    },
    {
      "epoch": 0.291089811856585,
      "grad_norm": 5.458481788635254,
      "learning_rate": 4.1e-06,
      "logits/chosen": 338.3026428222656,
      "logits/rejected": 339.6634521484375,
      "logps/chosen": -198.3746795654297,
      "logps/rejected": -211.30322265625,
      "loss": 2.9158,
      "nll_loss": 0.8886272311210632,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.7888097763061523,
      "rewards/margins": 0.7224231958389282,
      "rewards/rejected": 0.06638650596141815,
      "step": 410
    },
    {
      "epoch": 0.29818956336528224,
      "grad_norm": 4.475565433502197,
      "learning_rate": 4.2000000000000004e-06,
      "logits/chosen": 338.27337646484375,
      "logits/rejected": 338.53216552734375,
      "logps/chosen": -187.3531951904297,
      "logps/rejected": -198.54022216796875,
      "loss": 2.9351,
      "nll_loss": 0.8742128610610962,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.9933328628540039,
      "rewards/margins": -0.29026031494140625,
      "rewards/rejected": 1.2835931777954102,
      "step": 420
    },
    {
      "epoch": 0.3052893148739794,
      "grad_norm": 4.741191864013672,
      "learning_rate": 4.3e-06,
      "logits/chosen": 337.82672119140625,
      "logits/rejected": 339.18084716796875,
      "logps/chosen": -188.5250244140625,
      "logps/rejected": -195.38888549804688,
      "loss": 2.9541,
      "nll_loss": 0.8569225072860718,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.1967573165893555,
      "rewards/margins": 0.7197655439376831,
      "rewards/rejected": 0.47699183225631714,
      "step": 430
    },
    {
      "epoch": 0.3123890663826766,
      "grad_norm": 4.712846755981445,
      "learning_rate": 4.4e-06,
      "logits/chosen": 337.10919189453125,
      "logits/rejected": 336.9828796386719,
      "logps/chosen": -195.07774353027344,
      "logps/rejected": -201.50283813476562,
      "loss": 2.8449,
      "nll_loss": 0.8474432826042175,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 1.3376046419143677,
      "rewards/margins": 1.147348165512085,
      "rewards/rejected": 0.19025638699531555,
      "step": 440
    },
    {
      "epoch": 0.3194888178913738,
      "grad_norm": 3.974510431289673,
      "learning_rate": 4.5e-06,
      "logits/chosen": 337.55108642578125,
      "logits/rejected": 338.2608947753906,
      "logps/chosen": -201.52572631835938,
      "logps/rejected": -203.74606323242188,
      "loss": 2.9594,
      "nll_loss": 0.8473676443099976,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 1.3781681060791016,
      "rewards/margins": 0.9811832308769226,
      "rewards/rejected": 0.39698487520217896,
      "step": 450
    },
    {
      "epoch": 0.32658856940007097,
      "grad_norm": 4.97161340713501,
      "learning_rate": 4.600000000000001e-06,
      "logits/chosen": 338.0399475097656,
      "logits/rejected": 338.2320861816406,
      "logps/chosen": -204.46554565429688,
      "logps/rejected": -205.2917938232422,
      "loss": 2.9414,
      "nll_loss": 0.8488958477973938,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 0.9449862241744995,
      "rewards/margins": -0.038729678839445114,
      "rewards/rejected": 0.983715832233429,
      "step": 460
    },
    {
      "epoch": 0.3336883209087682,
      "grad_norm": 4.2380571365356445,
      "learning_rate": 4.7e-06,
      "logits/chosen": 338.1777648925781,
      "logits/rejected": 338.92156982421875,
      "logps/chosen": -188.89328002929688,
      "logps/rejected": -193.2984161376953,
      "loss": 3.0007,
      "nll_loss": 0.8657150268554688,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.0218976736068726,
      "rewards/margins": 0.21740217506885529,
      "rewards/rejected": 0.804495632648468,
      "step": 470
    },
    {
      "epoch": 0.3407880724174654,
      "grad_norm": 4.407166957855225,
      "learning_rate": 4.800000000000001e-06,
      "logits/chosen": 338.19781494140625,
      "logits/rejected": 337.4256896972656,
      "logps/chosen": -196.0521240234375,
      "logps/rejected": -201.76046752929688,
      "loss": 2.9262,
      "nll_loss": 0.8520196080207825,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.169984221458435,
      "rewards/margins": 0.5099948048591614,
      "rewards/rejected": 0.6599894165992737,
      "step": 480
    },
    {
      "epoch": 0.3478878239261626,
      "grad_norm": 3.875429630279541,
      "learning_rate": 4.9000000000000005e-06,
      "logits/chosen": 336.45330810546875,
      "logits/rejected": 336.63372802734375,
      "logps/chosen": -193.95693969726562,
      "logps/rejected": -203.78262329101562,
      "loss": 2.8604,
      "nll_loss": 0.7909938097000122,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.3241920471191406,
      "rewards/margins": 0.4669254422187805,
      "rewards/rejected": 0.8572665452957153,
      "step": 490
    },
    {
      "epoch": 0.35498757543485976,
      "grad_norm": 4.165746212005615,
      "learning_rate": 5e-06,
      "logits/chosen": 338.1818542480469,
      "logits/rejected": 339.3546142578125,
      "logps/chosen": -200.84486389160156,
      "logps/rejected": -210.6057586669922,
      "loss": 2.9182,
      "nll_loss": 0.8997402191162109,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.3732285499572754,
      "rewards/margins": 0.29979178309440613,
      "rewards/rejected": 1.0734367370605469,
      "step": 500
    },
    {
      "epoch": 0.362087326943557,
      "grad_norm": 4.596170425415039,
      "learning_rate": 5.1e-06,
      "logits/chosen": 337.04400634765625,
      "logits/rejected": 338.2396545410156,
      "logps/chosen": -185.6189727783203,
      "logps/rejected": -205.67489624023438,
      "loss": 2.7709,
      "nll_loss": 0.8458759188652039,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 1.509199619293213,
      "rewards/margins": 1.224475383758545,
      "rewards/rejected": 0.28472432494163513,
      "step": 510
    },
    {
      "epoch": 0.3691870784522542,
      "grad_norm": 4.111680507659912,
      "learning_rate": 5.2e-06,
      "logits/chosen": 338.2658996582031,
      "logits/rejected": 338.83056640625,
      "logps/chosen": -190.34902954101562,
      "logps/rejected": -197.77197265625,
      "loss": 2.8809,
      "nll_loss": 0.8379777669906616,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 0.9973095059394836,
      "rewards/margins": 0.12852880358695984,
      "rewards/rejected": 0.868780791759491,
      "step": 520
    },
    {
      "epoch": 0.37628682996095136,
      "grad_norm": 4.215987205505371,
      "learning_rate": 5.300000000000001e-06,
      "logits/chosen": 338.1058044433594,
      "logits/rejected": 338.61370849609375,
      "logps/chosen": -196.2153778076172,
      "logps/rejected": -199.5200653076172,
      "loss": 3.0258,
      "nll_loss": 0.8539320826530457,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.1691434383392334,
      "rewards/margins": 0.2572168707847595,
      "rewards/rejected": 0.9119264483451843,
      "step": 530
    },
    {
      "epoch": 0.38338658146964855,
      "grad_norm": 4.371106147766113,
      "learning_rate": 5.400000000000001e-06,
      "logits/chosen": 335.11517333984375,
      "logits/rejected": 336.4100341796875,
      "logps/chosen": -181.97877502441406,
      "logps/rejected": -196.4906005859375,
      "loss": 2.9474,
      "nll_loss": 0.7880091667175293,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.8228098154067993,
      "rewards/margins": 0.8135138750076294,
      "rewards/rejected": 1.0092958211898804,
      "step": 540
    },
    {
      "epoch": 0.3904863329783458,
      "grad_norm": 4.402061462402344,
      "learning_rate": 5.500000000000001e-06,
      "logits/chosen": 336.99468994140625,
      "logits/rejected": 337.1065979003906,
      "logps/chosen": -178.82943725585938,
      "logps/rejected": -187.31759643554688,
      "loss": 2.7815,
      "nll_loss": 0.7496986985206604,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.5442659854888916,
      "rewards/margins": 0.8800584673881531,
      "rewards/rejected": 0.6642075777053833,
      "step": 550
    },
    {
      "epoch": 0.39758608448704297,
      "grad_norm": 4.596703052520752,
      "learning_rate": 5.600000000000001e-06,
      "logits/chosen": 336.48101806640625,
      "logits/rejected": 336.59527587890625,
      "logps/chosen": -181.79505920410156,
      "logps/rejected": -187.70413208007812,
      "loss": 2.8425,
      "nll_loss": 0.8008502721786499,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.1397453546524048,
      "rewards/margins": 0.5098705887794495,
      "rewards/rejected": 0.6298746466636658,
      "step": 560
    },
    {
      "epoch": 0.40468583599574015,
      "grad_norm": 4.713412761688232,
      "learning_rate": 5.7e-06,
      "logits/chosen": 336.55621337890625,
      "logits/rejected": 337.90789794921875,
      "logps/chosen": -189.966064453125,
      "logps/rejected": -200.4188232421875,
      "loss": 2.9511,
      "nll_loss": 0.8129614591598511,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.2100629806518555,
      "rewards/margins": 0.0258087869733572,
      "rewards/rejected": 1.1842541694641113,
      "step": 570
    },
    {
      "epoch": 0.41178558750443733,
      "grad_norm": 4.450455188751221,
      "learning_rate": 5.8e-06,
      "logits/chosen": 337.7146301269531,
      "logits/rejected": 337.96148681640625,
      "logps/chosen": -201.57431030273438,
      "logps/rejected": -210.4578094482422,
      "loss": 2.8247,
      "nll_loss": 0.857318103313446,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.332401990890503,
      "rewards/margins": 0.41712188720703125,
      "rewards/rejected": 0.9152801632881165,
      "step": 580
    },
    {
      "epoch": 0.4188853390131345,
      "grad_norm": 6.20656156539917,
      "learning_rate": 5.9e-06,
      "logits/chosen": 336.1466064453125,
      "logits/rejected": 337.4126281738281,
      "logps/chosen": -197.28335571289062,
      "logps/rejected": -214.544189453125,
      "loss": 2.874,
      "nll_loss": 0.7998654842376709,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.3085293769836426,
      "rewards/margins": 0.9256702661514282,
      "rewards/rejected": 0.38285908102989197,
      "step": 590
    },
    {
      "epoch": 0.42598509052183176,
      "grad_norm": 4.674094200134277,
      "learning_rate": 6e-06,
      "logits/chosen": 337.821044921875,
      "logits/rejected": 336.6459045410156,
      "logps/chosen": -185.22933959960938,
      "logps/rejected": -187.6697998046875,
      "loss": 2.9522,
      "nll_loss": 0.8372478485107422,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 0.9417027235031128,
      "rewards/margins": 0.4180382788181305,
      "rewards/rejected": 0.5236644744873047,
      "step": 600
    },
    {
      "epoch": 0.43308484203052894,
      "grad_norm": 4.49171781539917,
      "learning_rate": 6.1e-06,
      "logits/chosen": 335.5630798339844,
      "logits/rejected": 336.49554443359375,
      "logps/chosen": -180.25210571289062,
      "logps/rejected": -191.89859008789062,
      "loss": 2.7902,
      "nll_loss": 0.8123408555984497,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.7839109897613525,
      "rewards/margins": 0.9489609599113464,
      "rewards/rejected": 0.8349498510360718,
      "step": 610
    },
    {
      "epoch": 0.4401845935392261,
      "grad_norm": 6.579679012298584,
      "learning_rate": 6.200000000000001e-06,
      "logits/chosen": 338.2999572753906,
      "logits/rejected": 339.7723388671875,
      "logps/chosen": -198.20404052734375,
      "logps/rejected": -204.17251586914062,
      "loss": 2.9287,
      "nll_loss": 0.9061139822006226,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.6507059335708618,
      "rewards/margins": -0.22203746438026428,
      "rewards/rejected": 0.8727434277534485,
      "step": 620
    },
    {
      "epoch": 0.4472843450479233,
      "grad_norm": 5.320703029632568,
      "learning_rate": 6.300000000000001e-06,
      "logits/chosen": 338.41229248046875,
      "logits/rejected": 339.3296203613281,
      "logps/chosen": -183.27244567871094,
      "logps/rejected": -195.04608154296875,
      "loss": 2.83,
      "nll_loss": 0.8235902786254883,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": 0.32117828726768494,
      "rewards/margins": -0.5906069874763489,
      "rewards/rejected": 0.9117852449417114,
      "step": 630
    },
    {
      "epoch": 0.45438409655662054,
      "grad_norm": 5.038029193878174,
      "learning_rate": 6.4000000000000006e-06,
      "logits/chosen": 337.2144775390625,
      "logits/rejected": 338.5590515136719,
      "logps/chosen": -190.6703338623047,
      "logps/rejected": -200.31411743164062,
      "loss": 2.9421,
      "nll_loss": 0.8079932928085327,
      "rewards/accuracies": 0.45625001192092896,
      "rewards/chosen": 0.6310380697250366,
      "rewards/margins": -0.056106291711330414,
      "rewards/rejected": 0.6871442794799805,
      "step": 640
    },
    {
      "epoch": 0.4614838480653177,
      "grad_norm": 4.213029384613037,
      "learning_rate": 6.5000000000000004e-06,
      "logits/chosen": 337.4275207519531,
      "logits/rejected": 338.7562561035156,
      "logps/chosen": -181.26646423339844,
      "logps/rejected": -191.73056030273438,
      "loss": 2.8568,
      "nll_loss": 0.7991979718208313,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.153973937034607,
      "rewards/margins": 0.950560450553894,
      "rewards/rejected": 0.20341363549232483,
      "step": 650
    },
    {
      "epoch": 0.4685835995740149,
      "grad_norm": 4.11649751663208,
      "learning_rate": 6.600000000000001e-06,
      "logits/chosen": 339.41888427734375,
      "logits/rejected": 340.84564208984375,
      "logps/chosen": -185.62069702148438,
      "logps/rejected": -188.51681518554688,
      "loss": 2.679,
      "nll_loss": 0.8751899003982544,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.5595095753669739,
      "rewards/margins": 0.45818716287612915,
      "rewards/rejected": 0.10132239758968353,
      "step": 660
    },
    {
      "epoch": 0.4756833510827121,
      "grad_norm": 5.5565314292907715,
      "learning_rate": 6.700000000000001e-06,
      "logits/chosen": 338.0726013183594,
      "logits/rejected": 338.42669677734375,
      "logps/chosen": -177.3237762451172,
      "logps/rejected": -189.39450073242188,
      "loss": 2.7845,
      "nll_loss": 0.7679818868637085,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 0.920207679271698,
      "rewards/margins": 0.6840817332267761,
      "rewards/rejected": 0.2361259013414383,
      "step": 670
    },
    {
      "epoch": 0.4827831025914093,
      "grad_norm": 4.736187934875488,
      "learning_rate": 6.800000000000001e-06,
      "logits/chosen": 336.68328857421875,
      "logits/rejected": 337.8475036621094,
      "logps/chosen": -186.93447875976562,
      "logps/rejected": -192.233642578125,
      "loss": 2.9644,
      "nll_loss": 0.8056257367134094,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.39637359976768494,
      "rewards/margins": 0.419231116771698,
      "rewards/rejected": -0.022857511416077614,
      "step": 680
    },
    {
      "epoch": 0.4898828541001065,
      "grad_norm": 4.333308696746826,
      "learning_rate": 6.9e-06,
      "logits/chosen": 338.48150634765625,
      "logits/rejected": 338.95928955078125,
      "logps/chosen": -190.16104125976562,
      "logps/rejected": -192.56466674804688,
      "loss": 2.9585,
      "nll_loss": 0.869432806968689,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 0.9233593940734863,
      "rewards/margins": -0.04375356435775757,
      "rewards/rejected": 0.9671128988265991,
      "step": 690
    },
    {
      "epoch": 0.4969826056088037,
      "grad_norm": 5.101160526275635,
      "learning_rate": 7e-06,
      "logits/chosen": 337.3883972167969,
      "logits/rejected": 338.4773254394531,
      "logps/chosen": -194.49156188964844,
      "logps/rejected": -197.68637084960938,
      "loss": 2.9897,
      "nll_loss": 0.8177469968795776,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.7406405210494995,
      "rewards/margins": 0.023840874433517456,
      "rewards/rejected": 0.7167997360229492,
      "step": 700
    },
    {
      "epoch": 0.5040823571175009,
      "grad_norm": 4.929600715637207,
      "learning_rate": 7.100000000000001e-06,
      "logits/chosen": 339.3281555175781,
      "logits/rejected": 339.802490234375,
      "logps/chosen": -197.8757781982422,
      "logps/rejected": -204.648681640625,
      "loss": 2.9231,
      "nll_loss": 0.8773030042648315,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 0.8446496725082397,
      "rewards/margins": 0.4880269467830658,
      "rewards/rejected": 0.3566226065158844,
      "step": 710
    },
    {
      "epoch": 0.5111821086261981,
      "grad_norm": 4.569047451019287,
      "learning_rate": 7.2000000000000005e-06,
      "logits/chosen": 337.88726806640625,
      "logits/rejected": 338.5638732910156,
      "logps/chosen": -196.8194580078125,
      "logps/rejected": -197.83935546875,
      "loss": 3.0085,
      "nll_loss": 0.8333257436752319,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 0.7933591604232788,
      "rewards/margins": 0.014911520294845104,
      "rewards/rejected": 0.7784477472305298,
      "step": 720
    },
    {
      "epoch": 0.5182818601348953,
      "grad_norm": 3.8565356731414795,
      "learning_rate": 7.3e-06,
      "logits/chosen": 339.55194091796875,
      "logits/rejected": 340.6100158691406,
      "logps/chosen": -184.0364990234375,
      "logps/rejected": -191.9780731201172,
      "loss": 2.8224,
      "nll_loss": 0.8501542806625366,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.4870914220809937,
      "rewards/margins": 1.0693811178207397,
      "rewards/rejected": 0.4177103638648987,
      "step": 730
    },
    {
      "epoch": 0.5253816116435924,
      "grad_norm": 4.432656764984131,
      "learning_rate": 7.4e-06,
      "logits/chosen": 338.963623046875,
      "logits/rejected": 339.7579345703125,
      "logps/chosen": -205.9942626953125,
      "logps/rejected": -213.95425415039062,
      "loss": 2.8997,
      "nll_loss": 0.873369038105011,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.733289361000061,
      "rewards/margins": 0.5025690793991089,
      "rewards/rejected": 0.23072020709514618,
      "step": 740
    },
    {
      "epoch": 0.5324813631522897,
      "grad_norm": 5.470387935638428,
      "learning_rate": 7.500000000000001e-06,
      "logits/chosen": 339.11309814453125,
      "logits/rejected": 339.48876953125,
      "logps/chosen": -206.91943359375,
      "logps/rejected": -205.74169921875,
      "loss": 3.0091,
      "nll_loss": 0.8578422665596008,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 0.24513134360313416,
      "rewards/margins": 0.054183054715394974,
      "rewards/rejected": 0.1909482777118683,
      "step": 750
    },
    {
      "epoch": 0.5395811146609869,
      "grad_norm": 5.169703960418701,
      "learning_rate": 7.600000000000001e-06,
      "logits/chosen": 337.08245849609375,
      "logits/rejected": 338.59417724609375,
      "logps/chosen": -186.72250366210938,
      "logps/rejected": -193.95118713378906,
      "loss": 2.9082,
      "nll_loss": 0.8809435963630676,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.2332065105438232,
      "rewards/margins": 0.6542103886604309,
      "rewards/rejected": 0.5789960622787476,
      "step": 760
    },
    {
      "epoch": 0.546680866169684,
      "grad_norm": 5.307666778564453,
      "learning_rate": 7.7e-06,
      "logits/chosen": 338.69219970703125,
      "logits/rejected": 339.6082458496094,
      "logps/chosen": -187.89369201660156,
      "logps/rejected": -193.70919799804688,
      "loss": 2.8798,
      "nll_loss": 0.8604322671890259,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 0.8713840246200562,
      "rewards/margins": 0.16839055716991425,
      "rewards/rejected": 0.7029935121536255,
      "step": 770
    },
    {
      "epoch": 0.5537806176783813,
      "grad_norm": 4.655934810638428,
      "learning_rate": 7.800000000000002e-06,
      "logits/chosen": 336.73895263671875,
      "logits/rejected": 338.0452880859375,
      "logps/chosen": -193.22341918945312,
      "logps/rejected": -197.3422393798828,
      "loss": 2.8764,
      "nll_loss": 0.8108530044555664,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 1.2647805213928223,
      "rewards/margins": 0.0008935689693316817,
      "rewards/rejected": 1.2638870477676392,
      "step": 780
    },
    {
      "epoch": 0.5608803691870784,
      "grad_norm": 4.5469970703125,
      "learning_rate": 7.9e-06,
      "logits/chosen": 334.71002197265625,
      "logits/rejected": 335.398193359375,
      "logps/chosen": -194.54273986816406,
      "logps/rejected": -199.7803497314453,
      "loss": 2.8373,
      "nll_loss": 0.7664003968238831,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.1567351818084717,
      "rewards/margins": 0.4853329658508301,
      "rewards/rejected": 0.671402096748352,
      "step": 790
    },
    {
      "epoch": 0.5679801206957756,
      "grad_norm": 4.620859146118164,
      "learning_rate": 8.000000000000001e-06,
      "logits/chosen": 338.8424072265625,
      "logits/rejected": 339.1756896972656,
      "logps/chosen": -198.51791381835938,
      "logps/rejected": -202.16390991210938,
      "loss": 2.8361,
      "nll_loss": 0.9403940439224243,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": 0.2916225492954254,
      "rewards/margins": -0.21542127430438995,
      "rewards/rejected": 0.507043719291687,
      "step": 800
    },
    {
      "epoch": 0.5750798722044729,
      "grad_norm": 5.236166954040527,
      "learning_rate": 8.1e-06,
      "logits/chosen": 337.18011474609375,
      "logits/rejected": 338.1773376464844,
      "logps/chosen": -184.51449584960938,
      "logps/rejected": -191.29165649414062,
      "loss": 2.9063,
      "nll_loss": 0.8505734205245972,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.8931310772895813,
      "rewards/margins": 0.17519274353981018,
      "rewards/rejected": 0.717938244342804,
      "step": 810
    },
    {
      "epoch": 0.58217962371317,
      "grad_norm": 4.512578964233398,
      "learning_rate": 8.2e-06,
      "logits/chosen": 335.43341064453125,
      "logits/rejected": 336.02362060546875,
      "logps/chosen": -178.31753540039062,
      "logps/rejected": -183.866455078125,
      "loss": 3.1629,
      "nll_loss": 0.8123858571052551,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.4334063529968262,
      "rewards/margins": 0.0276238564401865,
      "rewards/rejected": 1.4057825803756714,
      "step": 820
    },
    {
      "epoch": 0.5892793752218672,
      "grad_norm": 5.381501197814941,
      "learning_rate": 8.3e-06,
      "logits/chosen": 336.73602294921875,
      "logits/rejected": 338.28228759765625,
      "logps/chosen": -199.15151977539062,
      "logps/rejected": -211.489501953125,
      "loss": 2.9793,
      "nll_loss": 0.8984100222587585,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.7784751057624817,
      "rewards/margins": 0.7949172854423523,
      "rewards/rejected": -0.016442203894257545,
      "step": 830
    },
    {
      "epoch": 0.5963791267305645,
      "grad_norm": 4.789608001708984,
      "learning_rate": 8.400000000000001e-06,
      "logits/chosen": 336.501220703125,
      "logits/rejected": 336.9692687988281,
      "logps/chosen": -184.4305877685547,
      "logps/rejected": -195.4596405029297,
      "loss": 2.8988,
      "nll_loss": 0.8748941421508789,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.0838696956634521,
      "rewards/margins": 0.8998770713806152,
      "rewards/rejected": 0.1839926540851593,
      "step": 840
    },
    {
      "epoch": 0.6034788782392616,
      "grad_norm": 4.8750176429748535,
      "learning_rate": 8.5e-06,
      "logits/chosen": 337.12921142578125,
      "logits/rejected": 338.1341552734375,
      "logps/chosen": -197.13668823242188,
      "logps/rejected": -208.08767700195312,
      "loss": 2.8587,
      "nll_loss": 0.8345314860343933,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.3294661045074463,
      "rewards/margins": 0.42576760053634644,
      "rewards/rejected": 0.9036985635757446,
      "step": 850
    },
    {
      "epoch": 0.6105786297479588,
      "grad_norm": 4.873546600341797,
      "learning_rate": 8.6e-06,
      "logits/chosen": 336.4296875,
      "logits/rejected": 336.7078552246094,
      "logps/chosen": -193.68728637695312,
      "logps/rejected": -207.7475128173828,
      "loss": 2.9184,
      "nll_loss": 0.8390801548957825,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.1028211116790771,
      "rewards/margins": 0.483977735042572,
      "rewards/rejected": 0.6188432574272156,
      "step": 860
    },
    {
      "epoch": 0.617678381256656,
      "grad_norm": 4.823185443878174,
      "learning_rate": 8.700000000000001e-06,
      "logits/chosen": 337.93878173828125,
      "logits/rejected": 338.4663391113281,
      "logps/chosen": -195.48263549804688,
      "logps/rejected": -208.7892303466797,
      "loss": 2.8836,
      "nll_loss": 0.8418054580688477,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.1670186519622803,
      "rewards/margins": 0.4440228343009949,
      "rewards/rejected": 0.7229957580566406,
      "step": 870
    },
    {
      "epoch": 0.6247781327653532,
      "grad_norm": 5.120813369750977,
      "learning_rate": 8.8e-06,
      "logits/chosen": 338.4606628417969,
      "logits/rejected": 338.75335693359375,
      "logps/chosen": -191.5253448486328,
      "logps/rejected": -201.1088104248047,
      "loss": 2.754,
      "nll_loss": 0.8938019871711731,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 1.330195665359497,
      "rewards/margins": 0.28730395436286926,
      "rewards/rejected": 1.0428917407989502,
      "step": 880
    },
    {
      "epoch": 0.6318778842740504,
      "grad_norm": 5.075727462768555,
      "learning_rate": 8.900000000000001e-06,
      "logits/chosen": 335.46807861328125,
      "logits/rejected": 335.74273681640625,
      "logps/chosen": -197.14613342285156,
      "logps/rejected": -201.73294067382812,
      "loss": 2.9006,
      "nll_loss": 0.8384187817573547,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.1504733562469482,
      "rewards/margins": 0.46664389967918396,
      "rewards/rejected": 0.6838296055793762,
      "step": 890
    },
    {
      "epoch": 0.6389776357827476,
      "grad_norm": 5.3298749923706055,
      "learning_rate": 9e-06,
      "logits/chosen": 335.8448181152344,
      "logits/rejected": 336.8697814941406,
      "logps/chosen": -184.31283569335938,
      "logps/rejected": -196.31256103515625,
      "loss": 2.9498,
      "nll_loss": 0.7859322428703308,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.7349170446395874,
      "rewards/margins": 0.7969421148300171,
      "rewards/rejected": 0.9379751086235046,
      "step": 900
    },
    {
      "epoch": 0.6460773872914448,
      "grad_norm": 4.777324676513672,
      "learning_rate": 9.100000000000001e-06,
      "logits/chosen": 336.6230773925781,
      "logits/rejected": 338.42303466796875,
      "logps/chosen": -184.7257080078125,
      "logps/rejected": -192.90110778808594,
      "loss": 2.7819,
      "nll_loss": 0.8363262414932251,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": 0.7555071115493774,
      "rewards/margins": -0.26825419068336487,
      "rewards/rejected": 1.02376127243042,
      "step": 910
    },
    {
      "epoch": 0.6531771388001419,
      "grad_norm": 5.102710723876953,
      "learning_rate": 9.200000000000002e-06,
      "logits/chosen": 336.35650634765625,
      "logits/rejected": 337.6487731933594,
      "logps/chosen": -191.270263671875,
      "logps/rejected": -201.2938995361328,
      "loss": 2.9637,
      "nll_loss": 0.8326032757759094,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 1.0011087656021118,
      "rewards/margins": 0.45158615708351135,
      "rewards/rejected": 0.5495225787162781,
      "step": 920
    },
    {
      "epoch": 0.6602768903088392,
      "grad_norm": 5.442827224731445,
      "learning_rate": 9.3e-06,
      "logits/chosen": 336.6328430175781,
      "logits/rejected": 338.8896484375,
      "logps/chosen": -200.80007934570312,
      "logps/rejected": -209.66543579101562,
      "loss": 3.0046,
      "nll_loss": 0.8411393165588379,
      "rewards/accuracies": 0.46875,
      "rewards/chosen": 1.145575761795044,
      "rewards/margins": 0.29240402579307556,
      "rewards/rejected": 0.8531715273857117,
      "step": 930
    },
    {
      "epoch": 0.6673766418175364,
      "grad_norm": 4.731616973876953,
      "learning_rate": 9.4e-06,
      "logits/chosen": 337.1300048828125,
      "logits/rejected": 337.644287109375,
      "logps/chosen": -199.14151000976562,
      "logps/rejected": -216.6233673095703,
      "loss": 2.9649,
      "nll_loss": 0.8358514904975891,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 1.7141506671905518,
      "rewards/margins": 1.1784942150115967,
      "rewards/rejected": 0.5356563329696655,
      "step": 940
    },
    {
      "epoch": 0.6744763933262335,
      "grad_norm": 5.074743270874023,
      "learning_rate": 9.5e-06,
      "logits/chosen": 337.0983581542969,
      "logits/rejected": 337.57208251953125,
      "logps/chosen": -191.43011474609375,
      "logps/rejected": -200.0409698486328,
      "loss": 2.8339,
      "nll_loss": 0.7758280038833618,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.8651237487792969,
      "rewards/margins": 1.296175241470337,
      "rewards/rejected": 0.5689484477043152,
      "step": 950
    },
    {
      "epoch": 0.6815761448349308,
      "grad_norm": 5.356409072875977,
      "learning_rate": 9.600000000000001e-06,
      "logits/chosen": 335.6034851074219,
      "logits/rejected": 337.0556640625,
      "logps/chosen": -198.62545776367188,
      "logps/rejected": -207.1045379638672,
      "loss": 2.7714,
      "nll_loss": 0.8144248723983765,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.4750840663909912,
      "rewards/margins": 1.01213800907135,
      "rewards/rejected": 0.4629460275173187,
      "step": 960
    },
    {
      "epoch": 0.688675896343628,
      "grad_norm": 6.624457359313965,
      "learning_rate": 9.7e-06,
      "logits/chosen": 336.1517639160156,
      "logits/rejected": 336.68975830078125,
      "logps/chosen": -175.8153839111328,
      "logps/rejected": -180.172119140625,
      "loss": 2.9135,
      "nll_loss": 0.8158800005912781,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 0.7216514945030212,
      "rewards/margins": 0.34841886162757874,
      "rewards/rejected": 0.3732326030731201,
      "step": 970
    },
    {
      "epoch": 0.6957756478523252,
      "grad_norm": 5.674862384796143,
      "learning_rate": 9.800000000000001e-06,
      "logits/chosen": 336.23443603515625,
      "logits/rejected": 337.59259033203125,
      "logps/chosen": -184.2375946044922,
      "logps/rejected": -192.39649963378906,
      "loss": 2.7555,
      "nll_loss": 0.8090079426765442,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.3499858379364014,
      "rewards/margins": 1.60285222530365,
      "rewards/rejected": -0.2528662085533142,
      "step": 980
    },
    {
      "epoch": 0.7028753993610224,
      "grad_norm": 5.152024269104004,
      "learning_rate": 9.9e-06,
      "logits/chosen": 336.7443542480469,
      "logits/rejected": 337.382568359375,
      "logps/chosen": -184.3607635498047,
      "logps/rejected": -198.18124389648438,
      "loss": 2.9943,
      "nll_loss": 0.7875118255615234,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.6546207666397095,
      "rewards/margins": 0.7524873614311218,
      "rewards/rejected": 0.9021332859992981,
      "step": 990
    },
    {
      "epoch": 0.7099751508697195,
      "grad_norm": 4.65666389465332,
      "learning_rate": 1e-05,
      "logits/chosen": 337.03106689453125,
      "logits/rejected": 337.9044189453125,
      "logps/chosen": -169.42031860351562,
      "logps/rejected": -185.41268920898438,
      "loss": 2.9282,
      "nll_loss": 0.8016290664672852,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.029031753540039,
      "rewards/margins": 0.409898579120636,
      "rewards/rejected": 0.6191331744194031,
      "step": 1000
    },
    {
      "epoch": 0.7170749023784168,
      "grad_norm": 5.034586429595947,
      "learning_rate": 9.975000000000002e-06,
      "logits/chosen": 337.70355224609375,
      "logits/rejected": 339.0611267089844,
      "logps/chosen": -183.19647216796875,
      "logps/rejected": -195.38092041015625,
      "loss": 3.0322,
      "nll_loss": 0.7661064267158508,
      "rewards/accuracies": 0.41874998807907104,
      "rewards/chosen": 0.4295019507408142,
      "rewards/margins": -0.4974845051765442,
      "rewards/rejected": 0.9269865155220032,
      "step": 1010
    },
    {
      "epoch": 0.724174653887114,
      "grad_norm": 5.245494842529297,
      "learning_rate": 9.950000000000001e-06,
      "logits/chosen": 337.80230712890625,
      "logits/rejected": 339.41973876953125,
      "logps/chosen": -199.5679168701172,
      "logps/rejected": -213.97860717773438,
      "loss": 2.8514,
      "nll_loss": 0.864190399646759,
      "rewards/accuracies": 0.6312500238418579,
      "rewards/chosen": 1.2617213726043701,
      "rewards/margins": 1.5406811237335205,
      "rewards/rejected": -0.27895960211753845,
      "step": 1020
    },
    {
      "epoch": 0.7312744053958111,
      "grad_norm": 4.569324493408203,
      "learning_rate": 9.925e-06,
      "logits/chosen": 338.73626708984375,
      "logits/rejected": 339.8829040527344,
      "logps/chosen": -187.8116455078125,
      "logps/rejected": -200.0115966796875,
      "loss": 2.8838,
      "nll_loss": 0.8566773533821106,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 1.2017812728881836,
      "rewards/margins": 0.4713052809238434,
      "rewards/rejected": 0.7304760217666626,
      "step": 1030
    },
    {
      "epoch": 0.7383741569045084,
      "grad_norm": 6.05963659286499,
      "learning_rate": 9.9e-06,
      "logits/chosen": 337.2255554199219,
      "logits/rejected": 337.51605224609375,
      "logps/chosen": -174.84414672851562,
      "logps/rejected": -182.0305633544922,
      "loss": 2.8561,
      "nll_loss": 0.7981030344963074,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": 1.8708560466766357,
      "rewards/margins": 1.365530252456665,
      "rewards/rejected": 0.5053259134292603,
      "step": 1040
    },
    {
      "epoch": 0.7454739084132055,
      "grad_norm": 5.331493854522705,
      "learning_rate": 9.875000000000001e-06,
      "logits/chosen": 338.0371398925781,
      "logits/rejected": 338.2874450683594,
      "logps/chosen": -186.85012817382812,
      "logps/rejected": -195.8101348876953,
      "loss": 3.0612,
      "nll_loss": 0.7898029088973999,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.668478012084961,
      "rewards/margins": 1.0012848377227783,
      "rewards/rejected": 0.6671932339668274,
      "step": 1050
    },
    {
      "epoch": 0.7525736599219027,
      "grad_norm": 5.226905345916748,
      "learning_rate": 9.85e-06,
      "logits/chosen": 336.49237060546875,
      "logits/rejected": 337.60687255859375,
      "logps/chosen": -186.89822387695312,
      "logps/rejected": -195.7739715576172,
      "loss": 2.9707,
      "nll_loss": 0.7740370035171509,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 1.832018256187439,
      "rewards/margins": 0.8091225624084473,
      "rewards/rejected": 1.0228958129882812,
      "step": 1060
    },
    {
      "epoch": 0.7596734114306,
      "grad_norm": 5.137454509735107,
      "learning_rate": 9.825000000000002e-06,
      "logits/chosen": 340.79376220703125,
      "logits/rejected": 341.54425048828125,
      "logps/chosen": -196.5230712890625,
      "logps/rejected": -206.0001220703125,
      "loss": 2.8912,
      "nll_loss": 0.8802235722541809,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.9445627927780151,
      "rewards/margins": 1.0225471258163452,
      "rewards/rejected": -0.0779842957854271,
      "step": 1070
    },
    {
      "epoch": 0.7667731629392971,
      "grad_norm": 5.8447794914245605,
      "learning_rate": 9.800000000000001e-06,
      "logits/chosen": 339.60198974609375,
      "logits/rejected": 339.02978515625,
      "logps/chosen": -187.6977081298828,
      "logps/rejected": -192.91123962402344,
      "loss": 3.0973,
      "nll_loss": 0.8371576070785522,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.3539330959320068,
      "rewards/margins": 1.0019363164901733,
      "rewards/rejected": 0.3519968092441559,
      "step": 1080
    },
    {
      "epoch": 0.7738729144479943,
      "grad_norm": 4.756031513214111,
      "learning_rate": 9.775e-06,
      "logits/chosen": 338.87506103515625,
      "logits/rejected": 339.5970153808594,
      "logps/chosen": -200.10693359375,
      "logps/rejected": -206.0737762451172,
      "loss": 2.8409,
      "nll_loss": 0.8250052332878113,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.5658237934112549,
      "rewards/margins": 0.9940078854560852,
      "rewards/rejected": 0.5718159675598145,
      "step": 1090
    },
    {
      "epoch": 0.7809726659566916,
      "grad_norm": 5.474150657653809,
      "learning_rate": 9.75e-06,
      "logits/chosen": 339.26031494140625,
      "logits/rejected": 339.56951904296875,
      "logps/chosen": -196.87057495117188,
      "logps/rejected": -208.5595703125,
      "loss": 2.8588,
      "nll_loss": 0.8358258008956909,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.5453259944915771,
      "rewards/margins": 0.7989579439163208,
      "rewards/rejected": 0.7463681101799011,
      "step": 1100
    },
    {
      "epoch": 0.7880724174653887,
      "grad_norm": 5.807976245880127,
      "learning_rate": 9.725000000000001e-06,
      "logits/chosen": 339.6192932128906,
      "logits/rejected": 340.1963195800781,
      "logps/chosen": -193.12240600585938,
      "logps/rejected": -200.970947265625,
      "loss": 2.8713,
      "nll_loss": 0.8592588305473328,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.6282379627227783,
      "rewards/margins": 1.1104888916015625,
      "rewards/rejected": 0.517749011516571,
      "step": 1110
    },
    {
      "epoch": 0.7951721689740859,
      "grad_norm": 5.096536636352539,
      "learning_rate": 9.7e-06,
      "logits/chosen": 340.86358642578125,
      "logits/rejected": 341.68365478515625,
      "logps/chosen": -197.7061004638672,
      "logps/rejected": -201.54391479492188,
      "loss": 2.9954,
      "nll_loss": 0.8222063183784485,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 1.040552020072937,
      "rewards/margins": 0.26457080245018005,
      "rewards/rejected": 0.7759811282157898,
      "step": 1120
    },
    {
      "epoch": 0.8022719204827831,
      "grad_norm": 4.511030197143555,
      "learning_rate": 9.675000000000001e-06,
      "logits/chosen": 337.48638916015625,
      "logits/rejected": 338.4755554199219,
      "logps/chosen": -176.34140014648438,
      "logps/rejected": -186.09149169921875,
      "loss": 2.8979,
      "nll_loss": 0.764702320098877,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.2007744312286377,
      "rewards/margins": 0.7791424989700317,
      "rewards/rejected": 0.4216318130493164,
      "step": 1130
    },
    {
      "epoch": 0.8093716719914803,
      "grad_norm": 4.523362159729004,
      "learning_rate": 9.65e-06,
      "logits/chosen": 339.337646484375,
      "logits/rejected": 340.23870849609375,
      "logps/chosen": -196.0849609375,
      "logps/rejected": -201.1939697265625,
      "loss": 3.0515,
      "nll_loss": 0.8503373265266418,
      "rewards/accuracies": 0.4437499940395355,
      "rewards/chosen": 0.7582377195358276,
      "rewards/margins": -0.4496750235557556,
      "rewards/rejected": 1.207912802696228,
      "step": 1140
    },
    {
      "epoch": 0.8164714235001775,
      "grad_norm": 5.450959205627441,
      "learning_rate": 9.625e-06,
      "logits/chosen": 337.23468017578125,
      "logits/rejected": 337.48370361328125,
      "logps/chosen": -183.2733917236328,
      "logps/rejected": -192.65638732910156,
      "loss": 2.7717,
      "nll_loss": 0.8182468414306641,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 1.6549255847930908,
      "rewards/margins": 0.8833104968070984,
      "rewards/rejected": 0.7716149091720581,
      "step": 1150
    },
    {
      "epoch": 0.8235711750088747,
      "grad_norm": 5.782627105712891,
      "learning_rate": 9.600000000000001e-06,
      "logits/chosen": 338.19769287109375,
      "logits/rejected": 338.9775390625,
      "logps/chosen": -183.479736328125,
      "logps/rejected": -197.3533172607422,
      "loss": 2.9561,
      "nll_loss": 0.8403092622756958,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.4790329933166504,
      "rewards/margins": 0.8251223564147949,
      "rewards/rejected": 0.6539105772972107,
      "step": 1160
    },
    {
      "epoch": 0.8306709265175719,
      "grad_norm": 6.162798881530762,
      "learning_rate": 9.575e-06,
      "logits/chosen": 336.7727966308594,
      "logits/rejected": 339.1225280761719,
      "logps/chosen": -190.30052185058594,
      "logps/rejected": -205.53366088867188,
      "loss": 3.0935,
      "nll_loss": 0.8464582562446594,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.3223400115966797,
      "rewards/margins": 1.0449739694595337,
      "rewards/rejected": 0.27736592292785645,
      "step": 1170
    },
    {
      "epoch": 0.837770678026269,
      "grad_norm": 4.676019668579102,
      "learning_rate": 9.55e-06,
      "logits/chosen": 337.6827697753906,
      "logits/rejected": 339.6482238769531,
      "logps/chosen": -201.87966918945312,
      "logps/rejected": -217.01904296875,
      "loss": 2.8894,
      "nll_loss": 0.8624844551086426,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 1.1202433109283447,
      "rewards/margins": 0.33103734254837036,
      "rewards/rejected": 0.7892059087753296,
      "step": 1180
    },
    {
      "epoch": 0.8448704295349663,
      "grad_norm": 5.151653289794922,
      "learning_rate": 9.525000000000001e-06,
      "logits/chosen": 339.4630432128906,
      "logits/rejected": 340.09222412109375,
      "logps/chosen": -196.4219512939453,
      "logps/rejected": -202.10397338867188,
      "loss": 2.9548,
      "nll_loss": 0.8834567070007324,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.055072546005249,
      "rewards/margins": 0.18968281149864197,
      "rewards/rejected": 0.8653898239135742,
      "step": 1190
    },
    {
      "epoch": 0.8519701810436635,
      "grad_norm": 5.651036262512207,
      "learning_rate": 9.5e-06,
      "logits/chosen": 337.36065673828125,
      "logits/rejected": 338.98797607421875,
      "logps/chosen": -186.46339416503906,
      "logps/rejected": -197.13217163085938,
      "loss": 2.845,
      "nll_loss": 0.8448178172111511,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.2361129522323608,
      "rewards/margins": 1.1844676733016968,
      "rewards/rejected": 0.05164529010653496,
      "step": 1200
    },
    {
      "epoch": 0.8590699325523606,
      "grad_norm": 6.423951148986816,
      "learning_rate": 9.475000000000002e-06,
      "logits/chosen": 337.507080078125,
      "logits/rejected": 339.183837890625,
      "logps/chosen": -196.36627197265625,
      "logps/rejected": -209.81356811523438,
      "loss": 2.9696,
      "nll_loss": 0.8207383155822754,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.4904521703720093,
      "rewards/margins": 0.8810279965400696,
      "rewards/rejected": 0.6094242334365845,
      "step": 1210
    },
    {
      "epoch": 0.8661696840610579,
      "grad_norm": 4.477911472320557,
      "learning_rate": 9.450000000000001e-06,
      "logits/chosen": 339.0962829589844,
      "logits/rejected": 339.88494873046875,
      "logps/chosen": -193.87722778320312,
      "logps/rejected": -204.49569702148438,
      "loss": 2.851,
      "nll_loss": 0.8441823124885559,
      "rewards/accuracies": 0.6312500238418579,
      "rewards/chosen": 1.4512970447540283,
      "rewards/margins": 1.7686636447906494,
      "rewards/rejected": -0.31736645102500916,
      "step": 1220
    },
    {
      "epoch": 0.873269435569755,
      "grad_norm": 5.31676721572876,
      "learning_rate": 9.425e-06,
      "logits/chosen": 337.568115234375,
      "logits/rejected": 338.26727294921875,
      "logps/chosen": -183.8654022216797,
      "logps/rejected": -190.69911193847656,
      "loss": 2.8293,
      "nll_loss": 0.8224946856498718,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.4853932857513428,
      "rewards/margins": 0.8525323867797852,
      "rewards/rejected": 0.6328609585762024,
      "step": 1230
    },
    {
      "epoch": 0.8803691870784522,
      "grad_norm": 5.692936897277832,
      "learning_rate": 9.4e-06,
      "logits/chosen": 338.8398132324219,
      "logits/rejected": 339.34832763671875,
      "logps/chosen": -190.6184539794922,
      "logps/rejected": -197.28001403808594,
      "loss": 2.8935,
      "nll_loss": 0.8292878270149231,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 2.1649680137634277,
      "rewards/margins": 1.2104785442352295,
      "rewards/rejected": 0.9544893503189087,
      "step": 1240
    },
    {
      "epoch": 0.8874689385871495,
      "grad_norm": 5.026283264160156,
      "learning_rate": 9.375000000000001e-06,
      "logits/chosen": 336.87591552734375,
      "logits/rejected": 337.2928161621094,
      "logps/chosen": -179.84255981445312,
      "logps/rejected": -183.4288330078125,
      "loss": 2.8408,
      "nll_loss": 0.8015525937080383,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": 1.4206979274749756,
      "rewards/margins": 0.4963456094264984,
      "rewards/rejected": 0.9243522882461548,
      "step": 1250
    },
    {
      "epoch": 0.8945686900958466,
      "grad_norm": 5.947307109832764,
      "learning_rate": 9.350000000000002e-06,
      "logits/chosen": 338.6391296386719,
      "logits/rejected": 340.3224792480469,
      "logps/chosen": -197.5972137451172,
      "logps/rejected": -209.0689239501953,
      "loss": 2.9335,
      "nll_loss": 0.8461586236953735,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": 0.8346337080001831,
      "rewards/margins": -0.11082283407449722,
      "rewards/rejected": 0.9454566240310669,
      "step": 1260
    },
    {
      "epoch": 0.9016684416045438,
      "grad_norm": 5.63460111618042,
      "learning_rate": 9.325000000000001e-06,
      "logits/chosen": 336.58123779296875,
      "logits/rejected": 338.5921325683594,
      "logps/chosen": -186.27658081054688,
      "logps/rejected": -199.085693359375,
      "loss": 2.8174,
      "nll_loss": 0.8147910237312317,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": 1.8215385675430298,
      "rewards/margins": 1.6135867834091187,
      "rewards/rejected": 0.20795181393623352,
      "step": 1270
    },
    {
      "epoch": 0.9087681931132411,
      "grad_norm": 4.674714088439941,
      "learning_rate": 9.3e-06,
      "logits/chosen": 339.03131103515625,
      "logits/rejected": 340.0071716308594,
      "logps/chosen": -210.482666015625,
      "logps/rejected": -222.57742309570312,
      "loss": 3.0902,
      "nll_loss": 0.8621382713317871,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 1.8063862323760986,
      "rewards/margins": 1.0633823871612549,
      "rewards/rejected": 0.7430038452148438,
      "step": 1280
    },
    {
      "epoch": 0.9158679446219382,
      "grad_norm": 6.4437947273254395,
      "learning_rate": 9.275e-06,
      "logits/chosen": 338.2009582519531,
      "logits/rejected": 339.2520446777344,
      "logps/chosen": -186.0985565185547,
      "logps/rejected": -195.23623657226562,
      "loss": 2.9172,
      "nll_loss": 0.8278757929801941,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.2768099308013916,
      "rewards/margins": 0.8108935356140137,
      "rewards/rejected": 0.46591633558273315,
      "step": 1290
    },
    {
      "epoch": 0.9229676961306355,
      "grad_norm": 6.829351902008057,
      "learning_rate": 9.250000000000001e-06,
      "logits/chosen": 338.64910888671875,
      "logits/rejected": 340.0137634277344,
      "logps/chosen": -186.17779541015625,
      "logps/rejected": -193.72035217285156,
      "loss": 3.0263,
      "nll_loss": 0.858303427696228,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.9131434559822083,
      "rewards/margins": 0.40439462661743164,
      "rewards/rejected": 0.5087488293647766,
      "step": 1300
    },
    {
      "epoch": 0.9300674476393326,
      "grad_norm": 5.862401008605957,
      "learning_rate": 9.225e-06,
      "logits/chosen": 341.4454040527344,
      "logits/rejected": 342.22064208984375,
      "logps/chosen": -204.07568359375,
      "logps/rejected": -214.4129180908203,
      "loss": 2.8787,
      "nll_loss": 0.8908349275588989,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.9207199215888977,
      "rewards/margins": 0.3819986879825592,
      "rewards/rejected": 0.5387212038040161,
      "step": 1310
    },
    {
      "epoch": 0.9371671991480298,
      "grad_norm": 4.729090213775635,
      "learning_rate": 9.200000000000002e-06,
      "logits/chosen": 339.0777282714844,
      "logits/rejected": 340.55413818359375,
      "logps/chosen": -187.21945190429688,
      "logps/rejected": -192.3096466064453,
      "loss": 2.991,
      "nll_loss": 0.8663023710250854,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 1.4049310684204102,
      "rewards/margins": 0.6768951416015625,
      "rewards/rejected": 0.7280358076095581,
      "step": 1320
    },
    {
      "epoch": 0.944266950656727,
      "grad_norm": 4.493321418762207,
      "learning_rate": 9.175000000000001e-06,
      "logits/chosen": 340.9284362792969,
      "logits/rejected": 342.0330505371094,
      "logps/chosen": -200.40420532226562,
      "logps/rejected": -214.12484741210938,
      "loss": 2.9178,
      "nll_loss": 0.8814798593521118,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.555886149406433,
      "rewards/margins": 1.3816989660263062,
      "rewards/rejected": 0.17418721318244934,
      "step": 1330
    },
    {
      "epoch": 0.9513667021654242,
      "grad_norm": 5.564772129058838,
      "learning_rate": 9.15e-06,
      "logits/chosen": 340.74945068359375,
      "logits/rejected": 341.2099914550781,
      "logps/chosen": -195.17913818359375,
      "logps/rejected": -205.9224090576172,
      "loss": 2.9116,
      "nll_loss": 0.857194721698761,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.00387704372406,
      "rewards/margins": 0.6956961750984192,
      "rewards/rejected": 0.3081808388233185,
      "step": 1340
    },
    {
      "epoch": 0.9584664536741214,
      "grad_norm": 4.409079551696777,
      "learning_rate": 9.125e-06,
      "logits/chosen": 341.22357177734375,
      "logits/rejected": 342.43487548828125,
      "logps/chosen": -203.08914184570312,
      "logps/rejected": -213.38247680664062,
      "loss": 2.6814,
      "nll_loss": 0.882184624671936,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.125808835029602,
      "rewards/margins": 0.7299207448959351,
      "rewards/rejected": 0.39588791131973267,
      "step": 1350
    },
    {
      "epoch": 0.9655662051828185,
      "grad_norm": 6.5605292320251465,
      "learning_rate": 9.100000000000001e-06,
      "logits/chosen": 340.6078796386719,
      "logits/rejected": 341.3970642089844,
      "logps/chosen": -201.99697875976562,
      "logps/rejected": -209.512939453125,
      "loss": 2.8657,
      "nll_loss": 0.8266183733940125,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 1.8432719707489014,
      "rewards/margins": 1.8624588251113892,
      "rewards/rejected": -0.019186805933713913,
      "step": 1360
    },
    {
      "epoch": 0.9726659566915158,
      "grad_norm": 4.852658748626709,
      "learning_rate": 9.075e-06,
      "logits/chosen": 338.49267578125,
      "logits/rejected": 339.09783935546875,
      "logps/chosen": -176.40982055664062,
      "logps/rejected": -187.8316650390625,
      "loss": 2.9646,
      "nll_loss": 0.7958912253379822,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 1.1781202554702759,
      "rewards/margins": 0.4891897737979889,
      "rewards/rejected": 0.6889303922653198,
      "step": 1370
    },
    {
      "epoch": 0.979765708200213,
      "grad_norm": 4.669196128845215,
      "learning_rate": 9.050000000000001e-06,
      "logits/chosen": 340.65509033203125,
      "logits/rejected": 341.3074951171875,
      "logps/chosen": -189.39480590820312,
      "logps/rejected": -204.78509521484375,
      "loss": 2.7672,
      "nll_loss": 0.8520326614379883,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.8489987254142761,
      "rewards/margins": 0.8562992215156555,
      "rewards/rejected": -0.0073004006408154964,
      "step": 1380
    },
    {
      "epoch": 0.9868654597089102,
      "grad_norm": 4.984156131744385,
      "learning_rate": 9.025e-06,
      "logits/chosen": 340.68023681640625,
      "logits/rejected": 342.09124755859375,
      "logps/chosen": -200.73858642578125,
      "logps/rejected": -212.7345428466797,
      "loss": 2.7833,
      "nll_loss": 0.8340578079223633,
      "rewards/accuracies": 0.46875,
      "rewards/chosen": 0.7785106897354126,
      "rewards/margins": -0.18855996429920197,
      "rewards/rejected": 0.9670705795288086,
      "step": 1390
    },
    {
      "epoch": 0.9939652112176074,
      "grad_norm": 5.418461799621582,
      "learning_rate": 9e-06,
      "logits/chosen": 338.58782958984375,
      "logits/rejected": 339.7431640625,
      "logps/chosen": -188.6875457763672,
      "logps/rejected": -196.33004760742188,
      "loss": 2.9807,
      "nll_loss": 0.7771390080451965,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 0.9617994427680969,
      "rewards/margins": 0.3431256115436554,
      "rewards/rejected": 0.6186736226081848,
      "step": 1400
    },
    {
      "epoch": 1.0007099751508697,
      "grad_norm": 3.518498182296753,
      "learning_rate": 8.975e-06,
      "logits/chosen": 339.6480407714844,
      "logits/rejected": 341.095947265625,
      "logps/chosen": -189.84788513183594,
      "logps/rejected": -205.57281494140625,
      "loss": 2.9113,
      "nll_loss": 0.7924151420593262,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.635971188545227,
      "rewards/margins": 0.30631136894226074,
      "rewards/rejected": 0.3296597898006439,
      "step": 1410
    },
    {
      "epoch": 1.007809726659567,
      "grad_norm": 3.3066532611846924,
      "learning_rate": 8.95e-06,
      "logits/chosen": 341.25799560546875,
      "logits/rejected": 342.1750183105469,
      "logps/chosen": -196.45187377929688,
      "logps/rejected": -210.38809204101562,
      "loss": 2.9541,
      "nll_loss": 0.8360880017280579,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.3797584772109985,
      "rewards/margins": 0.5418506860733032,
      "rewards/rejected": 0.8379079103469849,
      "step": 1420
    },
    {
      "epoch": 1.0149094781682642,
      "grad_norm": 4.293073654174805,
      "learning_rate": 8.925e-06,
      "logits/chosen": 341.51727294921875,
      "logits/rejected": 342.25616455078125,
      "logps/chosen": -194.34205627441406,
      "logps/rejected": -198.4343719482422,
      "loss": 3.1018,
      "nll_loss": 0.8854513168334961,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": 0.5500572919845581,
      "rewards/margins": 0.01053993683308363,
      "rewards/rejected": 0.5395174026489258,
      "step": 1430
    },
    {
      "epoch": 1.0220092296769614,
      "grad_norm": 3.911417245864868,
      "learning_rate": 8.900000000000001e-06,
      "logits/chosen": 340.04888916015625,
      "logits/rejected": 340.2338562011719,
      "logps/chosen": -193.8403778076172,
      "logps/rejected": -202.007568359375,
      "loss": 2.7516,
      "nll_loss": 0.8242541551589966,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 0.8668476343154907,
      "rewards/margins": 1.1561702489852905,
      "rewards/rejected": -0.2893225848674774,
      "step": 1440
    },
    {
      "epoch": 1.0291089811856584,
      "grad_norm": 3.7137792110443115,
      "learning_rate": 8.875e-06,
      "logits/chosen": 340.4403381347656,
      "logits/rejected": 340.75421142578125,
      "logps/chosen": -203.35903930664062,
      "logps/rejected": -217.2755889892578,
      "loss": 2.8766,
      "nll_loss": 0.8409374356269836,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 1.76837956905365,
      "rewards/margins": 1.441735029220581,
      "rewards/rejected": 0.3266444802284241,
      "step": 1450
    },
    {
      "epoch": 1.0362087326943556,
      "grad_norm": 4.778472423553467,
      "learning_rate": 8.85e-06,
      "logits/chosen": 339.4875793457031,
      "logits/rejected": 340.3006896972656,
      "logps/chosen": -182.9895782470703,
      "logps/rejected": -193.43161010742188,
      "loss": 2.9743,
      "nll_loss": 0.8184632062911987,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 1.0020883083343506,
      "rewards/margins": 0.6625112891197205,
      "rewards/rejected": 0.3395770490169525,
      "step": 1460
    },
    {
      "epoch": 1.0433084842030529,
      "grad_norm": 3.2902185916900635,
      "learning_rate": 8.825000000000001e-06,
      "logits/chosen": 338.39410400390625,
      "logits/rejected": 339.75830078125,
      "logps/chosen": -187.6942138671875,
      "logps/rejected": -188.06224060058594,
      "loss": 2.9433,
      "nll_loss": 0.827163815498352,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 1.0083094835281372,
      "rewards/margins": 0.2871331572532654,
      "rewards/rejected": 0.721176266670227,
      "step": 1470
    },
    {
      "epoch": 1.0504082357117501,
      "grad_norm": 3.7149689197540283,
      "learning_rate": 8.8e-06,
      "logits/chosen": 339.25439453125,
      "logits/rejected": 339.57989501953125,
      "logps/chosen": -193.2591552734375,
      "logps/rejected": -200.39111328125,
      "loss": 3.0619,
      "nll_loss": 0.7893176078796387,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": 0.9834807515144348,
      "rewards/margins": -0.0636393278837204,
      "rewards/rejected": 1.0471203327178955,
      "step": 1480
    },
    {
      "epoch": 1.0575079872204474,
      "grad_norm": 3.6999778747558594,
      "learning_rate": 8.775e-06,
      "logits/chosen": 338.8623352050781,
      "logits/rejected": 340.6391906738281,
      "logps/chosen": -187.15493774414062,
      "logps/rejected": -192.80007934570312,
      "loss": 2.9248,
      "nll_loss": 0.8629676699638367,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 1.2222545146942139,
      "rewards/margins": 0.9350816011428833,
      "rewards/rejected": 0.287172794342041,
      "step": 1490
    },
    {
      "epoch": 1.0646077387291444,
      "grad_norm": 4.338784217834473,
      "learning_rate": 8.750000000000001e-06,
      "logits/chosen": 340.25286865234375,
      "logits/rejected": 341.38134765625,
      "logps/chosen": -194.3972625732422,
      "logps/rejected": -195.93568420410156,
      "loss": 2.8662,
      "nll_loss": 0.8583171963691711,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.0927032232284546,
      "rewards/margins": 0.45100802183151245,
      "rewards/rejected": 0.6416953206062317,
      "step": 1500
    },
    {
      "epoch": 1.0717074902378416,
      "grad_norm": 2.9227564334869385,
      "learning_rate": 8.725000000000002e-06,
      "logits/chosen": 337.92120361328125,
      "logits/rejected": 339.3435363769531,
      "logps/chosen": -183.2168731689453,
      "logps/rejected": -192.08694458007812,
      "loss": 2.8609,
      "nll_loss": 0.792168140411377,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 1.4831641912460327,
      "rewards/margins": 0.8541313409805298,
      "rewards/rejected": 0.6290327906608582,
      "step": 1510
    },
    {
      "epoch": 1.0788072417465389,
      "grad_norm": 4.042004585266113,
      "learning_rate": 8.700000000000001e-06,
      "logits/chosen": 340.4018859863281,
      "logits/rejected": 342.74176025390625,
      "logps/chosen": -197.490234375,
      "logps/rejected": -212.5970916748047,
      "loss": 2.6941,
      "nll_loss": 0.8407976031303406,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.9918349981307983,
      "rewards/margins": 0.5114678144454956,
      "rewards/rejected": 0.48036718368530273,
      "step": 1520
    },
    {
      "epoch": 1.085906993255236,
      "grad_norm": 4.4538493156433105,
      "learning_rate": 8.675e-06,
      "logits/chosen": 340.4520568847656,
      "logits/rejected": 340.85113525390625,
      "logps/chosen": -196.14341735839844,
      "logps/rejected": -201.70651245117188,
      "loss": 2.8712,
      "nll_loss": 0.8301631808280945,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": 0.7238889932632446,
      "rewards/margins": 0.3698866367340088,
      "rewards/rejected": 0.3540024161338806,
      "step": 1530
    },
    {
      "epoch": 1.0930067447639333,
      "grad_norm": 3.9950296878814697,
      "learning_rate": 8.65e-06,
      "logits/chosen": 341.0440979003906,
      "logits/rejected": 342.16107177734375,
      "logps/chosen": -181.04017639160156,
      "logps/rejected": -189.2296600341797,
      "loss": 2.9071,
      "nll_loss": 0.8367129564285278,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.1190193891525269,
      "rewards/margins": 0.8091394305229187,
      "rewards/rejected": 0.3098798990249634,
      "step": 1540
    },
    {
      "epoch": 1.1001064962726304,
      "grad_norm": 4.650782108306885,
      "learning_rate": 8.625000000000001e-06,
      "logits/chosen": 340.54534912109375,
      "logits/rejected": 342.9261169433594,
      "logps/chosen": -191.97946166992188,
      "logps/rejected": -206.81765747070312,
      "loss": 2.855,
      "nll_loss": 0.8310203552246094,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 0.45105671882629395,
      "rewards/margins": 0.16025009751319885,
      "rewards/rejected": 0.2908066511154175,
      "step": 1550
    },
    {
      "epoch": 1.1072062477813276,
      "grad_norm": 3.584472417831421,
      "learning_rate": 8.6e-06,
      "logits/chosen": 340.0411071777344,
      "logits/rejected": 341.38568115234375,
      "logps/chosen": -188.5929412841797,
      "logps/rejected": -204.10040283203125,
      "loss": 2.648,
      "nll_loss": 0.8173882365226746,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.0276854038238525,
      "rewards/margins": 0.8045555353164673,
      "rewards/rejected": 0.22312986850738525,
      "step": 1560
    },
    {
      "epoch": 1.1143059992900248,
      "grad_norm": 4.105007171630859,
      "learning_rate": 8.575000000000002e-06,
      "logits/chosen": 341.017333984375,
      "logits/rejected": 341.6028747558594,
      "logps/chosen": -197.1302490234375,
      "logps/rejected": -203.6832733154297,
      "loss": 2.854,
      "nll_loss": 0.873302161693573,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.9701941609382629,
      "rewards/margins": 0.43730100989341736,
      "rewards/rejected": 0.5328931212425232,
      "step": 1570
    },
    {
      "epoch": 1.121405750798722,
      "grad_norm": 4.526991367340088,
      "learning_rate": 8.550000000000001e-06,
      "logits/chosen": 338.8733825683594,
      "logits/rejected": 340.4959716796875,
      "logps/chosen": -176.5824432373047,
      "logps/rejected": -185.77557373046875,
      "loss": 2.8242,
      "nll_loss": 0.8042973279953003,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.054913878440857,
      "rewards/margins": 0.8617621660232544,
      "rewards/rejected": 0.1931518018245697,
      "step": 1580
    },
    {
      "epoch": 1.1285055023074193,
      "grad_norm": 2.9194908142089844,
      "learning_rate": 8.525e-06,
      "logits/chosen": 340.3371276855469,
      "logits/rejected": 340.46148681640625,
      "logps/chosen": -188.19100952148438,
      "logps/rejected": -187.3601837158203,
      "loss": 2.9584,
      "nll_loss": 0.8450362086296082,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.1717652082443237,
      "rewards/margins": 0.5871485471725464,
      "rewards/rejected": 0.5846166610717773,
      "step": 1590
    },
    {
      "epoch": 1.1356052538161165,
      "grad_norm": 3.871718168258667,
      "learning_rate": 8.5e-06,
      "logits/chosen": 340.42230224609375,
      "logits/rejected": 340.6893005371094,
      "logps/chosen": -205.48379516601562,
      "logps/rejected": -212.87344360351562,
      "loss": 2.87,
      "nll_loss": 0.8562639951705933,
      "rewards/accuracies": 0.46875,
      "rewards/chosen": 0.32301104068756104,
      "rewards/margins": -0.23068685829639435,
      "rewards/rejected": 0.5536978840827942,
      "step": 1600
    },
    {
      "epoch": 1.1427050053248136,
      "grad_norm": 3.2216548919677734,
      "learning_rate": 8.475000000000001e-06,
      "logits/chosen": 338.776611328125,
      "logits/rejected": 340.90594482421875,
      "logps/chosen": -178.0882568359375,
      "logps/rejected": -192.21878051757812,
      "loss": 2.786,
      "nll_loss": 0.8151729702949524,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.4233646392822266,
      "rewards/margins": 0.8265708088874817,
      "rewards/rejected": 0.5967936515808105,
      "step": 1610
    },
    {
      "epoch": 1.1498047568335108,
      "grad_norm": 4.080079078674316,
      "learning_rate": 8.45e-06,
      "logits/chosen": 339.3879699707031,
      "logits/rejected": 340.2811584472656,
      "logps/chosen": -189.34169006347656,
      "logps/rejected": -192.62994384765625,
      "loss": 2.775,
      "nll_loss": 0.8244802355766296,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 1.4365953207015991,
      "rewards/margins": 1.1379330158233643,
      "rewards/rejected": 0.29866230487823486,
      "step": 1620
    },
    {
      "epoch": 1.156904508342208,
      "grad_norm": 3.3016319274902344,
      "learning_rate": 8.425000000000001e-06,
      "logits/chosen": 340.8569641113281,
      "logits/rejected": 341.6436767578125,
      "logps/chosen": -203.50375366210938,
      "logps/rejected": -210.526123046875,
      "loss": 2.6553,
      "nll_loss": 0.8712364435195923,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 1.6048223972320557,
      "rewards/margins": 2.141632318496704,
      "rewards/rejected": -0.5368099212646484,
      "step": 1630
    },
    {
      "epoch": 1.1640042598509053,
      "grad_norm": 3.9046545028686523,
      "learning_rate": 8.400000000000001e-06,
      "logits/chosen": 339.23736572265625,
      "logits/rejected": 339.89776611328125,
      "logps/chosen": -199.1226806640625,
      "logps/rejected": -206.24923706054688,
      "loss": 2.7506,
      "nll_loss": 0.825864315032959,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 1.3545154333114624,
      "rewards/margins": 1.3850349187850952,
      "rewards/rejected": -0.030519450083374977,
      "step": 1640
    },
    {
      "epoch": 1.1711040113596023,
      "grad_norm": 4.010277271270752,
      "learning_rate": 8.375e-06,
      "logits/chosen": 338.0540771484375,
      "logits/rejected": 338.86004638671875,
      "logps/chosen": -189.231689453125,
      "logps/rejected": -202.2471160888672,
      "loss": 2.8111,
      "nll_loss": 0.8411731719970703,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.7910385131835938,
      "rewards/margins": 1.3453514575958252,
      "rewards/rejected": 0.44568705558776855,
      "step": 1650
    },
    {
      "epoch": 1.1782037628682995,
      "grad_norm": 3.6233034133911133,
      "learning_rate": 8.35e-06,
      "logits/chosen": 340.627197265625,
      "logits/rejected": 341.31573486328125,
      "logps/chosen": -191.48175048828125,
      "logps/rejected": -198.3437042236328,
      "loss": 2.9286,
      "nll_loss": 0.8491460680961609,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 1.3917664289474487,
      "rewards/margins": 0.4324657917022705,
      "rewards/rejected": 0.9593006372451782,
      "step": 1660
    },
    {
      "epoch": 1.1853035143769968,
      "grad_norm": 3.817347288131714,
      "learning_rate": 8.325e-06,
      "logits/chosen": 337.8629455566406,
      "logits/rejected": 339.232177734375,
      "logps/chosen": -190.2604522705078,
      "logps/rejected": -202.38665771484375,
      "loss": 2.9472,
      "nll_loss": 0.7921324968338013,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.6619402170181274,
      "rewards/margins": 0.9912534952163696,
      "rewards/rejected": 0.6706868410110474,
      "step": 1670
    },
    {
      "epoch": 1.192403265885694,
      "grad_norm": 3.4911320209503174,
      "learning_rate": 8.3e-06,
      "logits/chosen": 338.64093017578125,
      "logits/rejected": 339.36029052734375,
      "logps/chosen": -183.5236053466797,
      "logps/rejected": -194.89334106445312,
      "loss": 2.8835,
      "nll_loss": 0.7890980243682861,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": 1.8099644184112549,
      "rewards/margins": 1.125924825668335,
      "rewards/rejected": 0.6840394735336304,
      "step": 1680
    },
    {
      "epoch": 1.1995030173943912,
      "grad_norm": 3.9971141815185547,
      "learning_rate": 8.275000000000001e-06,
      "logits/chosen": 338.9953918457031,
      "logits/rejected": 339.82843017578125,
      "logps/chosen": -193.67636108398438,
      "logps/rejected": -202.0526580810547,
      "loss": 2.7169,
      "nll_loss": 0.831063449382782,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 1.4714272022247314,
      "rewards/margins": 0.9630268812179565,
      "rewards/rejected": 0.5084003210067749,
      "step": 1690
    },
    {
      "epoch": 1.2066027689030885,
      "grad_norm": 5.050751686096191,
      "learning_rate": 8.25e-06,
      "logits/chosen": 338.45269775390625,
      "logits/rejected": 339.6547546386719,
      "logps/chosen": -184.01663208007812,
      "logps/rejected": -200.53123474121094,
      "loss": 2.9143,
      "nll_loss": 0.818320631980896,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 1.7823505401611328,
      "rewards/margins": 0.5916246175765991,
      "rewards/rejected": 1.1907260417938232,
      "step": 1700
    },
    {
      "epoch": 1.2137025204117855,
      "grad_norm": 4.388422966003418,
      "learning_rate": 8.225e-06,
      "logits/chosen": 337.72259521484375,
      "logits/rejected": 338.7200622558594,
      "logps/chosen": -189.6288604736328,
      "logps/rejected": -201.04507446289062,
      "loss": 2.9501,
      "nll_loss": 0.8495877981185913,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 1.5829498767852783,
      "rewards/margins": 0.7821515798568726,
      "rewards/rejected": 0.8007982969284058,
      "step": 1710
    },
    {
      "epoch": 1.2208022719204827,
      "grad_norm": 4.334252834320068,
      "learning_rate": 8.2e-06,
      "logits/chosen": 339.60772705078125,
      "logits/rejected": 340.1954650878906,
      "logps/chosen": -186.7445831298828,
      "logps/rejected": -195.08505249023438,
      "loss": 2.7916,
      "nll_loss": 0.834956169128418,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 1.2405064105987549,
      "rewards/margins": 0.14342400431632996,
      "rewards/rejected": 1.0970823764801025,
      "step": 1720
    },
    {
      "epoch": 1.22790202342918,
      "grad_norm": 3.5243310928344727,
      "learning_rate": 8.175e-06,
      "logits/chosen": 337.2369079589844,
      "logits/rejected": 338.64617919921875,
      "logps/chosen": -180.49842834472656,
      "logps/rejected": -195.07762145996094,
      "loss": 2.9153,
      "nll_loss": 0.8279843330383301,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 1.3121850490570068,
      "rewards/margins": 0.8870641589164734,
      "rewards/rejected": 0.4251207709312439,
      "step": 1730
    },
    {
      "epoch": 1.2350017749378772,
      "grad_norm": 3.5783441066741943,
      "learning_rate": 8.15e-06,
      "logits/chosen": 338.621826171875,
      "logits/rejected": 340.5491638183594,
      "logps/chosen": -189.68399047851562,
      "logps/rejected": -208.7183837890625,
      "loss": 2.885,
      "nll_loss": 0.8058541417121887,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.224232792854309,
      "rewards/margins": 1.1926761865615845,
      "rewards/rejected": 0.03155647590756416,
      "step": 1740
    },
    {
      "epoch": 1.2421015264465745,
      "grad_norm": 2.740841865539551,
      "learning_rate": 8.125000000000001e-06,
      "logits/chosen": 340.08013916015625,
      "logits/rejected": 341.6470642089844,
      "logps/chosen": -198.73614501953125,
      "logps/rejected": -210.6556396484375,
      "loss": 2.7415,
      "nll_loss": 0.8404291868209839,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 0.21592703461647034,
      "rewards/margins": 0.14337703585624695,
      "rewards/rejected": 0.07255001366138458,
      "step": 1750
    },
    {
      "epoch": 1.2492012779552715,
      "grad_norm": 3.4323031902313232,
      "learning_rate": 8.1e-06,
      "logits/chosen": 338.7582092285156,
      "logits/rejected": 339.40667724609375,
      "logps/chosen": -191.72653198242188,
      "logps/rejected": -194.0586700439453,
      "loss": 2.7174,
      "nll_loss": 0.8416287302970886,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.3590731620788574,
      "rewards/margins": 1.110272765159607,
      "rewards/rejected": 0.24880027770996094,
      "step": 1760
    },
    {
      "epoch": 1.2563010294639687,
      "grad_norm": 4.268158912658691,
      "learning_rate": 8.075000000000001e-06,
      "logits/chosen": 338.21746826171875,
      "logits/rejected": 339.9846496582031,
      "logps/chosen": -182.69041442871094,
      "logps/rejected": -194.28623962402344,
      "loss": 2.7372,
      "nll_loss": 0.7994340062141418,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 1.9523347616195679,
      "rewards/margins": 1.64300537109375,
      "rewards/rejected": 0.30932945013046265,
      "step": 1770
    },
    {
      "epoch": 1.263400780972666,
      "grad_norm": 3.894078016281128,
      "learning_rate": 8.050000000000001e-06,
      "logits/chosen": 339.52606201171875,
      "logits/rejected": 341.3309020996094,
      "logps/chosen": -184.8249969482422,
      "logps/rejected": -197.466796875,
      "loss": 2.9874,
      "nll_loss": 0.8001931309700012,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.1988623142242432,
      "rewards/margins": 0.7127425670623779,
      "rewards/rejected": 0.48611965775489807,
      "step": 1780
    },
    {
      "epoch": 1.2705005324813632,
      "grad_norm": 3.8925440311431885,
      "learning_rate": 8.025e-06,
      "logits/chosen": 341.80535888671875,
      "logits/rejected": 342.39666748046875,
      "logps/chosen": -197.42172241210938,
      "logps/rejected": -207.8034210205078,
      "loss": 2.9413,
      "nll_loss": 0.8355985879898071,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 0.9403538703918457,
      "rewards/margins": 0.42638102173805237,
      "rewards/rejected": 0.5139728784561157,
      "step": 1790
    },
    {
      "epoch": 1.2776002839900604,
      "grad_norm": 3.4551684856414795,
      "learning_rate": 8.000000000000001e-06,
      "logits/chosen": 341.4669494628906,
      "logits/rejected": 341.7503356933594,
      "logps/chosen": -175.16603088378906,
      "logps/rejected": -182.3688507080078,
      "loss": 2.7794,
      "nll_loss": 0.8557265400886536,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.3690779209136963,
      "rewards/margins": 0.752770721912384,
      "rewards/rejected": 0.6163071393966675,
      "step": 1800
    },
    {
      "epoch": 1.2847000354987577,
      "grad_norm": 3.929164409637451,
      "learning_rate": 7.975e-06,
      "logits/chosen": 340.14410400390625,
      "logits/rejected": 340.3075866699219,
      "logps/chosen": -202.33872985839844,
      "logps/rejected": -200.9756622314453,
      "loss": 2.7568,
      "nll_loss": 0.8416630625724792,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.3384016752243042,
      "rewards/margins": 0.6803576350212097,
      "rewards/rejected": 0.6580439805984497,
      "step": 1810
    },
    {
      "epoch": 1.2917997870074547,
      "grad_norm": 3.959857702255249,
      "learning_rate": 7.950000000000002e-06,
      "logits/chosen": 340.9101257324219,
      "logits/rejected": 341.0663757324219,
      "logps/chosen": -174.85289001464844,
      "logps/rejected": -177.79653930664062,
      "loss": 2.9981,
      "nll_loss": 0.8431947827339172,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.207998275756836,
      "rewards/margins": 0.1113225668668747,
      "rewards/rejected": 1.0966756343841553,
      "step": 1820
    },
    {
      "epoch": 1.298899538516152,
      "grad_norm": 3.2618844509124756,
      "learning_rate": 7.925000000000001e-06,
      "logits/chosen": 340.14154052734375,
      "logits/rejected": 340.0506896972656,
      "logps/chosen": -186.65013122558594,
      "logps/rejected": -186.99002075195312,
      "loss": 2.9495,
      "nll_loss": 0.8096723556518555,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.3397446870803833,
      "rewards/margins": 0.849502682685852,
      "rewards/rejected": 0.4902420938014984,
      "step": 1830
    },
    {
      "epoch": 1.3059992900248492,
      "grad_norm": 3.5094287395477295,
      "learning_rate": 7.9e-06,
      "logits/chosen": 339.02166748046875,
      "logits/rejected": 340.37725830078125,
      "logps/chosen": -190.76809692382812,
      "logps/rejected": -198.5635223388672,
      "loss": 2.7241,
      "nll_loss": 0.7904618382453918,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.5135234594345093,
      "rewards/margins": 1.0336240530014038,
      "rewards/rejected": 0.47989940643310547,
      "step": 1840
    },
    {
      "epoch": 1.3130990415335464,
      "grad_norm": 3.611518383026123,
      "learning_rate": 7.875e-06,
      "logits/chosen": 339.57891845703125,
      "logits/rejected": 340.0268249511719,
      "logps/chosen": -194.0839080810547,
      "logps/rejected": -197.16404724121094,
      "loss": 2.7522,
      "nll_loss": 0.8192523121833801,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 1.3107264041900635,
      "rewards/margins": 0.16911832988262177,
      "rewards/rejected": 1.1416081190109253,
      "step": 1850
    },
    {
      "epoch": 1.3201987930422434,
      "grad_norm": 4.709707736968994,
      "learning_rate": 7.850000000000001e-06,
      "logits/chosen": 341.87921142578125,
      "logits/rejected": 343.395751953125,
      "logps/chosen": -192.28482055664062,
      "logps/rejected": -203.53622436523438,
      "loss": 2.849,
      "nll_loss": 0.8624848127365112,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 1.5261666774749756,
      "rewards/margins": 1.1057960987091064,
      "rewards/rejected": 0.4203703999519348,
      "step": 1860
    },
    {
      "epoch": 1.3272985445509407,
      "grad_norm": 4.271967887878418,
      "learning_rate": 7.825e-06,
      "logits/chosen": 340.1646423339844,
      "logits/rejected": 340.38494873046875,
      "logps/chosen": -188.04330444335938,
      "logps/rejected": -189.123291015625,
      "loss": 2.7983,
      "nll_loss": 0.7891383171081543,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.1443662643432617,
      "rewards/margins": 0.5444419980049133,
      "rewards/rejected": 0.5999244451522827,
      "step": 1870
    },
    {
      "epoch": 1.334398296059638,
      "grad_norm": 4.025763034820557,
      "learning_rate": 7.800000000000002e-06,
      "logits/chosen": 340.4295349121094,
      "logits/rejected": 342.5989074707031,
      "logps/chosen": -191.5185089111328,
      "logps/rejected": -193.86439514160156,
      "loss": 2.762,
      "nll_loss": 0.8534207344055176,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.2369142770767212,
      "rewards/margins": 0.6571766138076782,
      "rewards/rejected": 0.5797377824783325,
      "step": 1880
    },
    {
      "epoch": 1.3414980475683351,
      "grad_norm": 5.136887073516846,
      "learning_rate": 7.775000000000001e-06,
      "logits/chosen": 339.1517028808594,
      "logits/rejected": 340.39691162109375,
      "logps/chosen": -175.9570770263672,
      "logps/rejected": -179.25674438476562,
      "loss": 2.8036,
      "nll_loss": 0.7785991430282593,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.355119228363037,
      "rewards/margins": 0.46839746832847595,
      "rewards/rejected": 0.8867216110229492,
      "step": 1890
    },
    {
      "epoch": 1.3485977990770324,
      "grad_norm": 4.306469917297363,
      "learning_rate": 7.75e-06,
      "logits/chosen": 341.4596252441406,
      "logits/rejected": 344.0299072265625,
      "logps/chosen": -190.23812866210938,
      "logps/rejected": -204.64230346679688,
      "loss": 2.7475,
      "nll_loss": 0.8550945520401001,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.9193546175956726,
      "rewards/margins": 0.631149172782898,
      "rewards/rejected": 0.2882053852081299,
      "step": 1900
    },
    {
      "epoch": 1.3556975505857296,
      "grad_norm": 4.478053569793701,
      "learning_rate": 7.725e-06,
      "logits/chosen": 342.12689208984375,
      "logits/rejected": 343.2157287597656,
      "logps/chosen": -199.96128845214844,
      "logps/rejected": -206.72750854492188,
      "loss": 2.9398,
      "nll_loss": 0.8516634702682495,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 1.1450879573822021,
      "rewards/margins": 0.5945863127708435,
      "rewards/rejected": 0.5505016446113586,
      "step": 1910
    },
    {
      "epoch": 1.3627973020944266,
      "grad_norm": 4.351319789886475,
      "learning_rate": 7.7e-06,
      "logits/chosen": 341.34423828125,
      "logits/rejected": 342.9105224609375,
      "logps/chosen": -195.16799926757812,
      "logps/rejected": -202.81271362304688,
      "loss": 2.8322,
      "nll_loss": 0.8419910669326782,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.1942965984344482,
      "rewards/margins": 0.8333761096000671,
      "rewards/rejected": 0.3609205186367035,
      "step": 1920
    },
    {
      "epoch": 1.3698970536031239,
      "grad_norm": 3.7139527797698975,
      "learning_rate": 7.675e-06,
      "logits/chosen": 340.9198303222656,
      "logits/rejected": 342.8694152832031,
      "logps/chosen": -197.49136352539062,
      "logps/rejected": -206.13046264648438,
      "loss": 2.8832,
      "nll_loss": 0.829811692237854,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.3540470600128174,
      "rewards/margins": 0.487638384103775,
      "rewards/rejected": 0.8664087057113647,
      "step": 1930
    },
    {
      "epoch": 1.376996805111821,
      "grad_norm": 4.427187919616699,
      "learning_rate": 7.650000000000001e-06,
      "logits/chosen": 340.97601318359375,
      "logits/rejected": 341.7929382324219,
      "logps/chosen": -190.33636474609375,
      "logps/rejected": -194.1543426513672,
      "loss": 2.7954,
      "nll_loss": 0.8152230381965637,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 0.8441628217697144,
      "rewards/margins": 0.06029230356216431,
      "rewards/rejected": 0.7838705778121948,
      "step": 1940
    },
    {
      "epoch": 1.3840965566205183,
      "grad_norm": 3.972235679626465,
      "learning_rate": 7.625e-06,
      "logits/chosen": 341.4920959472656,
      "logits/rejected": 342.1246032714844,
      "logps/chosen": -198.87088012695312,
      "logps/rejected": -210.5428009033203,
      "loss": 2.8311,
      "nll_loss": 0.8646643757820129,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.283650517463684,
      "rewards/margins": 1.2034740447998047,
      "rewards/rejected": 0.08017649501562119,
      "step": 1950
    },
    {
      "epoch": 1.3911963081292154,
      "grad_norm": 4.119014739990234,
      "learning_rate": 7.600000000000001e-06,
      "logits/chosen": 340.6510925292969,
      "logits/rejected": 341.7246398925781,
      "logps/chosen": -198.2279510498047,
      "logps/rejected": -202.95150756835938,
      "loss": 2.9751,
      "nll_loss": 0.8241156339645386,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.5542834997177124,
      "rewards/margins": 0.04781373590230942,
      "rewards/rejected": 0.5064698457717896,
      "step": 1960
    },
    {
      "epoch": 1.3982960596379126,
      "grad_norm": 4.151145935058594,
      "learning_rate": 7.575e-06,
      "logits/chosen": 340.51873779296875,
      "logits/rejected": 342.21466064453125,
      "logps/chosen": -193.17039489746094,
      "logps/rejected": -202.2554473876953,
      "loss": 3.0029,
      "nll_loss": 0.8441386222839355,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.9758868217468262,
      "rewards/margins": 0.16114556789398193,
      "rewards/rejected": 0.8147412538528442,
      "step": 1970
    },
    {
      "epoch": 1.4053958111466098,
      "grad_norm": 3.8212502002716064,
      "learning_rate": 7.5500000000000006e-06,
      "logits/chosen": 342.24542236328125,
      "logits/rejected": 343.4151611328125,
      "logps/chosen": -205.7521209716797,
      "logps/rejected": -219.6190948486328,
      "loss": 2.8813,
      "nll_loss": 0.8752349615097046,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.6565104722976685,
      "rewards/margins": 0.6004519462585449,
      "rewards/rejected": 0.05605846643447876,
      "step": 1980
    },
    {
      "epoch": 1.412495562655307,
      "grad_norm": 3.6788854598999023,
      "learning_rate": 7.525e-06,
      "logits/chosen": 338.75897216796875,
      "logits/rejected": 340.1818542480469,
      "logps/chosen": -176.66407775878906,
      "logps/rejected": -194.81558227539062,
      "loss": 2.9998,
      "nll_loss": 0.7830638885498047,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.5637736320495605,
      "rewards/margins": 0.7127215266227722,
      "rewards/rejected": 0.8510521054267883,
      "step": 1990
    },
    {
      "epoch": 1.4195953141640043,
      "grad_norm": 3.920827627182007,
      "learning_rate": 7.500000000000001e-06,
      "logits/chosen": 340.1693420410156,
      "logits/rejected": 340.09454345703125,
      "logps/chosen": -188.7467041015625,
      "logps/rejected": -193.61732482910156,
      "loss": 2.6693,
      "nll_loss": 0.8420814275741577,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": 1.8354270458221436,
      "rewards/margins": 1.5590639114379883,
      "rewards/rejected": 0.2763631343841553,
      "step": 2000
    },
    {
      "epoch": 1.4266950656727015,
      "grad_norm": 4.578457355499268,
      "learning_rate": 7.475000000000001e-06,
      "logits/chosen": 339.0767517089844,
      "logits/rejected": 341.67767333984375,
      "logps/chosen": -183.07958984375,
      "logps/rejected": -200.47763061523438,
      "loss": 2.8219,
      "nll_loss": 0.7888543009757996,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.686614990234375,
      "rewards/margins": 0.7959238886833191,
      "rewards/rejected": 0.8906911611557007,
      "step": 2010
    },
    {
      "epoch": 1.4337948171813988,
      "grad_norm": 3.455875873565674,
      "learning_rate": 7.450000000000001e-06,
      "logits/chosen": 338.9548645019531,
      "logits/rejected": 340.3414001464844,
      "logps/chosen": -184.58367919921875,
      "logps/rejected": -199.2617645263672,
      "loss": 2.9461,
      "nll_loss": 0.7967444658279419,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 1.3303706645965576,
      "rewards/margins": 0.2677156925201416,
      "rewards/rejected": 1.062654972076416,
      "step": 2020
    },
    {
      "epoch": 1.4408945686900958,
      "grad_norm": 3.9043424129486084,
      "learning_rate": 7.425000000000001e-06,
      "logits/chosen": 339.9795227050781,
      "logits/rejected": 340.9074401855469,
      "logps/chosen": -191.3502197265625,
      "logps/rejected": -199.95631408691406,
      "loss": 2.8836,
      "nll_loss": 0.8551106452941895,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.3618671894073486,
      "rewards/margins": 0.820838451385498,
      "rewards/rejected": 0.5410284996032715,
      "step": 2030
    },
    {
      "epoch": 1.447994320198793,
      "grad_norm": 3.3244266510009766,
      "learning_rate": 7.4e-06,
      "logits/chosen": 338.837890625,
      "logits/rejected": 340.7485046386719,
      "logps/chosen": -197.343505859375,
      "logps/rejected": -206.1751251220703,
      "loss": 2.7186,
      "nll_loss": 0.7991342544555664,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.6186378002166748,
      "rewards/margins": 0.6316665410995483,
      "rewards/rejected": 0.986971378326416,
      "step": 2040
    },
    {
      "epoch": 1.4550940717074903,
      "grad_norm": 4.777885437011719,
      "learning_rate": 7.375000000000001e-06,
      "logits/chosen": 337.7852783203125,
      "logits/rejected": 338.9451904296875,
      "logps/chosen": -193.81072998046875,
      "logps/rejected": -199.7366180419922,
      "loss": 2.9988,
      "nll_loss": 0.8131029009819031,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 1.1438395977020264,
      "rewards/margins": 0.4654250144958496,
      "rewards/rejected": 0.6784147024154663,
      "step": 2050
    },
    {
      "epoch": 1.4621938232161875,
      "grad_norm": 4.874780654907227,
      "learning_rate": 7.350000000000001e-06,
      "logits/chosen": 339.016845703125,
      "logits/rejected": 340.53106689453125,
      "logps/chosen": -200.59988403320312,
      "logps/rejected": -208.98233032226562,
      "loss": 2.8057,
      "nll_loss": 0.8279398679733276,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.4562461376190186,
      "rewards/margins": 0.9019635319709778,
      "rewards/rejected": 0.5542827248573303,
      "step": 2060
    },
    {
      "epoch": 1.4692935747248845,
      "grad_norm": 4.603757381439209,
      "learning_rate": 7.325000000000001e-06,
      "logits/chosen": 337.1116638183594,
      "logits/rejected": 338.1113586425781,
      "logps/chosen": -182.95562744140625,
      "logps/rejected": -186.68978881835938,
      "loss": 2.8551,
      "nll_loss": 0.7447530031204224,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.8020870685577393,
      "rewards/margins": 0.6272591352462769,
      "rewards/rejected": 1.1748276948928833,
      "step": 2070
    },
    {
      "epoch": 1.4763933262335818,
      "grad_norm": 4.040008544921875,
      "learning_rate": 7.3e-06,
      "logits/chosen": 339.54461669921875,
      "logits/rejected": 340.9527282714844,
      "logps/chosen": -197.36744689941406,
      "logps/rejected": -207.1871337890625,
      "loss": 2.9281,
      "nll_loss": 0.8712335824966431,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 0.8546584844589233,
      "rewards/margins": -0.0027577816508710384,
      "rewards/rejected": 0.8574161529541016,
      "step": 2080
    },
    {
      "epoch": 1.483493077742279,
      "grad_norm": 4.425686836242676,
      "learning_rate": 7.275000000000001e-06,
      "logits/chosen": 338.8273620605469,
      "logits/rejected": 340.9471740722656,
      "logps/chosen": -198.19735717773438,
      "logps/rejected": -211.26828002929688,
      "loss": 2.8193,
      "nll_loss": 0.8035755157470703,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 1.982173204421997,
      "rewards/margins": 1.1658512353897095,
      "rewards/rejected": 0.8163219690322876,
      "step": 2090
    },
    {
      "epoch": 1.4905928292509762,
      "grad_norm": 3.9275875091552734,
      "learning_rate": 7.25e-06,
      "logits/chosen": 338.6479797363281,
      "logits/rejected": 340.35284423828125,
      "logps/chosen": -188.20562744140625,
      "logps/rejected": -196.03353881835938,
      "loss": 2.8234,
      "nll_loss": 0.8237439393997192,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 1.6908737421035767,
      "rewards/margins": 0.9718906283378601,
      "rewards/rejected": 0.7189830541610718,
      "step": 2100
    },
    {
      "epoch": 1.4976925807596735,
      "grad_norm": 4.2383294105529785,
      "learning_rate": 7.225000000000001e-06,
      "logits/chosen": 337.144775390625,
      "logits/rejected": 338.16326904296875,
      "logps/chosen": -169.96127319335938,
      "logps/rejected": -179.99032592773438,
      "loss": 2.8776,
      "nll_loss": 0.7441676259040833,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": 1.3183850049972534,
      "rewards/margins": 0.05758192390203476,
      "rewards/rejected": 1.2608031034469604,
      "step": 2110
    },
    {
      "epoch": 1.5047923322683707,
      "grad_norm": 3.764956474304199,
      "learning_rate": 7.2000000000000005e-06,
      "logits/chosen": 340.46551513671875,
      "logits/rejected": 340.54656982421875,
      "logps/chosen": -185.3101043701172,
      "logps/rejected": -198.7221221923828,
      "loss": 2.7941,
      "nll_loss": 0.8249145746231079,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.8589147329330444,
      "rewards/margins": 0.927655041217804,
      "rewards/rejected": 0.9312599301338196,
      "step": 2120
    },
    {
      "epoch": 1.511892083777068,
      "grad_norm": 3.5011062622070312,
      "learning_rate": 7.175000000000001e-06,
      "logits/chosen": 338.3722229003906,
      "logits/rejected": 339.47650146484375,
      "logps/chosen": -169.7290496826172,
      "logps/rejected": -185.91732788085938,
      "loss": 2.6946,
      "nll_loss": 0.8101471662521362,
      "rewards/accuracies": 0.6312500238418579,
      "rewards/chosen": 2.0971059799194336,
      "rewards/margins": 1.8337215185165405,
      "rewards/rejected": 0.26338455080986023,
      "step": 2130
    },
    {
      "epoch": 1.518991835285765,
      "grad_norm": 3.983950614929199,
      "learning_rate": 7.15e-06,
      "logits/chosen": 341.56231689453125,
      "logits/rejected": 341.4192199707031,
      "logps/chosen": -199.72984313964844,
      "logps/rejected": -204.19302368164062,
      "loss": 2.916,
      "nll_loss": 0.8897363543510437,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.5964305400848389,
      "rewards/margins": 0.5889582633972168,
      "rewards/rejected": 1.007472276687622,
      "step": 2140
    },
    {
      "epoch": 1.5260915867944622,
      "grad_norm": 4.491429328918457,
      "learning_rate": 7.125e-06,
      "logits/chosen": 340.44573974609375,
      "logits/rejected": 341.6802062988281,
      "logps/chosen": -187.12820434570312,
      "logps/rejected": -196.89317321777344,
      "loss": 2.8362,
      "nll_loss": 0.8510099649429321,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 0.581689715385437,
      "rewards/margins": -0.14978042244911194,
      "rewards/rejected": 0.7314701080322266,
      "step": 2150
    },
    {
      "epoch": 1.5331913383031592,
      "grad_norm": 4.56249475479126,
      "learning_rate": 7.100000000000001e-06,
      "logits/chosen": 339.1760559082031,
      "logits/rejected": 341.2334899902344,
      "logps/chosen": -192.51039123535156,
      "logps/rejected": -208.7445831298828,
      "loss": 2.7208,
      "nll_loss": 0.8185786008834839,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.384587049484253,
      "rewards/margins": 0.9153262376785278,
      "rewards/rejected": 0.4692608416080475,
      "step": 2160
    },
    {
      "epoch": 1.5402910898118565,
      "grad_norm": 4.323859691619873,
      "learning_rate": 7.075000000000001e-06,
      "logits/chosen": 338.1593933105469,
      "logits/rejected": 339.64764404296875,
      "logps/chosen": -193.72927856445312,
      "logps/rejected": -207.046875,
      "loss": 2.8621,
      "nll_loss": 0.8017889261245728,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 2.063192367553711,
      "rewards/margins": 1.0307655334472656,
      "rewards/rejected": 1.0324270725250244,
      "step": 2170
    },
    {
      "epoch": 1.5473908413205537,
      "grad_norm": 5.197772979736328,
      "learning_rate": 7.05e-06,
      "logits/chosen": 337.7025146484375,
      "logits/rejected": 339.26068115234375,
      "logps/chosen": -180.05670166015625,
      "logps/rejected": -192.50634765625,
      "loss": 2.9229,
      "nll_loss": 0.7718768119812012,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": 2.1733591556549072,
      "rewards/margins": 1.3459341526031494,
      "rewards/rejected": 0.8274250030517578,
      "step": 2180
    },
    {
      "epoch": 1.554490592829251,
      "grad_norm": 3.753549575805664,
      "learning_rate": 7.0250000000000005e-06,
      "logits/chosen": 339.60723876953125,
      "logits/rejected": 339.82904052734375,
      "logps/chosen": -186.75572204589844,
      "logps/rejected": -191.36093139648438,
      "loss": 2.8455,
      "nll_loss": 0.8420035243034363,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.9427921772003174,
      "rewards/margins": 0.7964972257614136,
      "rewards/rejected": 1.146295189857483,
      "step": 2190
    },
    {
      "epoch": 1.5615903443379482,
      "grad_norm": 4.374830722808838,
      "learning_rate": 7e-06,
      "logits/chosen": 338.4313659667969,
      "logits/rejected": 339.8096923828125,
      "logps/chosen": -187.48681640625,
      "logps/rejected": -204.87741088867188,
      "loss": 2.8876,
      "nll_loss": 0.8476747274398804,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.312429666519165,
      "rewards/margins": 0.48655110597610474,
      "rewards/rejected": 0.8258785009384155,
      "step": 2200
    },
    {
      "epoch": 1.5686900958466454,
      "grad_norm": 4.045526504516602,
      "learning_rate": 6.975000000000001e-06,
      "logits/chosen": 340.04486083984375,
      "logits/rejected": 341.01409912109375,
      "logps/chosen": -199.83741760253906,
      "logps/rejected": -209.162841796875,
      "loss": 2.9057,
      "nll_loss": 0.8567794561386108,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.795781135559082,
      "rewards/margins": 0.543044924736023,
      "rewards/rejected": 1.252736210823059,
      "step": 2210
    },
    {
      "epoch": 1.5757898473553427,
      "grad_norm": 4.086952209472656,
      "learning_rate": 6.95e-06,
      "logits/chosen": 338.8799743652344,
      "logits/rejected": 339.6663513183594,
      "logps/chosen": -185.85316467285156,
      "logps/rejected": -195.4964141845703,
      "loss": 2.9864,
      "nll_loss": 0.8565464019775391,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.927323579788208,
      "rewards/margins": 1.0896047353744507,
      "rewards/rejected": 0.837718665599823,
      "step": 2220
    },
    {
      "epoch": 1.58288959886404,
      "grad_norm": 4.1491851806640625,
      "learning_rate": 6.925000000000001e-06,
      "logits/chosen": 339.8090515136719,
      "logits/rejected": 340.6795654296875,
      "logps/chosen": -200.73001098632812,
      "logps/rejected": -217.2935791015625,
      "loss": 2.8101,
      "nll_loss": 0.8561665415763855,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.309262752532959,
      "rewards/margins": 0.7470703125,
      "rewards/rejected": 0.562192440032959,
      "step": 2230
    },
    {
      "epoch": 1.589989350372737,
      "grad_norm": 3.8369624614715576,
      "learning_rate": 6.9e-06,
      "logits/chosen": 335.2975158691406,
      "logits/rejected": 337.4085388183594,
      "logps/chosen": -179.92910766601562,
      "logps/rejected": -201.29531860351562,
      "loss": 2.8634,
      "nll_loss": 0.7279912829399109,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.6663541793823242,
      "rewards/margins": 0.8383283615112305,
      "rewards/rejected": 0.8280259370803833,
      "step": 2240
    },
    {
      "epoch": 1.5970891018814342,
      "grad_norm": 4.670558452606201,
      "learning_rate": 6.875e-06,
      "logits/chosen": 338.9090881347656,
      "logits/rejected": 339.68353271484375,
      "logps/chosen": -198.06185913085938,
      "logps/rejected": -202.59764099121094,
      "loss": 2.8028,
      "nll_loss": 0.836604118347168,
      "rewards/accuracies": 0.46875,
      "rewards/chosen": 1.2865902185440063,
      "rewards/margins": -0.3076013922691345,
      "rewards/rejected": 1.5941916704177856,
      "step": 2250
    },
    {
      "epoch": 1.6041888533901314,
      "grad_norm": 4.042556285858154,
      "learning_rate": 6.850000000000001e-06,
      "logits/chosen": 339.0499267578125,
      "logits/rejected": 340.4635925292969,
      "logps/chosen": -197.92416381835938,
      "logps/rejected": -209.0960235595703,
      "loss": 2.7908,
      "nll_loss": 0.8338438272476196,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 1.4819467067718506,
      "rewards/margins": 1.612025499343872,
      "rewards/rejected": -0.1300785094499588,
      "step": 2260
    },
    {
      "epoch": 1.6112886048988284,
      "grad_norm": 5.00715446472168,
      "learning_rate": 6.825000000000001e-06,
      "logits/chosen": 338.68304443359375,
      "logits/rejected": 339.6430358886719,
      "logps/chosen": -180.3760528564453,
      "logps/rejected": -180.0961456298828,
      "loss": 2.9434,
      "nll_loss": 0.8089610934257507,
      "rewards/accuracies": 0.46875,
      "rewards/chosen": 1.4775396585464478,
      "rewards/margins": 0.4433348774909973,
      "rewards/rejected": 1.0342047214508057,
      "step": 2270
    },
    {
      "epoch": 1.6183883564075257,
      "grad_norm": 4.739441394805908,
      "learning_rate": 6.800000000000001e-06,
      "logits/chosen": 341.02886962890625,
      "logits/rejected": 341.0263671875,
      "logps/chosen": -191.4351806640625,
      "logps/rejected": -195.2884979248047,
      "loss": 2.7887,
      "nll_loss": 0.8733304738998413,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.5110198259353638,
      "rewards/margins": 0.757474958896637,
      "rewards/rejected": 0.7535446882247925,
      "step": 2280
    },
    {
      "epoch": 1.625488107916223,
      "grad_norm": 4.448541164398193,
      "learning_rate": 6.775e-06,
      "logits/chosen": 339.6402587890625,
      "logits/rejected": 339.46649169921875,
      "logps/chosen": -185.85919189453125,
      "logps/rejected": -195.8517608642578,
      "loss": 2.9181,
      "nll_loss": 0.824359118938446,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 1.184187889099121,
      "rewards/margins": 0.28512462973594666,
      "rewards/rejected": 0.8990631103515625,
      "step": 2290
    },
    {
      "epoch": 1.6325878594249201,
      "grad_norm": 4.708822727203369,
      "learning_rate": 6.750000000000001e-06,
      "logits/chosen": 340.45623779296875,
      "logits/rejected": 342.1158447265625,
      "logps/chosen": -208.27224731445312,
      "logps/rejected": -221.66098022460938,
      "loss": 2.8714,
      "nll_loss": 0.8661977052688599,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.572310209274292,
      "rewards/margins": 1.2384917736053467,
      "rewards/rejected": 0.3338184356689453,
      "step": 2300
    },
    {
      "epoch": 1.6396876109336174,
      "grad_norm": 4.299317359924316,
      "learning_rate": 6.725000000000001e-06,
      "logits/chosen": 339.6534118652344,
      "logits/rejected": 341.8071594238281,
      "logps/chosen": -204.01507568359375,
      "logps/rejected": -222.80728149414062,
      "loss": 2.8919,
      "nll_loss": 0.8600009679794312,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.3579275608062744,
      "rewards/margins": 0.8814895749092102,
      "rewards/rejected": 0.4764379560947418,
      "step": 2310
    },
    {
      "epoch": 1.6467873624423146,
      "grad_norm": 3.995805501937866,
      "learning_rate": 6.700000000000001e-06,
      "logits/chosen": 339.50164794921875,
      "logits/rejected": 340.3804931640625,
      "logps/chosen": -203.23553466796875,
      "logps/rejected": -211.17202758789062,
      "loss": 2.9182,
      "nll_loss": 0.8698709607124329,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.5807074308395386,
      "rewards/margins": 0.5118290185928345,
      "rewards/rejected": 1.0688786506652832,
      "step": 2320
    },
    {
      "epoch": 1.6538871139510118,
      "grad_norm": 4.604413032531738,
      "learning_rate": 6.6750000000000005e-06,
      "logits/chosen": 340.77850341796875,
      "logits/rejected": 341.48944091796875,
      "logps/chosen": -193.88821411132812,
      "logps/rejected": -196.88784790039062,
      "loss": 2.8319,
      "nll_loss": 0.8790038824081421,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 1.3346762657165527,
      "rewards/margins": 0.258357435464859,
      "rewards/rejected": 1.0763189792633057,
      "step": 2330
    },
    {
      "epoch": 1.6609868654597089,
      "grad_norm": 4.383596420288086,
      "learning_rate": 6.650000000000001e-06,
      "logits/chosen": 340.02606201171875,
      "logits/rejected": 342.00238037109375,
      "logps/chosen": -197.13449096679688,
      "logps/rejected": -215.6028289794922,
      "loss": 2.6702,
      "nll_loss": 0.8428922891616821,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 1.2990753650665283,
      "rewards/margins": 2.0131759643554688,
      "rewards/rejected": -0.7141008377075195,
      "step": 2340
    },
    {
      "epoch": 1.668086616968406,
      "grad_norm": 5.211791038513184,
      "learning_rate": 6.625e-06,
      "logits/chosen": 339.9574279785156,
      "logits/rejected": 341.1875,
      "logps/chosen": -184.55514526367188,
      "logps/rejected": -194.9544677734375,
      "loss": 2.6783,
      "nll_loss": 0.8363542556762695,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.225147008895874,
      "rewards/margins": 1.1645711660385132,
      "rewards/rejected": 0.06057582050561905,
      "step": 2350
    },
    {
      "epoch": 1.6751863684771033,
      "grad_norm": 3.293949842453003,
      "learning_rate": 6.600000000000001e-06,
      "logits/chosen": 339.16522216796875,
      "logits/rejected": 340.95172119140625,
      "logps/chosen": -185.77816772460938,
      "logps/rejected": -193.53469848632812,
      "loss": 2.6761,
      "nll_loss": 0.8441033363342285,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.3785488605499268,
      "rewards/margins": 1.4818028211593628,
      "rewards/rejected": -0.10325384140014648,
      "step": 2360
    },
    {
      "epoch": 1.6822861199858004,
      "grad_norm": 5.159486770629883,
      "learning_rate": 6.5750000000000006e-06,
      "logits/chosen": 341.27203369140625,
      "logits/rejected": 341.97955322265625,
      "logps/chosen": -199.73519897460938,
      "logps/rejected": -209.1084442138672,
      "loss": 2.9289,
      "nll_loss": 0.868370532989502,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.981981635093689,
      "rewards/margins": 0.7034223675727844,
      "rewards/rejected": 0.27855926752090454,
      "step": 2370
    },
    {
      "epoch": 1.6893858714944976,
      "grad_norm": 4.5351362228393555,
      "learning_rate": 6.550000000000001e-06,
      "logits/chosen": 342.0942687988281,
      "logits/rejected": 342.55096435546875,
      "logps/chosen": -213.174560546875,
      "logps/rejected": -221.4120635986328,
      "loss": 2.7968,
      "nll_loss": 0.894511878490448,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.1462312936782837,
      "rewards/margins": 0.9636276364326477,
      "rewards/rejected": 0.1826036423444748,
      "step": 2380
    },
    {
      "epoch": 1.6964856230031948,
      "grad_norm": 3.6160428524017334,
      "learning_rate": 6.525e-06,
      "logits/chosen": 340.28253173828125,
      "logits/rejected": 341.23004150390625,
      "logps/chosen": -191.4768829345703,
      "logps/rejected": -203.42015075683594,
      "loss": 2.7772,
      "nll_loss": 0.8751882314682007,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.1237510442733765,
      "rewards/margins": 1.002317190170288,
      "rewards/rejected": 0.12143383175134659,
      "step": 2390
    },
    {
      "epoch": 1.703585374511892,
      "grad_norm": 4.854567050933838,
      "learning_rate": 6.5000000000000004e-06,
      "logits/chosen": 340.7454528808594,
      "logits/rejected": 339.63372802734375,
      "logps/chosen": -204.5142059326172,
      "logps/rejected": -204.8683624267578,
      "loss": 2.9961,
      "nll_loss": 0.912934422492981,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.1511143445968628,
      "rewards/margins": 0.5846120119094849,
      "rewards/rejected": 0.5665022730827332,
      "step": 2400
    },
    {
      "epoch": 1.7106851260205893,
      "grad_norm": 3.5447070598602295,
      "learning_rate": 6.475e-06,
      "logits/chosen": 340.88153076171875,
      "logits/rejected": 342.928466796875,
      "logps/chosen": -207.8765869140625,
      "logps/rejected": -217.78695678710938,
      "loss": 2.8429,
      "nll_loss": 0.9049555063247681,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": 1.1860272884368896,
      "rewards/margins": 1.5689951181411743,
      "rewards/rejected": -0.3829677700996399,
      "step": 2410
    },
    {
      "epoch": 1.7177848775292865,
      "grad_norm": 4.151037216186523,
      "learning_rate": 6.450000000000001e-06,
      "logits/chosen": 338.282470703125,
      "logits/rejected": 340.0445251464844,
      "logps/chosen": -204.27223205566406,
      "logps/rejected": -211.774169921875,
      "loss": 2.8996,
      "nll_loss": 0.8197101354598999,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.2968767881393433,
      "rewards/margins": 0.9883058667182922,
      "rewards/rejected": 0.30857086181640625,
      "step": 2420
    },
    {
      "epoch": 1.7248846290379838,
      "grad_norm": 5.0619730949401855,
      "learning_rate": 6.425e-06,
      "logits/chosen": 340.27825927734375,
      "logits/rejected": 340.9788513183594,
      "logps/chosen": -186.89962768554688,
      "logps/rejected": -197.194091796875,
      "loss": 2.8564,
      "nll_loss": 0.8715068101882935,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.6302053928375244,
      "rewards/margins": 0.5800212025642395,
      "rewards/rejected": 1.0501841306686401,
      "step": 2430
    },
    {
      "epoch": 1.731984380546681,
      "grad_norm": 4.125449180603027,
      "learning_rate": 6.4000000000000006e-06,
      "logits/chosen": 338.29376220703125,
      "logits/rejected": 338.6551818847656,
      "logps/chosen": -182.90798950195312,
      "logps/rejected": -186.4722442626953,
      "loss": 2.8343,
      "nll_loss": 0.8339325189590454,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.2604597806930542,
      "rewards/margins": 0.35415029525756836,
      "rewards/rejected": 0.9063093066215515,
      "step": 2440
    },
    {
      "epoch": 1.739084132055378,
      "grad_norm": 4.3503804206848145,
      "learning_rate": 6.375e-06,
      "logits/chosen": 337.62750244140625,
      "logits/rejected": 339.7582702636719,
      "logps/chosen": -180.5191192626953,
      "logps/rejected": -193.59046936035156,
      "loss": 2.8454,
      "nll_loss": 0.7755412459373474,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.54691481590271,
      "rewards/margins": 0.5898535847663879,
      "rewards/rejected": 0.9570614099502563,
      "step": 2450
    },
    {
      "epoch": 1.7461838835640753,
      "grad_norm": 5.0330424308776855,
      "learning_rate": 6.35e-06,
      "logits/chosen": 338.7376403808594,
      "logits/rejected": 340.03228759765625,
      "logps/chosen": -184.84268188476562,
      "logps/rejected": -199.76922607421875,
      "loss": 2.8971,
      "nll_loss": 0.7978558540344238,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.5493834018707275,
      "rewards/margins": 0.6561684608459473,
      "rewards/rejected": 0.8932148218154907,
      "step": 2460
    },
    {
      "epoch": 1.7532836350727723,
      "grad_norm": 4.227469444274902,
      "learning_rate": 6.3250000000000004e-06,
      "logits/chosen": 340.5292663574219,
      "logits/rejected": 340.91949462890625,
      "logps/chosen": -199.91925048828125,
      "logps/rejected": -200.62576293945312,
      "loss": 2.9606,
      "nll_loss": 0.8883742094039917,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.7645902633666992,
      "rewards/margins": 1.4935247898101807,
      "rewards/rejected": 0.2710651755332947,
      "step": 2470
    },
    {
      "epoch": 1.7603833865814695,
      "grad_norm": 3.7661209106445312,
      "learning_rate": 6.300000000000001e-06,
      "logits/chosen": 339.3232421875,
      "logits/rejected": 340.7978210449219,
      "logps/chosen": -193.10389709472656,
      "logps/rejected": -199.18576049804688,
      "loss": 2.8132,
      "nll_loss": 0.8450847864151001,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 2.132969856262207,
      "rewards/margins": 1.3668221235275269,
      "rewards/rejected": 0.7661479115486145,
      "step": 2480
    },
    {
      "epoch": 1.7674831380901668,
      "grad_norm": 4.521320819854736,
      "learning_rate": 6.275e-06,
      "logits/chosen": 338.3802795410156,
      "logits/rejected": 338.8680725097656,
      "logps/chosen": -188.22769165039062,
      "logps/rejected": -190.7111053466797,
      "loss": 2.8568,
      "nll_loss": 0.8446177244186401,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": 1.640346884727478,
      "rewards/margins": 1.3404045104980469,
      "rewards/rejected": 0.2999423146247864,
      "step": 2490
    },
    {
      "epoch": 1.774582889598864,
      "grad_norm": 5.226047039031982,
      "learning_rate": 6.25e-06,
      "logits/chosen": 341.3248596191406,
      "logits/rejected": 342.25885009765625,
      "logps/chosen": -200.91493225097656,
      "logps/rejected": -203.79342651367188,
      "loss": 2.7822,
      "nll_loss": 0.9018969535827637,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.6564944982528687,
      "rewards/margins": 1.358184814453125,
      "rewards/rejected": 0.2983095943927765,
      "step": 2500
    },
    {
      "epoch": 1.7816826411075612,
      "grad_norm": 4.769329071044922,
      "learning_rate": 6.225000000000001e-06,
      "logits/chosen": 335.6601257324219,
      "logits/rejected": 336.1965026855469,
      "logps/chosen": -178.83447265625,
      "logps/rejected": -196.08755493164062,
      "loss": 2.825,
      "nll_loss": 0.7161829471588135,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.7040557861328125,
      "rewards/margins": 1.1330792903900146,
      "rewards/rejected": 0.5709764361381531,
      "step": 2510
    },
    {
      "epoch": 1.7887823926162585,
      "grad_norm": 5.494654178619385,
      "learning_rate": 6.200000000000001e-06,
      "logits/chosen": 338.4483947753906,
      "logits/rejected": 338.7321472167969,
      "logps/chosen": -184.84217834472656,
      "logps/rejected": -193.41741943359375,
      "loss": 2.9652,
      "nll_loss": 0.805963397026062,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.9241880178451538,
      "rewards/margins": 1.2446367740631104,
      "rewards/rejected": 0.6795514225959778,
      "step": 2520
    },
    {
      "epoch": 1.7958821441249557,
      "grad_norm": 4.796844005584717,
      "learning_rate": 6.175000000000001e-06,
      "logits/chosen": 338.01318359375,
      "logits/rejected": 338.7757568359375,
      "logps/chosen": -195.39501953125,
      "logps/rejected": -208.9003448486328,
      "loss": 2.995,
      "nll_loss": 0.8150683641433716,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.0119011402130127,
      "rewards/margins": 0.4853357672691345,
      "rewards/rejected": 0.526565432548523,
      "step": 2530
    },
    {
      "epoch": 1.802981895633653,
      "grad_norm": 5.802955627441406,
      "learning_rate": 6.15e-06,
      "logits/chosen": 339.6123046875,
      "logits/rejected": 341.50030517578125,
      "logps/chosen": -205.5465850830078,
      "logps/rejected": -212.1383056640625,
      "loss": 2.9709,
      "nll_loss": 0.853245735168457,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.067926287651062,
      "rewards/margins": 0.623855471611023,
      "rewards/rejected": 0.4440709054470062,
      "step": 2540
    },
    {
      "epoch": 1.81008164714235,
      "grad_norm": 3.950220823287964,
      "learning_rate": 6.125000000000001e-06,
      "logits/chosen": 338.6756286621094,
      "logits/rejected": 339.49969482421875,
      "logps/chosen": -180.18870544433594,
      "logps/rejected": -193.29379272460938,
      "loss": 2.7028,
      "nll_loss": 0.7989925146102905,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 2.5750229358673096,
      "rewards/margins": 1.9072482585906982,
      "rewards/rejected": 0.6677743792533875,
      "step": 2550
    },
    {
      "epoch": 1.8171813986510472,
      "grad_norm": 4.061397552490234,
      "learning_rate": 6.1e-06,
      "logits/chosen": 337.33673095703125,
      "logits/rejected": 340.0647888183594,
      "logps/chosen": -184.15423583984375,
      "logps/rejected": -196.95704650878906,
      "loss": 2.7529,
      "nll_loss": 0.8099324107170105,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.2053930759429932,
      "rewards/margins": 0.7754701375961304,
      "rewards/rejected": 0.4299229681491852,
      "step": 2560
    },
    {
      "epoch": 1.8242811501597445,
      "grad_norm": 4.68931770324707,
      "learning_rate": 6.075000000000001e-06,
      "logits/chosen": 337.2412109375,
      "logits/rejected": 340.8460693359375,
      "logps/chosen": -183.47933959960938,
      "logps/rejected": -207.5799102783203,
      "loss": 2.9817,
      "nll_loss": 0.752371609210968,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.6714643239974976,
      "rewards/margins": 0.7496611475944519,
      "rewards/rejected": 0.92180335521698,
      "step": 2570
    },
    {
      "epoch": 1.8313809016684415,
      "grad_norm": 5.562877655029297,
      "learning_rate": 6.0500000000000005e-06,
      "logits/chosen": 340.3011779785156,
      "logits/rejected": 341.5297546386719,
      "logps/chosen": -195.45199584960938,
      "logps/rejected": -214.1287384033203,
      "loss": 2.6834,
      "nll_loss": 0.8438652157783508,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": 2.193613290786743,
      "rewards/margins": 1.7661529779434204,
      "rewards/rejected": 0.4274604916572571,
      "step": 2580
    },
    {
      "epoch": 1.8384806531771387,
      "grad_norm": 4.747444152832031,
      "learning_rate": 6.025000000000001e-06,
      "logits/chosen": 336.8849182128906,
      "logits/rejected": 337.29083251953125,
      "logps/chosen": -175.71600341796875,
      "logps/rejected": -184.04196166992188,
      "loss": 2.7015,
      "nll_loss": 0.7730544805526733,
      "rewards/accuracies": 0.643750011920929,
      "rewards/chosen": 1.9386974573135376,
      "rewards/margins": 1.6363027095794678,
      "rewards/rejected": 0.3023946285247803,
      "step": 2590
    },
    {
      "epoch": 1.845580404685836,
      "grad_norm": 5.086993217468262,
      "learning_rate": 6e-06,
      "logits/chosen": 339.4365234375,
      "logits/rejected": 340.0769958496094,
      "logps/chosen": -199.113525390625,
      "logps/rejected": -202.37689208984375,
      "loss": 2.7825,
      "nll_loss": 0.8637831807136536,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.8589309453964233,
      "rewards/margins": 0.6582294702529907,
      "rewards/rejected": 1.2007014751434326,
      "step": 2600
    },
    {
      "epoch": 1.8526801561945332,
      "grad_norm": 3.923872232437134,
      "learning_rate": 5.975e-06,
      "logits/chosen": 338.24603271484375,
      "logits/rejected": 339.2802734375,
      "logps/chosen": -189.7838897705078,
      "logps/rejected": -203.1720428466797,
      "loss": 2.742,
      "nll_loss": 0.8100608587265015,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.4204323291778564,
      "rewards/margins": 1.3691990375518799,
      "rewards/rejected": 0.051233530044555664,
      "step": 2610
    },
    {
      "epoch": 1.8597799077032304,
      "grad_norm": 4.83229923248291,
      "learning_rate": 5.950000000000001e-06,
      "logits/chosen": 339.55328369140625,
      "logits/rejected": 340.8984680175781,
      "logps/chosen": -186.66647338867188,
      "logps/rejected": -191.05662536621094,
      "loss": 2.8618,
      "nll_loss": 0.8401314616203308,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.1002318859100342,
      "rewards/margins": 0.5242379903793335,
      "rewards/rejected": 0.575994074344635,
      "step": 2620
    },
    {
      "epoch": 1.8668796592119277,
      "grad_norm": 4.5694475173950195,
      "learning_rate": 5.925000000000001e-06,
      "logits/chosen": 342.12030029296875,
      "logits/rejected": 343.70062255859375,
      "logps/chosen": -216.631103515625,
      "logps/rejected": -228.6589813232422,
      "loss": 2.7653,
      "nll_loss": 0.9239271283149719,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": 1.000078797340393,
      "rewards/margins": 1.3964413404464722,
      "rewards/rejected": -0.3963627219200134,
      "step": 2630
    },
    {
      "epoch": 1.873979410720625,
      "grad_norm": 4.571382999420166,
      "learning_rate": 5.9e-06,
      "logits/chosen": 337.41668701171875,
      "logits/rejected": 338.77471923828125,
      "logps/chosen": -183.30215454101562,
      "logps/rejected": -193.54293823242188,
      "loss": 2.8589,
      "nll_loss": 0.7824704051017761,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.3734773397445679,
      "rewards/margins": 1.6594979763031006,
      "rewards/rejected": -0.2860206663608551,
      "step": 2640
    },
    {
      "epoch": 1.881079162229322,
      "grad_norm": 4.6198930740356445,
      "learning_rate": 5.8750000000000005e-06,
      "logits/chosen": 340.4710388183594,
      "logits/rejected": 341.9286193847656,
      "logps/chosen": -182.08636474609375,
      "logps/rejected": -193.72787475585938,
      "loss": 2.8018,
      "nll_loss": 0.8408993482589722,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 1.3032329082489014,
      "rewards/margins": 0.7208487391471863,
      "rewards/rejected": 0.5823842287063599,
      "step": 2650
    },
    {
      "epoch": 1.8881789137380192,
      "grad_norm": 4.494877338409424,
      "learning_rate": 5.85e-06,
      "logits/chosen": 338.9183044433594,
      "logits/rejected": 338.64276123046875,
      "logps/chosen": -186.8978729248047,
      "logps/rejected": -192.39706420898438,
      "loss": 2.7433,
      "nll_loss": 0.8044428825378418,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": 1.183127999305725,
      "rewards/margins": 0.037555672228336334,
      "rewards/rejected": 1.145572304725647,
      "step": 2660
    },
    {
      "epoch": 1.8952786652467164,
      "grad_norm": 4.227202892303467,
      "learning_rate": 5.825000000000001e-06,
      "logits/chosen": 339.76519775390625,
      "logits/rejected": 340.77667236328125,
      "logps/chosen": -198.0360870361328,
      "logps/rejected": -200.40109252929688,
      "loss": 2.8022,
      "nll_loss": 0.8480561971664429,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": 1.3639650344848633,
      "rewards/margins": 1.1576154232025146,
      "rewards/rejected": 0.20634973049163818,
      "step": 2670
    },
    {
      "epoch": 1.9023784167554134,
      "grad_norm": 4.477468013763428,
      "learning_rate": 5.8e-06,
      "logits/chosen": 340.46746826171875,
      "logits/rejected": 341.75225830078125,
      "logps/chosen": -198.99911499023438,
      "logps/rejected": -216.1954345703125,
      "loss": 2.8198,
      "nll_loss": 0.8712493181228638,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 2.0107293128967285,
      "rewards/margins": 1.5110938549041748,
      "rewards/rejected": 0.49963560700416565,
      "step": 2680
    },
    {
      "epoch": 1.9094781682641107,
      "grad_norm": 4.768120765686035,
      "learning_rate": 5.775000000000001e-06,
      "logits/chosen": 336.77911376953125,
      "logits/rejected": 337.80706787109375,
      "logps/chosen": -191.02044677734375,
      "logps/rejected": -201.69529724121094,
      "loss": 2.8554,
      "nll_loss": 0.760469913482666,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 2.130490303039551,
      "rewards/margins": 1.1356006860733032,
      "rewards/rejected": 0.9948896169662476,
      "step": 2690
    },
    {
      "epoch": 1.916577919772808,
      "grad_norm": 4.494722366333008,
      "learning_rate": 5.75e-06,
      "logits/chosen": 337.475341796875,
      "logits/rejected": 338.74273681640625,
      "logps/chosen": -191.59515380859375,
      "logps/rejected": -202.25169372558594,
      "loss": 2.6516,
      "nll_loss": 0.8079046010971069,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.76836359500885,
      "rewards/margins": 1.6297218799591064,
      "rewards/rejected": 0.13864177465438843,
      "step": 2700
    },
    {
      "epoch": 1.9236776712815051,
      "grad_norm": 4.518285751342773,
      "learning_rate": 5.725e-06,
      "logits/chosen": 338.82086181640625,
      "logits/rejected": 340.04156494140625,
      "logps/chosen": -194.2398223876953,
      "logps/rejected": -200.12802124023438,
      "loss": 2.889,
      "nll_loss": 0.8744741678237915,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.6186497211456299,
      "rewards/margins": 0.8760887980461121,
      "rewards/rejected": 0.7425609827041626,
      "step": 2710
    },
    {
      "epoch": 1.9307774227902024,
      "grad_norm": 4.439623832702637,
      "learning_rate": 5.7e-06,
      "logits/chosen": 336.0658874511719,
      "logits/rejected": 336.41546630859375,
      "logps/chosen": -170.47010803222656,
      "logps/rejected": -176.51065063476562,
      "loss": 2.8766,
      "nll_loss": 0.7717915177345276,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 2.1827712059020996,
      "rewards/margins": 0.9440290331840515,
      "rewards/rejected": 1.2387422323226929,
      "step": 2720
    },
    {
      "epoch": 1.9378771742988996,
      "grad_norm": 4.934340953826904,
      "learning_rate": 5.675000000000001e-06,
      "logits/chosen": 337.03594970703125,
      "logits/rejected": 338.3111572265625,
      "logps/chosen": -183.2435302734375,
      "logps/rejected": -196.44757080078125,
      "loss": 2.9439,
      "nll_loss": 0.8084403872489929,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 1.59892737865448,
      "rewards/margins": 1.2476874589920044,
      "rewards/rejected": 0.3512398302555084,
      "step": 2730
    },
    {
      "epoch": 1.9449769258075968,
      "grad_norm": 5.30368709564209,
      "learning_rate": 5.65e-06,
      "logits/chosen": 335.4336853027344,
      "logits/rejected": 336.68426513671875,
      "logps/chosen": -188.53936767578125,
      "logps/rejected": -200.960205078125,
      "loss": 2.663,
      "nll_loss": 0.7984800338745117,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 2.1918230056762695,
      "rewards/margins": 1.0128207206726074,
      "rewards/rejected": 1.1790021657943726,
      "step": 2740
    },
    {
      "epoch": 1.952076677316294,
      "grad_norm": 3.8601737022399902,
      "learning_rate": 5.625e-06,
      "logits/chosen": 337.69549560546875,
      "logits/rejected": 340.0099182128906,
      "logps/chosen": -180.45216369628906,
      "logps/rejected": -196.13331604003906,
      "loss": 2.6185,
      "nll_loss": 0.8080361485481262,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.8262771368026733,
      "rewards/margins": 1.5766193866729736,
      "rewards/rejected": 0.24965795874595642,
      "step": 2750
    },
    {
      "epoch": 1.959176428824991,
      "grad_norm": 4.39077615737915,
      "learning_rate": 5.600000000000001e-06,
      "logits/chosen": 336.29400634765625,
      "logits/rejected": 337.6388854980469,
      "logps/chosen": -174.48492431640625,
      "logps/rejected": -186.65353393554688,
      "loss": 2.6831,
      "nll_loss": 0.7891768217086792,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 2.2185003757476807,
      "rewards/margins": 1.3160542249679565,
      "rewards/rejected": 0.9024462699890137,
      "step": 2760
    },
    {
      "epoch": 1.9662761803336883,
      "grad_norm": 4.417272090911865,
      "learning_rate": 5.575000000000001e-06,
      "logits/chosen": 335.4423828125,
      "logits/rejected": 335.54461669921875,
      "logps/chosen": -191.1840057373047,
      "logps/rejected": -196.42596435546875,
      "loss": 2.8381,
      "nll_loss": 0.8063379526138306,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.9614566564559937,
      "rewards/margins": 0.6266731023788452,
      "rewards/rejected": 1.3347835540771484,
      "step": 2770
    },
    {
      "epoch": 1.9733759318423854,
      "grad_norm": 4.71718168258667,
      "learning_rate": 5.550000000000001e-06,
      "logits/chosen": 337.3692932128906,
      "logits/rejected": 339.5897216796875,
      "logps/chosen": -196.3211669921875,
      "logps/rejected": -209.6426239013672,
      "loss": 2.8245,
      "nll_loss": 0.8171440958976746,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.5734134912490845,
      "rewards/margins": 0.6132481694221497,
      "rewards/rejected": 0.9601653814315796,
      "step": 2780
    },
    {
      "epoch": 1.9804756833510826,
      "grad_norm": 5.278504371643066,
      "learning_rate": 5.5250000000000005e-06,
      "logits/chosen": 338.0802001953125,
      "logits/rejected": 339.2292785644531,
      "logps/chosen": -185.1862030029297,
      "logps/rejected": -196.9958953857422,
      "loss": 2.8273,
      "nll_loss": 0.7801715135574341,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.3791232109069824,
      "rewards/margins": 0.26543086767196655,
      "rewards/rejected": 1.1136924028396606,
      "step": 2790
    },
    {
      "epoch": 1.9875754348597798,
      "grad_norm": 4.658321857452393,
      "learning_rate": 5.500000000000001e-06,
      "logits/chosen": 338.41058349609375,
      "logits/rejected": 339.6219787597656,
      "logps/chosen": -186.66256713867188,
      "logps/rejected": -197.34603881835938,
      "loss": 2.6806,
      "nll_loss": 0.7836413979530334,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": 2.3026363849639893,
      "rewards/margins": 1.789018988609314,
      "rewards/rejected": 0.5136173963546753,
      "step": 2800
    },
    {
      "epoch": 1.994675186368477,
      "grad_norm": 3.7228968143463135,
      "learning_rate": 5.475e-06,
      "logits/chosen": 340.41064453125,
      "logits/rejected": 341.3620300292969,
      "logps/chosen": -203.5312957763672,
      "logps/rejected": -218.7999725341797,
      "loss": 2.8984,
      "nll_loss": 0.8704268336296082,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 1.910160779953003,
      "rewards/margins": 1.3369662761688232,
      "rewards/rejected": 0.5731943845748901,
      "step": 2810
    },
    {
      "epoch": 2.0014199503017394,
      "grad_norm": 6.649930477142334,
      "learning_rate": 5.450000000000001e-06,
      "logits/chosen": 340.22552490234375,
      "logits/rejected": 341.1056823730469,
      "logps/chosen": -201.43406677246094,
      "logps/rejected": -211.4611053466797,
      "loss": 2.6753,
      "nll_loss": 0.865116536617279,
      "rewards/accuracies": 0.5789473652839661,
      "rewards/chosen": 1.5225374698638916,
      "rewards/margins": 0.7002496719360352,
      "rewards/rejected": 0.8222877979278564,
      "step": 2820
    },
    {
      "epoch": 2.0085197018104366,
      "grad_norm": 6.4656805992126465,
      "learning_rate": 5.4250000000000006e-06,
      "logits/chosen": 338.3704528808594,
      "logits/rejected": 339.1483154296875,
      "logps/chosen": -203.35775756835938,
      "logps/rejected": -211.63943481445312,
      "loss": 2.6922,
      "nll_loss": 0.8724457025527954,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 2.3559327125549316,
      "rewards/margins": 1.626098871231079,
      "rewards/rejected": 0.7298339009284973,
      "step": 2830
    },
    {
      "epoch": 2.015619453319134,
      "grad_norm": 8.253189086914062,
      "learning_rate": 5.400000000000001e-06,
      "logits/chosen": 339.1753845214844,
      "logits/rejected": 340.439453125,
      "logps/chosen": -190.83883666992188,
      "logps/rejected": -202.263671875,
      "loss": 2.8522,
      "nll_loss": 0.8535490036010742,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.8023096323013306,
      "rewards/margins": 1.1489019393920898,
      "rewards/rejected": 0.6534077525138855,
      "step": 2840
    },
    {
      "epoch": 2.022719204827831,
      "grad_norm": 6.0219950675964355,
      "learning_rate": 5.375e-06,
      "logits/chosen": 339.08441162109375,
      "logits/rejected": 339.45623779296875,
      "logps/chosen": -190.9158477783203,
      "logps/rejected": -196.7988739013672,
      "loss": 2.777,
      "nll_loss": 0.8287941813468933,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.4699532985687256,
      "rewards/margins": 0.03904996067285538,
      "rewards/rejected": 1.430903434753418,
      "step": 2850
    },
    {
      "epoch": 2.0298189563365283,
      "grad_norm": 6.351048469543457,
      "learning_rate": 5.3500000000000004e-06,
      "logits/chosen": 336.5531311035156,
      "logits/rejected": 338.1964416503906,
      "logps/chosen": -194.4410400390625,
      "logps/rejected": -210.9767303466797,
      "loss": 2.8105,
      "nll_loss": 0.8423129916191101,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.4964685440063477,
      "rewards/margins": 0.8865699768066406,
      "rewards/rejected": 0.609898567199707,
      "step": 2860
    },
    {
      "epoch": 2.0369187078452256,
      "grad_norm": 6.335383415222168,
      "learning_rate": 5.325e-06,
      "logits/chosen": 336.77813720703125,
      "logits/rejected": 337.6108703613281,
      "logps/chosen": -181.70440673828125,
      "logps/rejected": -187.0491485595703,
      "loss": 2.8554,
      "nll_loss": 0.797600507736206,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.5750443935394287,
      "rewards/margins": 1.4804950952529907,
      "rewards/rejected": 0.0945492535829544,
      "step": 2870
    },
    {
      "epoch": 2.044018459353923,
      "grad_norm": 6.219535827636719,
      "learning_rate": 5.300000000000001e-06,
      "logits/chosen": 336.48651123046875,
      "logits/rejected": 338.98309326171875,
      "logps/chosen": -189.86021423339844,
      "logps/rejected": -205.35977172851562,
      "loss": 2.8403,
      "nll_loss": 0.7895963191986084,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.8044240474700928,
      "rewards/margins": 1.3744326829910278,
      "rewards/rejected": 0.42999157309532166,
      "step": 2880
    },
    {
      "epoch": 2.0511182108626196,
      "grad_norm": 6.002990245819092,
      "learning_rate": 5.275e-06,
      "logits/chosen": 336.5079650878906,
      "logits/rejected": 337.8755798339844,
      "logps/chosen": -191.62255859375,
      "logps/rejected": -213.7513427734375,
      "loss": 2.7299,
      "nll_loss": 0.7667266130447388,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 2.0164859294891357,
      "rewards/margins": 1.3516002893447876,
      "rewards/rejected": 0.6648856997489929,
      "step": 2890
    },
    {
      "epoch": 2.058217962371317,
      "grad_norm": 6.50872802734375,
      "learning_rate": 5.2500000000000006e-06,
      "logits/chosen": 338.0889587402344,
      "logits/rejected": 339.3222961425781,
      "logps/chosen": -178.86196899414062,
      "logps/rejected": -199.10302734375,
      "loss": 2.7822,
      "nll_loss": 0.8384788632392883,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.6979166269302368,
      "rewards/margins": 1.4406267404556274,
      "rewards/rejected": 0.2572900652885437,
      "step": 2900
    },
    {
      "epoch": 2.065317713880014,
      "grad_norm": 6.020150184631348,
      "learning_rate": 5.225e-06,
      "logits/chosen": 337.3924255371094,
      "logits/rejected": 337.95831298828125,
      "logps/chosen": -193.33338928222656,
      "logps/rejected": -205.07577514648438,
      "loss": 2.764,
      "nll_loss": 0.802613377571106,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.1948721408843994,
      "rewards/margins": 1.0788567066192627,
      "rewards/rejected": 0.11601565033197403,
      "step": 2910
    },
    {
      "epoch": 2.0724174653887113,
      "grad_norm": 7.961575508117676,
      "learning_rate": 5.2e-06,
      "logits/chosen": 337.45355224609375,
      "logits/rejected": 338.36920166015625,
      "logps/chosen": -186.5419158935547,
      "logps/rejected": -196.2751007080078,
      "loss": 2.852,
      "nll_loss": 0.8361884951591492,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 2.067657947540283,
      "rewards/margins": 1.5992196798324585,
      "rewards/rejected": 0.46843844652175903,
      "step": 2920
    },
    {
      "epoch": 2.0795172168974085,
      "grad_norm": 6.255530834197998,
      "learning_rate": 5.1750000000000004e-06,
      "logits/chosen": 337.82794189453125,
      "logits/rejected": 339.89801025390625,
      "logps/chosen": -189.2049560546875,
      "logps/rejected": -200.57772827148438,
      "loss": 2.6286,
      "nll_loss": 0.8333569765090942,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.474013328552246,
      "rewards/margins": 0.8312456011772156,
      "rewards/rejected": 0.6427677273750305,
      "step": 2930
    },
    {
      "epoch": 2.0866169684061058,
      "grad_norm": 6.73351526260376,
      "learning_rate": 5.150000000000001e-06,
      "logits/chosen": 338.2623291015625,
      "logits/rejected": 339.8560791015625,
      "logps/chosen": -186.25625610351562,
      "logps/rejected": -196.50161743164062,
      "loss": 2.7525,
      "nll_loss": 0.8457567095756531,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 1.323583960533142,
      "rewards/margins": 1.6934778690338135,
      "rewards/rejected": -0.36989378929138184,
      "step": 2940
    },
    {
      "epoch": 2.093716719914803,
      "grad_norm": 6.810431957244873,
      "learning_rate": 5.125e-06,
      "logits/chosen": 338.1629943847656,
      "logits/rejected": 339.59552001953125,
      "logps/chosen": -177.9695587158203,
      "logps/rejected": -188.19081115722656,
      "loss": 2.7959,
      "nll_loss": 0.7879065871238708,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.8421850204467773,
      "rewards/margins": 1.3119806051254272,
      "rewards/rejected": 0.5302042961120605,
      "step": 2950
    },
    {
      "epoch": 2.1008164714235003,
      "grad_norm": 7.6270647048950195,
      "learning_rate": 5.1e-06,
      "logits/chosen": 336.6476135253906,
      "logits/rejected": 338.1829833984375,
      "logps/chosen": -173.51846313476562,
      "logps/rejected": -191.22850036621094,
      "loss": 2.8983,
      "nll_loss": 0.7603787183761597,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.698399305343628,
      "rewards/margins": 1.0755308866500854,
      "rewards/rejected": 0.6228684186935425,
      "step": 2960
    },
    {
      "epoch": 2.1079162229321975,
      "grad_norm": 6.18328332901001,
      "learning_rate": 5.075e-06,
      "logits/chosen": 338.3467712402344,
      "logits/rejected": 339.3258056640625,
      "logps/chosen": -180.65476989746094,
      "logps/rejected": -190.42132568359375,
      "loss": 2.9439,
      "nll_loss": 0.8315478563308716,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 1.652014970779419,
      "rewards/margins": 1.7233995199203491,
      "rewards/rejected": -0.07138463109731674,
      "step": 2970
    },
    {
      "epoch": 2.1150159744408947,
      "grad_norm": 7.5503997802734375,
      "learning_rate": 5.050000000000001e-06,
      "logits/chosen": 339.68267822265625,
      "logits/rejected": 340.8587646484375,
      "logps/chosen": -191.2299041748047,
      "logps/rejected": -199.02650451660156,
      "loss": 2.8793,
      "nll_loss": 0.8554391860961914,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.6546472311019897,
      "rewards/margins": 0.7542393207550049,
      "rewards/rejected": 0.9004079699516296,
      "step": 2980
    },
    {
      "epoch": 2.122115725949592,
      "grad_norm": 6.4292802810668945,
      "learning_rate": 5.025e-06,
      "logits/chosen": 340.57769775390625,
      "logits/rejected": 340.8563232421875,
      "logps/chosen": -185.82418823242188,
      "logps/rejected": -197.80960083007812,
      "loss": 2.7472,
      "nll_loss": 0.876988410949707,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.5552449226379395,
      "rewards/margins": 0.9224251508712769,
      "rewards/rejected": 0.6328197121620178,
      "step": 2990
    },
    {
      "epoch": 2.1292154774582888,
      "grad_norm": 6.973447799682617,
      "learning_rate": 5e-06,
      "logits/chosen": 335.78179931640625,
      "logits/rejected": 338.6295166015625,
      "logps/chosen": -184.24884033203125,
      "logps/rejected": -195.6201629638672,
      "loss": 2.8034,
      "nll_loss": 0.769730806350708,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 2.1467854976654053,
      "rewards/margins": 1.704965591430664,
      "rewards/rejected": 0.4418201446533203,
      "step": 3000
    },
    {
      "epoch": 2.136315228966986,
      "grad_norm": 6.35395622253418,
      "learning_rate": 4.975000000000001e-06,
      "logits/chosen": 338.13909912109375,
      "logits/rejected": 339.73974609375,
      "logps/chosen": -199.80691528320312,
      "logps/rejected": -212.4320831298828,
      "loss": 2.7849,
      "nll_loss": 0.8573581576347351,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.8233482837677002,
      "rewards/margins": 1.2611969709396362,
      "rewards/rejected": 0.562151312828064,
      "step": 3010
    },
    {
      "epoch": 2.1434149804756832,
      "grad_norm": 7.220670700073242,
      "learning_rate": 4.95e-06,
      "logits/chosen": 338.97406005859375,
      "logits/rejected": 340.09674072265625,
      "logps/chosen": -202.9422149658203,
      "logps/rejected": -208.3765106201172,
      "loss": 2.9443,
      "nll_loss": 0.8720341920852661,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 2.0211119651794434,
      "rewards/margins": 0.916876494884491,
      "rewards/rejected": 1.1042357683181763,
      "step": 3020
    },
    {
      "epoch": 2.1505147319843805,
      "grad_norm": 6.784775257110596,
      "learning_rate": 4.925e-06,
      "logits/chosen": 336.916259765625,
      "logits/rejected": 336.8017272949219,
      "logps/chosen": -193.69894409179688,
      "logps/rejected": -193.10482788085938,
      "loss": 2.7302,
      "nll_loss": 0.8243916630744934,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 2.1299710273742676,
      "rewards/margins": 1.041722059249878,
      "rewards/rejected": 1.0882489681243896,
      "step": 3030
    },
    {
      "epoch": 2.1576144834930777,
      "grad_norm": 6.283402442932129,
      "learning_rate": 4.9000000000000005e-06,
      "logits/chosen": 337.2030944824219,
      "logits/rejected": 337.13836669921875,
      "logps/chosen": -189.13018798828125,
      "logps/rejected": -196.2104034423828,
      "loss": 2.8767,
      "nll_loss": 0.8488901853561401,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 2.171781063079834,
      "rewards/margins": 1.3933972120285034,
      "rewards/rejected": 0.7783840298652649,
      "step": 3040
    },
    {
      "epoch": 2.164714235001775,
      "grad_norm": 8.046265602111816,
      "learning_rate": 4.875e-06,
      "logits/chosen": 336.6136169433594,
      "logits/rejected": 336.5774841308594,
      "logps/chosen": -194.9586639404297,
      "logps/rejected": -200.62786865234375,
      "loss": 2.865,
      "nll_loss": 0.809927761554718,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.866351842880249,
      "rewards/margins": 0.905900776386261,
      "rewards/rejected": 0.9604510068893433,
      "step": 3050
    },
    {
      "epoch": 2.171813986510472,
      "grad_norm": 8.044671058654785,
      "learning_rate": 4.85e-06,
      "logits/chosen": 337.8675231933594,
      "logits/rejected": 338.11737060546875,
      "logps/chosen": -186.07516479492188,
      "logps/rejected": -194.80149841308594,
      "loss": 2.8285,
      "nll_loss": 0.8159818649291992,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 2.5346853733062744,
      "rewards/margins": 1.8488441705703735,
      "rewards/rejected": 0.6858410835266113,
      "step": 3060
    },
    {
      "epoch": 2.1789137380191694,
      "grad_norm": 6.216785907745361,
      "learning_rate": 4.825e-06,
      "logits/chosen": 336.0094299316406,
      "logits/rejected": 338.00872802734375,
      "logps/chosen": -183.9812469482422,
      "logps/rejected": -199.00677490234375,
      "loss": 2.6466,
      "nll_loss": 0.7834295034408569,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": 2.0025899410247803,
      "rewards/margins": 1.1618435382843018,
      "rewards/rejected": 0.8407465219497681,
      "step": 3070
    },
    {
      "epoch": 2.1860134895278667,
      "grad_norm": 6.917819976806641,
      "learning_rate": 4.800000000000001e-06,
      "logits/chosen": 337.5904541015625,
      "logits/rejected": 338.65606689453125,
      "logps/chosen": -195.59104919433594,
      "logps/rejected": -199.8016357421875,
      "loss": 2.6601,
      "nll_loss": 0.8599584698677063,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 1.6080608367919922,
      "rewards/margins": 1.1667606830596924,
      "rewards/rejected": 0.44130030274391174,
      "step": 3080
    },
    {
      "epoch": 2.193113241036564,
      "grad_norm": 8.147022247314453,
      "learning_rate": 4.775e-06,
      "logits/chosen": 337.65155029296875,
      "logits/rejected": 339.36468505859375,
      "logps/chosen": -192.23675537109375,
      "logps/rejected": -201.2091522216797,
      "loss": 2.6939,
      "nll_loss": 0.8482862710952759,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": 1.9912809133529663,
      "rewards/margins": 1.502177357673645,
      "rewards/rejected": 0.48910364508628845,
      "step": 3090
    },
    {
      "epoch": 2.2002129925452607,
      "grad_norm": 6.305619716644287,
      "learning_rate": 4.75e-06,
      "logits/chosen": 337.51824951171875,
      "logits/rejected": 339.3320007324219,
      "logps/chosen": -196.8864288330078,
      "logps/rejected": -211.55166625976562,
      "loss": 2.7065,
      "nll_loss": 0.8132200241088867,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": 2.1470370292663574,
      "rewards/margins": 1.4659408330917358,
      "rewards/rejected": 0.6810958385467529,
      "step": 3100
    },
    {
      "epoch": 2.207312744053958,
      "grad_norm": 5.906151294708252,
      "learning_rate": 4.7250000000000005e-06,
      "logits/chosen": 337.7591247558594,
      "logits/rejected": 337.9073791503906,
      "logps/chosen": -182.80255126953125,
      "logps/rejected": -191.98574829101562,
      "loss": 2.847,
      "nll_loss": 0.8195177912712097,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.5018745064735413,
      "rewards/margins": 0.3405170440673828,
      "rewards/rejected": 0.16135749220848083,
      "step": 3110
    },
    {
      "epoch": 2.214412495562655,
      "grad_norm": 7.550755500793457,
      "learning_rate": 4.7e-06,
      "logits/chosen": 337.72247314453125,
      "logits/rejected": 339.58367919921875,
      "logps/chosen": -190.0835723876953,
      "logps/rejected": -200.66000366210938,
      "loss": 2.8429,
      "nll_loss": 0.8019811511039734,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 2.045396327972412,
      "rewards/margins": 1.4005556106567383,
      "rewards/rejected": 0.644840657711029,
      "step": 3120
    },
    {
      "epoch": 2.2215122470713524,
      "grad_norm": 7.5966620445251465,
      "learning_rate": 4.675000000000001e-06,
      "logits/chosen": 335.79315185546875,
      "logits/rejected": 338.7310485839844,
      "logps/chosen": -186.5257110595703,
      "logps/rejected": -196.25314331054688,
      "loss": 2.7796,
      "nll_loss": 0.7932634949684143,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.2909518480300903,
      "rewards/margins": 0.6933327913284302,
      "rewards/rejected": 0.5976190567016602,
      "step": 3130
    },
    {
      "epoch": 2.2286119985800497,
      "grad_norm": 6.0841450691223145,
      "learning_rate": 4.65e-06,
      "logits/chosen": 338.5928039550781,
      "logits/rejected": 339.23040771484375,
      "logps/chosen": -202.02609252929688,
      "logps/rejected": -202.8081512451172,
      "loss": 2.9164,
      "nll_loss": 0.8386465311050415,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 1.6106971502304077,
      "rewards/margins": 0.07013096660375595,
      "rewards/rejected": 1.540566086769104,
      "step": 3140
    },
    {
      "epoch": 2.235711750088747,
      "grad_norm": 6.867880821228027,
      "learning_rate": 4.625000000000001e-06,
      "logits/chosen": 338.4112243652344,
      "logits/rejected": 338.8937683105469,
      "logps/chosen": -192.50967407226562,
      "logps/rejected": -198.69436645507812,
      "loss": 2.696,
      "nll_loss": 0.862527072429657,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 1.9039065837860107,
      "rewards/margins": 1.521436095237732,
      "rewards/rejected": 0.38247039914131165,
      "step": 3150
    },
    {
      "epoch": 2.242811501597444,
      "grad_norm": 7.2652411460876465,
      "learning_rate": 4.600000000000001e-06,
      "logits/chosen": 338.27923583984375,
      "logits/rejected": 338.406005859375,
      "logps/chosen": -197.91494750976562,
      "logps/rejected": -199.79046630859375,
      "loss": 2.9718,
      "nll_loss": 0.8353233337402344,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 1.3665534257888794,
      "rewards/margins": 0.6899369359016418,
      "rewards/rejected": 0.6766166687011719,
      "step": 3160
    },
    {
      "epoch": 2.2499112531061414,
      "grad_norm": 6.580617427825928,
      "learning_rate": 4.575e-06,
      "logits/chosen": 337.1618957519531,
      "logits/rejected": 337.44464111328125,
      "logps/chosen": -189.1826171875,
      "logps/rejected": -194.4853057861328,
      "loss": 2.7797,
      "nll_loss": 0.8360779881477356,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.8415123224258423,
      "rewards/margins": 0.6849167943000793,
      "rewards/rejected": 1.1565954685211182,
      "step": 3170
    },
    {
      "epoch": 2.2570110046148386,
      "grad_norm": 7.352388381958008,
      "learning_rate": 4.5500000000000005e-06,
      "logits/chosen": 337.3443908691406,
      "logits/rejected": 338.82891845703125,
      "logps/chosen": -183.83712768554688,
      "logps/rejected": -189.80520629882812,
      "loss": 2.9044,
      "nll_loss": 0.8134455680847168,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.8833324909210205,
      "rewards/margins": 0.8923762440681458,
      "rewards/rejected": 0.9909563064575195,
      "step": 3180
    },
    {
      "epoch": 2.264110756123536,
      "grad_norm": 6.6188154220581055,
      "learning_rate": 4.525000000000001e-06,
      "logits/chosen": 337.65533447265625,
      "logits/rejected": 337.54730224609375,
      "logps/chosen": -192.34854125976562,
      "logps/rejected": -192.97265625,
      "loss": 2.7944,
      "nll_loss": 0.834528923034668,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 1.7544834613800049,
      "rewards/margins": 1.1298209428787231,
      "rewards/rejected": 0.6246623992919922,
      "step": 3190
    },
    {
      "epoch": 2.271210507632233,
      "grad_norm": 6.905961513519287,
      "learning_rate": 4.5e-06,
      "logits/chosen": 338.1758728027344,
      "logits/rejected": 338.86395263671875,
      "logps/chosen": -199.1695556640625,
      "logps/rejected": -204.26844787597656,
      "loss": 2.9572,
      "nll_loss": 0.8454689979553223,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 1.9871037006378174,
      "rewards/margins": 0.6156911849975586,
      "rewards/rejected": 1.3714125156402588,
      "step": 3200
    },
    {
      "epoch": 2.27831025914093,
      "grad_norm": 6.586306095123291,
      "learning_rate": 4.475e-06,
      "logits/chosen": 337.53436279296875,
      "logits/rejected": 337.95892333984375,
      "logps/chosen": -198.47329711914062,
      "logps/rejected": -203.36050415039062,
      "loss": 2.8699,
      "nll_loss": 0.8610361218452454,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 2.317817449569702,
      "rewards/margins": 1.401957392692566,
      "rewards/rejected": 0.9158603549003601,
      "step": 3210
    },
    {
      "epoch": 2.285410010649627,
      "grad_norm": 8.446084976196289,
      "learning_rate": 4.450000000000001e-06,
      "logits/chosen": 334.6370849609375,
      "logits/rejected": 336.78839111328125,
      "logps/chosen": -176.47657775878906,
      "logps/rejected": -184.2322235107422,
      "loss": 2.9105,
      "nll_loss": 0.8012210130691528,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 2.177464485168457,
      "rewards/margins": 0.9891023635864258,
      "rewards/rejected": 1.1883618831634521,
      "step": 3220
    },
    {
      "epoch": 2.2925097621583244,
      "grad_norm": 7.34524393081665,
      "learning_rate": 4.425e-06,
      "logits/chosen": 336.03277587890625,
      "logits/rejected": 338.20458984375,
      "logps/chosen": -176.0439910888672,
      "logps/rejected": -189.95010375976562,
      "loss": 2.7099,
      "nll_loss": 0.7713911533355713,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.8437042236328125,
      "rewards/margins": 1.0651291608810425,
      "rewards/rejected": 0.7785750031471252,
      "step": 3230
    },
    {
      "epoch": 2.2996095136670216,
      "grad_norm": 7.384006023406982,
      "learning_rate": 4.4e-06,
      "logits/chosen": 337.92486572265625,
      "logits/rejected": 339.1449890136719,
      "logps/chosen": -189.76150512695312,
      "logps/rejected": -200.68276977539062,
      "loss": 2.8311,
      "nll_loss": 0.8426225781440735,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 1.9568579196929932,
      "rewards/margins": 1.6576251983642578,
      "rewards/rejected": 0.2992328107357025,
      "step": 3240
    },
    {
      "epoch": 2.306709265175719,
      "grad_norm": 7.053637981414795,
      "learning_rate": 4.3750000000000005e-06,
      "logits/chosen": 338.0697937011719,
      "logits/rejected": 339.46966552734375,
      "logps/chosen": -202.85809326171875,
      "logps/rejected": -213.9791259765625,
      "loss": 2.8444,
      "nll_loss": 0.8449970483779907,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 2.05208158493042,
      "rewards/margins": 1.6686912775039673,
      "rewards/rejected": 0.3833901584148407,
      "step": 3250
    },
    {
      "epoch": 2.313809016684416,
      "grad_norm": 7.056214332580566,
      "learning_rate": 4.350000000000001e-06,
      "logits/chosen": 336.8259582519531,
      "logits/rejected": 337.8714294433594,
      "logps/chosen": -187.63327026367188,
      "logps/rejected": -199.30523681640625,
      "loss": 2.8026,
      "nll_loss": 0.776067852973938,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 1.8962469100952148,
      "rewards/margins": 1.0500507354736328,
      "rewards/rejected": 0.8461960554122925,
      "step": 3260
    },
    {
      "epoch": 2.3209087681931133,
      "grad_norm": 7.1373982429504395,
      "learning_rate": 4.325e-06,
      "logits/chosen": 338.7446594238281,
      "logits/rejected": 339.5546569824219,
      "logps/chosen": -192.12420654296875,
      "logps/rejected": -201.1350555419922,
      "loss": 2.9193,
      "nll_loss": 0.8693065643310547,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.4013054370880127,
      "rewards/margins": 1.2665973901748657,
      "rewards/rejected": 0.13470812141895294,
      "step": 3270
    },
    {
      "epoch": 2.3280085197018106,
      "grad_norm": 7.455770015716553,
      "learning_rate": 4.3e-06,
      "logits/chosen": 339.05780029296875,
      "logits/rejected": 339.608154296875,
      "logps/chosen": -193.9559783935547,
      "logps/rejected": -200.74234008789062,
      "loss": 2.8613,
      "nll_loss": 0.9060068130493164,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.6107896566390991,
      "rewards/margins": 1.285523533821106,
      "rewards/rejected": 0.32526618242263794,
      "step": 3280
    },
    {
      "epoch": 2.335108271210508,
      "grad_norm": 6.78982400894165,
      "learning_rate": 4.2750000000000006e-06,
      "logits/chosen": 335.5394287109375,
      "logits/rejected": 337.45684814453125,
      "logps/chosen": -170.1770782470703,
      "logps/rejected": -185.6390380859375,
      "loss": 2.8274,
      "nll_loss": 0.761805534362793,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.7350082397460938,
      "rewards/margins": 1.0143744945526123,
      "rewards/rejected": 0.7206336855888367,
      "step": 3290
    },
    {
      "epoch": 2.3422080227192046,
      "grad_norm": 6.692729949951172,
      "learning_rate": 4.25e-06,
      "logits/chosen": 335.7712097167969,
      "logits/rejected": 337.28485107421875,
      "logps/chosen": -187.69973754882812,
      "logps/rejected": -199.880615234375,
      "loss": 2.7484,
      "nll_loss": 0.789789617061615,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.831632375717163,
      "rewards/margins": 1.020714282989502,
      "rewards/rejected": 0.8109182119369507,
      "step": 3300
    },
    {
      "epoch": 2.349307774227902,
      "grad_norm": 7.700042247772217,
      "learning_rate": 4.225e-06,
      "logits/chosen": 336.6248474121094,
      "logits/rejected": 337.46746826171875,
      "logps/chosen": -189.98915100097656,
      "logps/rejected": -188.72828674316406,
      "loss": 2.8068,
      "nll_loss": 0.8262639045715332,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 1.475714921951294,
      "rewards/margins": 1.3995482921600342,
      "rewards/rejected": 0.07616646587848663,
      "step": 3310
    },
    {
      "epoch": 2.356407525736599,
      "grad_norm": 7.980506896972656,
      "learning_rate": 4.2000000000000004e-06,
      "logits/chosen": 336.51708984375,
      "logits/rejected": 337.4078674316406,
      "logps/chosen": -190.04034423828125,
      "logps/rejected": -196.3818817138672,
      "loss": 2.7287,
      "nll_loss": 0.8076073527336121,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 2.8776941299438477,
      "rewards/margins": 1.8042757511138916,
      "rewards/rejected": 1.073418378829956,
      "step": 3320
    },
    {
      "epoch": 2.3635072772452963,
      "grad_norm": 8.473715782165527,
      "learning_rate": 4.175e-06,
      "logits/chosen": 336.27874755859375,
      "logits/rejected": 337.45697021484375,
      "logps/chosen": -181.83856201171875,
      "logps/rejected": -197.29623413085938,
      "loss": 2.9405,
      "nll_loss": 0.7752479314804077,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.8531110286712646,
      "rewards/margins": 0.7504945993423462,
      "rewards/rejected": 1.1026164293289185,
      "step": 3330
    },
    {
      "epoch": 2.3706070287539935,
      "grad_norm": 6.5492472648620605,
      "learning_rate": 4.15e-06,
      "logits/chosen": 339.61883544921875,
      "logits/rejected": 340.75390625,
      "logps/chosen": -198.71487426757812,
      "logps/rejected": -208.64013671875,
      "loss": 2.7811,
      "nll_loss": 0.8625701665878296,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.5597600936889648,
      "rewards/margins": 1.4088594913482666,
      "rewards/rejected": 0.1509006917476654,
      "step": 3340
    },
    {
      "epoch": 2.3777067802626908,
      "grad_norm": 6.8476457595825195,
      "learning_rate": 4.125e-06,
      "logits/chosen": 338.05859375,
      "logits/rejected": 338.42413330078125,
      "logps/chosen": -174.26194763183594,
      "logps/rejected": -190.47799682617188,
      "loss": 2.8036,
      "nll_loss": 0.7838207483291626,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.7645565271377563,
      "rewards/margins": 1.2112812995910645,
      "rewards/rejected": 0.5532749891281128,
      "step": 3350
    },
    {
      "epoch": 2.384806531771388,
      "grad_norm": 6.6104888916015625,
      "learning_rate": 4.1e-06,
      "logits/chosen": 337.85919189453125,
      "logits/rejected": 339.23675537109375,
      "logps/chosen": -181.91561889648438,
      "logps/rejected": -190.37840270996094,
      "loss": 2.809,
      "nll_loss": 0.8501696586608887,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.7742723226547241,
      "rewards/margins": 0.8752438426017761,
      "rewards/rejected": 0.8990286588668823,
      "step": 3360
    },
    {
      "epoch": 2.3919062832800853,
      "grad_norm": 7.036422252655029,
      "learning_rate": 4.075e-06,
      "logits/chosen": 338.171142578125,
      "logits/rejected": 339.91949462890625,
      "logps/chosen": -184.46319580078125,
      "logps/rejected": -190.17062377929688,
      "loss": 2.8058,
      "nll_loss": 0.8584386110305786,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 1.7083396911621094,
      "rewards/margins": 0.5877594351768494,
      "rewards/rejected": 1.1205801963806152,
      "step": 3370
    },
    {
      "epoch": 2.3990060347887825,
      "grad_norm": 6.610972881317139,
      "learning_rate": 4.05e-06,
      "logits/chosen": 337.28302001953125,
      "logits/rejected": 338.4544677734375,
      "logps/chosen": -205.1033477783203,
      "logps/rejected": -219.12460327148438,
      "loss": 2.7612,
      "nll_loss": 0.8239673376083374,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.576812982559204,
      "rewards/margins": 1.6657764911651611,
      "rewards/rejected": -0.08896342664957047,
      "step": 3380
    },
    {
      "epoch": 2.4061057862974797,
      "grad_norm": 7.076844692230225,
      "learning_rate": 4.0250000000000004e-06,
      "logits/chosen": 338.79998779296875,
      "logits/rejected": 340.15313720703125,
      "logps/chosen": -200.1719970703125,
      "logps/rejected": -217.45730590820312,
      "loss": 2.7891,
      "nll_loss": 0.8369544744491577,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.9101932048797607,
      "rewards/margins": 0.8211032152175903,
      "rewards/rejected": 1.08909010887146,
      "step": 3390
    },
    {
      "epoch": 2.413205537806177,
      "grad_norm": 7.751204967498779,
      "learning_rate": 4.000000000000001e-06,
      "logits/chosen": 339.3271179199219,
      "logits/rejected": 341.0967712402344,
      "logps/chosen": -196.74832153320312,
      "logps/rejected": -207.22897338867188,
      "loss": 2.8238,
      "nll_loss": 0.8755576014518738,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 2.0102500915527344,
      "rewards/margins": 1.9327213764190674,
      "rewards/rejected": 0.07752861827611923,
      "step": 3400
    },
    {
      "epoch": 2.420305289314874,
      "grad_norm": 7.989264965057373,
      "learning_rate": 3.975000000000001e-06,
      "logits/chosen": 336.49871826171875,
      "logits/rejected": 337.1164245605469,
      "logps/chosen": -194.3582763671875,
      "logps/rejected": -202.37185668945312,
      "loss": 2.9488,
      "nll_loss": 0.8119075894355774,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.9115928411483765,
      "rewards/margins": 0.598547637462616,
      "rewards/rejected": 1.3130452632904053,
      "step": 3410
    },
    {
      "epoch": 2.427405040823571,
      "grad_norm": 7.983441352844238,
      "learning_rate": 3.95e-06,
      "logits/chosen": 336.80950927734375,
      "logits/rejected": 339.1780090332031,
      "logps/chosen": -197.3321533203125,
      "logps/rejected": -216.4013214111328,
      "loss": 2.768,
      "nll_loss": 0.8186818957328796,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.9388010501861572,
      "rewards/margins": 0.8670732378959656,
      "rewards/rejected": 1.0717278718948364,
      "step": 3420
    },
    {
      "epoch": 2.4345047923322682,
      "grad_norm": 8.062889099121094,
      "learning_rate": 3.9250000000000005e-06,
      "logits/chosen": 338.10107421875,
      "logits/rejected": 338.66094970703125,
      "logps/chosen": -196.94723510742188,
      "logps/rejected": -208.20401000976562,
      "loss": 2.8628,
      "nll_loss": 0.8538459539413452,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 1.4812816381454468,
      "rewards/margins": 0.7507460117340088,
      "rewards/rejected": 0.730535626411438,
      "step": 3430
    },
    {
      "epoch": 2.4416045438409655,
      "grad_norm": 7.205513954162598,
      "learning_rate": 3.900000000000001e-06,
      "logits/chosen": 336.942626953125,
      "logits/rejected": 337.0449523925781,
      "logps/chosen": -193.82827758789062,
      "logps/rejected": -194.84837341308594,
      "loss": 2.7347,
      "nll_loss": 0.82304847240448,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": 1.852644920349121,
      "rewards/margins": -0.07517973333597183,
      "rewards/rejected": 1.9278247356414795,
      "step": 3440
    },
    {
      "epoch": 2.4487042953496627,
      "grad_norm": 6.2674994468688965,
      "learning_rate": 3.875e-06,
      "logits/chosen": 337.2740783691406,
      "logits/rejected": 338.0506286621094,
      "logps/chosen": -195.2274627685547,
      "logps/rejected": -202.6579132080078,
      "loss": 2.9055,
      "nll_loss": 0.8490751385688782,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.9219474792480469,
      "rewards/margins": 1.2335920333862305,
      "rewards/rejected": 0.6883556246757507,
      "step": 3450
    },
    {
      "epoch": 2.45580404685836,
      "grad_norm": 8.567747116088867,
      "learning_rate": 3.85e-06,
      "logits/chosen": 337.39239501953125,
      "logits/rejected": 338.07659912109375,
      "logps/chosen": -206.0815887451172,
      "logps/rejected": -212.48403930664062,
      "loss": 2.7931,
      "nll_loss": 0.851580023765564,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 1.8571548461914062,
      "rewards/margins": 0.6820299625396729,
      "rewards/rejected": 1.1751246452331543,
      "step": 3460
    },
    {
      "epoch": 2.462903798367057,
      "grad_norm": 7.279573440551758,
      "learning_rate": 3.825000000000001e-06,
      "logits/chosen": 335.141357421875,
      "logits/rejected": 335.905029296875,
      "logps/chosen": -186.62229919433594,
      "logps/rejected": -194.87255859375,
      "loss": 2.9076,
      "nll_loss": 0.8263307809829712,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 2.0446784496307373,
      "rewards/margins": 0.5222226977348328,
      "rewards/rejected": 1.5224558115005493,
      "step": 3470
    },
    {
      "epoch": 2.4700035498757544,
      "grad_norm": 7.925166606903076,
      "learning_rate": 3.8000000000000005e-06,
      "logits/chosen": 334.7508544921875,
      "logits/rejected": 334.96820068359375,
      "logps/chosen": -181.612548828125,
      "logps/rejected": -181.32411193847656,
      "loss": 3.042,
      "nll_loss": 0.793820321559906,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.2924039363861084,
      "rewards/margins": -0.13876360654830933,
      "rewards/rejected": 1.4311673641204834,
      "step": 3480
    },
    {
      "epoch": 2.4771033013844517,
      "grad_norm": 8.231383323669434,
      "learning_rate": 3.7750000000000003e-06,
      "logits/chosen": 334.1952209472656,
      "logits/rejected": 335.44830322265625,
      "logps/chosen": -171.76864624023438,
      "logps/rejected": -175.29129028320312,
      "loss": 2.9381,
      "nll_loss": 0.7591858506202698,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 2.228086471557617,
      "rewards/margins": 0.7805816531181335,
      "rewards/rejected": 1.447504997253418,
      "step": 3490
    },
    {
      "epoch": 2.484203052893149,
      "grad_norm": 9.93690013885498,
      "learning_rate": 3.7500000000000005e-06,
      "logits/chosen": 337.9228515625,
      "logits/rejected": 338.6273193359375,
      "logps/chosen": -186.74905395507812,
      "logps/rejected": -189.84780883789062,
      "loss": 2.6857,
      "nll_loss": 0.845206618309021,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": 2.5348093509674072,
      "rewards/margins": 1.8460661172866821,
      "rewards/rejected": 0.6887430548667908,
      "step": 3500
    },
    {
      "epoch": 2.4913028044018457,
      "grad_norm": 6.031403541564941,
      "learning_rate": 3.7250000000000003e-06,
      "logits/chosen": 335.27081298828125,
      "logits/rejected": 336.4752502441406,
      "logps/chosen": -186.12440490722656,
      "logps/rejected": -195.1853790283203,
      "loss": 2.6507,
      "nll_loss": 0.7836220860481262,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.9637418985366821,
      "rewards/margins": 1.1470215320587158,
      "rewards/rejected": 0.8167203068733215,
      "step": 3510
    },
    {
      "epoch": 2.498402555910543,
      "grad_norm": 8.67619514465332,
      "learning_rate": 3.7e-06,
      "logits/chosen": 336.828125,
      "logits/rejected": 337.6494445800781,
      "logps/chosen": -195.68861389160156,
      "logps/rejected": -205.2792510986328,
      "loss": 2.8221,
      "nll_loss": 0.7714719772338867,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 2.332432746887207,
      "rewards/margins": 1.277332067489624,
      "rewards/rejected": 1.0551007986068726,
      "step": 3520
    },
    {
      "epoch": 2.50550230741924,
      "grad_norm": 7.712894439697266,
      "learning_rate": 3.6750000000000004e-06,
      "logits/chosen": 336.79193115234375,
      "logits/rejected": 339.8727722167969,
      "logps/chosen": -199.9949951171875,
      "logps/rejected": -213.69308471679688,
      "loss": 2.7676,
      "nll_loss": 0.8425596952438354,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 1.8946574926376343,
      "rewards/margins": 1.2001670598983765,
      "rewards/rejected": 0.694490373134613,
      "step": 3530
    },
    {
      "epoch": 2.5126020589279374,
      "grad_norm": 7.949845790863037,
      "learning_rate": 3.65e-06,
      "logits/chosen": 338.8319091796875,
      "logits/rejected": 339.08355712890625,
      "logps/chosen": -210.3432159423828,
      "logps/rejected": -215.5692596435547,
      "loss": 2.805,
      "nll_loss": 0.8422643542289734,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.7257287502288818,
      "rewards/margins": 1.3924566507339478,
      "rewards/rejected": 0.3332720398902893,
      "step": 3540
    },
    {
      "epoch": 2.5197018104366347,
      "grad_norm": 6.939851760864258,
      "learning_rate": 3.625e-06,
      "logits/chosen": 335.59503173828125,
      "logits/rejected": 336.7198486328125,
      "logps/chosen": -184.43893432617188,
      "logps/rejected": -186.90798950195312,
      "loss": 2.7348,
      "nll_loss": 0.756580650806427,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.844297170639038,
      "rewards/margins": 0.503290057182312,
      "rewards/rejected": 1.341007113456726,
      "step": 3550
    },
    {
      "epoch": 2.526801561945332,
      "grad_norm": 7.784295558929443,
      "learning_rate": 3.6000000000000003e-06,
      "logits/chosen": 339.29443359375,
      "logits/rejected": 341.0050354003906,
      "logps/chosen": -199.53004455566406,
      "logps/rejected": -209.54141235351562,
      "loss": 2.8512,
      "nll_loss": 0.8653007745742798,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 2.0411739349365234,
      "rewards/margins": 0.742416501045227,
      "rewards/rejected": 1.2987574338912964,
      "step": 3560
    },
    {
      "epoch": 2.533901313454029,
      "grad_norm": 7.644811630249023,
      "learning_rate": 3.575e-06,
      "logits/chosen": 337.66552734375,
      "logits/rejected": 338.6713562011719,
      "logps/chosen": -184.84779357910156,
      "logps/rejected": -197.5338592529297,
      "loss": 2.7997,
      "nll_loss": 0.8107815980911255,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": 1.989712119102478,
      "rewards/margins": 1.4361613988876343,
      "rewards/rejected": 0.5535504817962646,
      "step": 3570
    },
    {
      "epoch": 2.5410010649627264,
      "grad_norm": 7.24470853805542,
      "learning_rate": 3.5500000000000003e-06,
      "logits/chosen": 338.6063537597656,
      "logits/rejected": 339.4460754394531,
      "logps/chosen": -182.37600708007812,
      "logps/rejected": -182.55288696289062,
      "loss": 2.8189,
      "nll_loss": 0.8479987382888794,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 2.414642333984375,
      "rewards/margins": 1.0495306253433228,
      "rewards/rejected": 1.3651117086410522,
      "step": 3580
    },
    {
      "epoch": 2.5481008164714236,
      "grad_norm": 6.560967922210693,
      "learning_rate": 3.525e-06,
      "logits/chosen": 336.9958801269531,
      "logits/rejected": 337.39501953125,
      "logps/chosen": -177.53408813476562,
      "logps/rejected": -192.97897338867188,
      "loss": 2.705,
      "nll_loss": 0.8182857632637024,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 1.6872930526733398,
      "rewards/margins": 1.236325979232788,
      "rewards/rejected": 0.45096713304519653,
      "step": 3590
    },
    {
      "epoch": 2.555200567980121,
      "grad_norm": 6.82819938659668,
      "learning_rate": 3.5e-06,
      "logits/chosen": 334.6446228027344,
      "logits/rejected": 336.61468505859375,
      "logps/chosen": -184.7330322265625,
      "logps/rejected": -195.78097534179688,
      "loss": 2.8961,
      "nll_loss": 0.7546778917312622,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 2.2561113834381104,
      "rewards/margins": 0.7116490602493286,
      "rewards/rejected": 1.5444623231887817,
      "step": 3600
    },
    {
      "epoch": 2.562300319488818,
      "grad_norm": 7.762811660766602,
      "learning_rate": 3.475e-06,
      "logits/chosen": 337.6026306152344,
      "logits/rejected": 338.7298278808594,
      "logps/chosen": -191.84768676757812,
      "logps/rejected": -202.0653076171875,
      "loss": 2.8001,
      "nll_loss": 0.8400314450263977,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 1.6181567907333374,
      "rewards/margins": 0.7046364545822144,
      "rewards/rejected": 0.9135202169418335,
      "step": 3610
    },
    {
      "epoch": 2.5694000709975153,
      "grad_norm": 8.136929512023926,
      "learning_rate": 3.45e-06,
      "logits/chosen": 338.712646484375,
      "logits/rejected": 339.59942626953125,
      "logps/chosen": -205.5103302001953,
      "logps/rejected": -213.36471557617188,
      "loss": 2.7996,
      "nll_loss": 0.8439109921455383,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.699263334274292,
      "rewards/margins": 1.0686914920806885,
      "rewards/rejected": 0.6305719017982483,
      "step": 3620
    },
    {
      "epoch": 2.576499822506212,
      "grad_norm": 6.472775936126709,
      "learning_rate": 3.4250000000000007e-06,
      "logits/chosen": 337.31915283203125,
      "logits/rejected": 338.8811950683594,
      "logps/chosen": -177.8749542236328,
      "logps/rejected": -197.47311401367188,
      "loss": 2.7663,
      "nll_loss": 0.8045981526374817,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 1.9230005741119385,
      "rewards/margins": 1.4216840267181396,
      "rewards/rejected": 0.5013164281845093,
      "step": 3630
    },
    {
      "epoch": 2.5835995740149094,
      "grad_norm": 8.625374794006348,
      "learning_rate": 3.4000000000000005e-06,
      "logits/chosen": 336.07794189453125,
      "logits/rejected": 337.802490234375,
      "logps/chosen": -181.59237670898438,
      "logps/rejected": -188.82815551757812,
      "loss": 2.9556,
      "nll_loss": 0.8101911544799805,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.9682281017303467,
      "rewards/margins": 0.8800710439682007,
      "rewards/rejected": 1.0881569385528564,
      "step": 3640
    },
    {
      "epoch": 2.5906993255236066,
      "grad_norm": 8.389689445495605,
      "learning_rate": 3.3750000000000003e-06,
      "logits/chosen": 338.2242736816406,
      "logits/rejected": 339.03350830078125,
      "logps/chosen": -192.61825561523438,
      "logps/rejected": -204.6494598388672,
      "loss": 2.8673,
      "nll_loss": 0.8113127946853638,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 2.425166606903076,
      "rewards/margins": 1.116848349571228,
      "rewards/rejected": 1.3083181381225586,
      "step": 3650
    },
    {
      "epoch": 2.597799077032304,
      "grad_norm": 8.258418083190918,
      "learning_rate": 3.3500000000000005e-06,
      "logits/chosen": 339.57415771484375,
      "logits/rejected": 340.81298828125,
      "logps/chosen": -203.12120056152344,
      "logps/rejected": -211.33346557617188,
      "loss": 2.8645,
      "nll_loss": 0.8527166247367859,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 1.3361953496932983,
      "rewards/margins": 0.7820661067962646,
      "rewards/rejected": 0.5541291236877441,
      "step": 3660
    },
    {
      "epoch": 2.604898828541001,
      "grad_norm": 6.973930358886719,
      "learning_rate": 3.3250000000000004e-06,
      "logits/chosen": 338.75146484375,
      "logits/rejected": 340.00933837890625,
      "logps/chosen": -191.24012756347656,
      "logps/rejected": -204.6830291748047,
      "loss": 2.7971,
      "nll_loss": 0.8418781161308289,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 2.449389934539795,
      "rewards/margins": 2.1894383430480957,
      "rewards/rejected": 0.2599516808986664,
      "step": 3670
    },
    {
      "epoch": 2.6119985800496983,
      "grad_norm": 7.537954330444336,
      "learning_rate": 3.3000000000000006e-06,
      "logits/chosen": 336.14434814453125,
      "logits/rejected": 339.22735595703125,
      "logps/chosen": -174.14633178710938,
      "logps/rejected": -190.5977325439453,
      "loss": 2.7134,
      "nll_loss": 0.8018668293952942,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.6480293273925781,
      "rewards/margins": 1.390645980834961,
      "rewards/rejected": 0.25738343596458435,
      "step": 3680
    },
    {
      "epoch": 2.6190983315583956,
      "grad_norm": 8.17784595489502,
      "learning_rate": 3.2750000000000004e-06,
      "logits/chosen": 339.0108337402344,
      "logits/rejected": 339.34332275390625,
      "logps/chosen": -200.48716735839844,
      "logps/rejected": -209.4536590576172,
      "loss": 2.858,
      "nll_loss": 0.8453109860420227,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.8351131677627563,
      "rewards/margins": 0.9764198064804077,
      "rewards/rejected": 0.8586932420730591,
      "step": 3690
    },
    {
      "epoch": 2.626198083067093,
      "grad_norm": 6.825833320617676,
      "learning_rate": 3.2500000000000002e-06,
      "logits/chosen": 337.965087890625,
      "logits/rejected": 339.1142883300781,
      "logps/chosen": -188.9168701171875,
      "logps/rejected": -206.24484252929688,
      "loss": 2.9215,
      "nll_loss": 0.8230928182601929,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 1.3545808792114258,
      "rewards/margins": 1.3514066934585571,
      "rewards/rejected": 0.003174030687659979,
      "step": 3700
    },
    {
      "epoch": 2.6332978345757896,
      "grad_norm": 7.774538040161133,
      "learning_rate": 3.2250000000000005e-06,
      "logits/chosen": 337.4725036621094,
      "logits/rejected": 338.8444519042969,
      "logps/chosen": -200.43214416503906,
      "logps/rejected": -214.09152221679688,
      "loss": 2.7605,
      "nll_loss": 0.878118634223938,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": 1.3371868133544922,
      "rewards/margins": 1.1874432563781738,
      "rewards/rejected": 0.14974382519721985,
      "step": 3710
    },
    {
      "epoch": 2.640397586084487,
      "grad_norm": 7.625513076782227,
      "learning_rate": 3.2000000000000003e-06,
      "logits/chosen": 337.89410400390625,
      "logits/rejected": 338.60540771484375,
      "logps/chosen": -196.24798583984375,
      "logps/rejected": -200.70993041992188,
      "loss": 2.8196,
      "nll_loss": 0.8326380848884583,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 2.1022753715515137,
      "rewards/margins": 0.9866388440132141,
      "rewards/rejected": 1.1156364679336548,
      "step": 3720
    },
    {
      "epoch": 2.647497337593184,
      "grad_norm": 8.351280212402344,
      "learning_rate": 3.175e-06,
      "logits/chosen": 337.92730712890625,
      "logits/rejected": 339.4516296386719,
      "logps/chosen": -188.16598510742188,
      "logps/rejected": -193.04156494140625,
      "loss": 2.9082,
      "nll_loss": 0.9038591384887695,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": 1.823566198348999,
      "rewards/margins": 1.7599875926971436,
      "rewards/rejected": 0.06357848644256592,
      "step": 3730
    },
    {
      "epoch": 2.6545970891018813,
      "grad_norm": 8.125482559204102,
      "learning_rate": 3.1500000000000003e-06,
      "logits/chosen": 340.3720397949219,
      "logits/rejected": 340.94580078125,
      "logps/chosen": -199.54864501953125,
      "logps/rejected": -206.8252410888672,
      "loss": 2.7409,
      "nll_loss": 0.9189850091934204,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.5643181800842285,
      "rewards/margins": 0.9785356521606445,
      "rewards/rejected": 0.5857824683189392,
      "step": 3740
    },
    {
      "epoch": 2.6616968406105785,
      "grad_norm": 7.186384677886963,
      "learning_rate": 3.125e-06,
      "logits/chosen": 336.07861328125,
      "logits/rejected": 339.2460632324219,
      "logps/chosen": -185.9427032470703,
      "logps/rejected": -199.6693115234375,
      "loss": 2.8418,
      "nll_loss": 0.8308781385421753,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 2.060777425765991,
      "rewards/margins": 1.3113337755203247,
      "rewards/rejected": 0.7494438290596008,
      "step": 3750
    },
    {
      "epoch": 2.668796592119276,
      "grad_norm": 8.17175006866455,
      "learning_rate": 3.1000000000000004e-06,
      "logits/chosen": 336.8350524902344,
      "logits/rejected": 338.01837158203125,
      "logps/chosen": -185.27566528320312,
      "logps/rejected": -191.25234985351562,
      "loss": 2.7053,
      "nll_loss": 0.8045522570610046,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": 2.27300763130188,
      "rewards/margins": 0.31824472546577454,
      "rewards/rejected": 1.9547630548477173,
      "step": 3760
    },
    {
      "epoch": 2.675896343627973,
      "grad_norm": 7.013954162597656,
      "learning_rate": 3.075e-06,
      "logits/chosen": 338.2591857910156,
      "logits/rejected": 338.8336181640625,
      "logps/chosen": -194.26083374023438,
      "logps/rejected": -199.4546661376953,
      "loss": 2.8325,
      "nll_loss": 0.787900447845459,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.3399865627288818,
      "rewards/margins": 0.006120729260146618,
      "rewards/rejected": 1.3338656425476074,
      "step": 3770
    },
    {
      "epoch": 2.6829960951366703,
      "grad_norm": 7.637637138366699,
      "learning_rate": 3.05e-06,
      "logits/chosen": 338.33740234375,
      "logits/rejected": 340.1802062988281,
      "logps/chosen": -197.3978729248047,
      "logps/rejected": -204.55267333984375,
      "loss": 2.9674,
      "nll_loss": 0.8421463966369629,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.637716293334961,
      "rewards/margins": 0.47479048371315,
      "rewards/rejected": 1.1629257202148438,
      "step": 3780
    },
    {
      "epoch": 2.6900958466453675,
      "grad_norm": 8.101849555969238,
      "learning_rate": 3.0250000000000003e-06,
      "logits/chosen": 336.7211608886719,
      "logits/rejected": 338.7467041015625,
      "logps/chosen": -190.04122924804688,
      "logps/rejected": -203.94717407226562,
      "loss": 2.9215,
      "nll_loss": 0.7775083780288696,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 2.510099411010742,
      "rewards/margins": 0.6382108926773071,
      "rewards/rejected": 1.8718883991241455,
      "step": 3790
    },
    {
      "epoch": 2.6971955981540647,
      "grad_norm": 7.0385260581970215,
      "learning_rate": 3e-06,
      "logits/chosen": 335.60906982421875,
      "logits/rejected": 336.96075439453125,
      "logps/chosen": -182.01683044433594,
      "logps/rejected": -190.08522033691406,
      "loss": 2.8024,
      "nll_loss": 0.8049634695053101,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 2.3377928733825684,
      "rewards/margins": 1.6494810581207275,
      "rewards/rejected": 0.688311755657196,
      "step": 3800
    },
    {
      "epoch": 2.704295349662762,
      "grad_norm": 8.914989471435547,
      "learning_rate": 2.9750000000000003e-06,
      "logits/chosen": 337.6221008300781,
      "logits/rejected": 337.37725830078125,
      "logps/chosen": -190.32041931152344,
      "logps/rejected": -196.16847229003906,
      "loss": 2.7954,
      "nll_loss": 0.8241161108016968,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 2.10980224609375,
      "rewards/margins": 1.2686487436294556,
      "rewards/rejected": 0.841153621673584,
      "step": 3810
    },
    {
      "epoch": 2.711395101171459,
      "grad_norm": 8.117293357849121,
      "learning_rate": 2.95e-06,
      "logits/chosen": 337.4765625,
      "logits/rejected": 339.4146423339844,
      "logps/chosen": -196.1151885986328,
      "logps/rejected": -209.938232421875,
      "loss": 2.985,
      "nll_loss": 0.845119297504425,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 1.9145450592041016,
      "rewards/margins": 0.7753962278366089,
      "rewards/rejected": 1.1391487121582031,
      "step": 3820
    },
    {
      "epoch": 2.7184948526801564,
      "grad_norm": 6.798254013061523,
      "learning_rate": 2.925e-06,
      "logits/chosen": 337.6473693847656,
      "logits/rejected": 337.3985290527344,
      "logps/chosen": -189.35794067382812,
      "logps/rejected": -188.94088745117188,
      "loss": 2.9025,
      "nll_loss": 0.8431628346443176,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 1.8022873401641846,
      "rewards/margins": 0.5473797917366028,
      "rewards/rejected": 1.2549073696136475,
      "step": 3830
    },
    {
      "epoch": 2.7255946041888532,
      "grad_norm": 7.6945672035217285,
      "learning_rate": 2.9e-06,
      "logits/chosen": 337.8458557128906,
      "logits/rejected": 338.613037109375,
      "logps/chosen": -182.54835510253906,
      "logps/rejected": -186.16390991210938,
      "loss": 2.8589,
      "nll_loss": 0.8392815589904785,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.8886489868164062,
      "rewards/margins": 0.2550428807735443,
      "rewards/rejected": 1.633606195449829,
      "step": 3840
    },
    {
      "epoch": 2.7326943556975505,
      "grad_norm": 10.190051078796387,
      "learning_rate": 2.875e-06,
      "logits/chosen": 336.10235595703125,
      "logits/rejected": 337.36834716796875,
      "logps/chosen": -181.89706420898438,
      "logps/rejected": -191.01536560058594,
      "loss": 2.7199,
      "nll_loss": 0.8112082481384277,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 1.6391410827636719,
      "rewards/margins": 0.9250858426094055,
      "rewards/rejected": 0.7140555381774902,
      "step": 3850
    },
    {
      "epoch": 2.7397941072062477,
      "grad_norm": 7.908398628234863,
      "learning_rate": 2.85e-06,
      "logits/chosen": 336.61737060546875,
      "logits/rejected": 337.25946044921875,
      "logps/chosen": -179.99331665039062,
      "logps/rejected": -189.97634887695312,
      "loss": 2.7063,
      "nll_loss": 0.7896687984466553,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 2.0524520874023438,
      "rewards/margins": 0.6199972033500671,
      "rewards/rejected": 1.4324548244476318,
      "step": 3860
    },
    {
      "epoch": 2.746893858714945,
      "grad_norm": 7.17902135848999,
      "learning_rate": 2.825e-06,
      "logits/chosen": 334.7681884765625,
      "logits/rejected": 337.11199951171875,
      "logps/chosen": -190.58627319335938,
      "logps/rejected": -194.31271362304688,
      "loss": 2.7784,
      "nll_loss": 0.802531361579895,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": 1.8581584692001343,
      "rewards/margins": 1.3992971181869507,
      "rewards/rejected": 0.4588613510131836,
      "step": 3870
    },
    {
      "epoch": 2.753993610223642,
      "grad_norm": 6.940035343170166,
      "learning_rate": 2.8000000000000003e-06,
      "logits/chosen": 335.33551025390625,
      "logits/rejected": 337.6448059082031,
      "logps/chosen": -166.53858947753906,
      "logps/rejected": -182.9202117919922,
      "loss": 2.8127,
      "nll_loss": 0.7336294054985046,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 2.154454469680786,
      "rewards/margins": 0.9852254986763,
      "rewards/rejected": 1.1692287921905518,
      "step": 3880
    },
    {
      "epoch": 2.7610933617323394,
      "grad_norm": 7.307646751403809,
      "learning_rate": 2.7750000000000005e-06,
      "logits/chosen": 337.0765380859375,
      "logits/rejected": 337.8518981933594,
      "logps/chosen": -203.65357971191406,
      "logps/rejected": -214.6864013671875,
      "loss": 2.7052,
      "nll_loss": 0.8479048013687134,
      "rewards/accuracies": 0.6312500238418579,
      "rewards/chosen": 2.687964916229248,
      "rewards/margins": 2.3203251361846924,
      "rewards/rejected": 0.3676401376724243,
      "step": 3890
    },
    {
      "epoch": 2.7681931132410367,
      "grad_norm": 8.811100959777832,
      "learning_rate": 2.7500000000000004e-06,
      "logits/chosen": 334.66802978515625,
      "logits/rejected": 336.51129150390625,
      "logps/chosen": -167.07867431640625,
      "logps/rejected": -181.9775390625,
      "loss": 2.8328,
      "nll_loss": 0.7699877023696899,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": 2.5080559253692627,
      "rewards/margins": 1.8537452220916748,
      "rewards/rejected": 0.6543105244636536,
      "step": 3900
    },
    {
      "epoch": 2.775292864749734,
      "grad_norm": 7.354368209838867,
      "learning_rate": 2.7250000000000006e-06,
      "logits/chosen": 335.4784240722656,
      "logits/rejected": 337.2909240722656,
      "logps/chosen": -183.29763793945312,
      "logps/rejected": -194.3643798828125,
      "loss": 2.7333,
      "nll_loss": 0.7995294332504272,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 2.118654489517212,
      "rewards/margins": 0.9961385726928711,
      "rewards/rejected": 1.1225159168243408,
      "step": 3910
    },
    {
      "epoch": 2.7823926162584307,
      "grad_norm": 7.474041938781738,
      "learning_rate": 2.7000000000000004e-06,
      "logits/chosen": 335.27044677734375,
      "logits/rejected": 337.9136962890625,
      "logps/chosen": -180.42013549804688,
      "logps/rejected": -191.68026733398438,
      "loss": 2.7359,
      "nll_loss": 0.8325625658035278,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 2.073739528656006,
      "rewards/margins": 0.8985139727592468,
      "rewards/rejected": 1.1752254962921143,
      "step": 3920
    },
    {
      "epoch": 2.789492367767128,
      "grad_norm": 7.554767608642578,
      "learning_rate": 2.6750000000000002e-06,
      "logits/chosen": 337.90032958984375,
      "logits/rejected": 339.1719055175781,
      "logps/chosen": -186.003662109375,
      "logps/rejected": -200.0457305908203,
      "loss": 2.7899,
      "nll_loss": 0.8473427891731262,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 2.206897735595703,
      "rewards/margins": 0.9627911448478699,
      "rewards/rejected": 1.244106650352478,
      "step": 3930
    },
    {
      "epoch": 2.796592119275825,
      "grad_norm": 7.576788902282715,
      "learning_rate": 2.6500000000000005e-06,
      "logits/chosen": 337.3039855957031,
      "logits/rejected": 337.2764892578125,
      "logps/chosen": -181.40992736816406,
      "logps/rejected": -189.02789306640625,
      "loss": 2.7228,
      "nll_loss": 0.8129798769950867,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": 2.140134572982788,
      "rewards/margins": 0.7347185015678406,
      "rewards/rejected": 1.4054160118103027,
      "step": 3940
    },
    {
      "epoch": 2.8036918707845224,
      "grad_norm": 8.126275062561035,
      "learning_rate": 2.6250000000000003e-06,
      "logits/chosen": 338.400390625,
      "logits/rejected": 339.9662780761719,
      "logps/chosen": -187.05001831054688,
      "logps/rejected": -198.31784057617188,
      "loss": 2.763,
      "nll_loss": 0.8385840654373169,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.886539101600647,
      "rewards/margins": 0.7386956214904785,
      "rewards/rejected": 1.1478437185287476,
      "step": 3950
    },
    {
      "epoch": 2.8107916222932197,
      "grad_norm": 9.03091049194336,
      "learning_rate": 2.6e-06,
      "logits/chosen": 338.07537841796875,
      "logits/rejected": 339.2159118652344,
      "logps/chosen": -189.9447021484375,
      "logps/rejected": -201.82981872558594,
      "loss": 2.9412,
      "nll_loss": 0.8590766191482544,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 2.5338902473449707,
      "rewards/margins": 1.1512110233306885,
      "rewards/rejected": 1.3826793432235718,
      "step": 3960
    },
    {
      "epoch": 2.817891373801917,
      "grad_norm": 8.010546684265137,
      "learning_rate": 2.5750000000000003e-06,
      "logits/chosen": 337.9234619140625,
      "logits/rejected": 340.4476013183594,
      "logps/chosen": -186.97720336914062,
      "logps/rejected": -203.12635803222656,
      "loss": 2.8917,
      "nll_loss": 0.8893429636955261,
      "rewards/accuracies": 0.643750011920929,
      "rewards/chosen": 2.2513537406921387,
      "rewards/margins": 1.766291856765747,
      "rewards/rejected": 0.4850618839263916,
      "step": 3970
    },
    {
      "epoch": 2.824991125310614,
      "grad_norm": 8.028417587280273,
      "learning_rate": 2.55e-06,
      "logits/chosen": 335.9419250488281,
      "logits/rejected": 338.8778991699219,
      "logps/chosen": -185.86526489257812,
      "logps/rejected": -205.9115447998047,
      "loss": 2.8712,
      "nll_loss": 0.7919226884841919,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": 2.231628179550171,
      "rewards/margins": 0.3957595229148865,
      "rewards/rejected": 1.8358688354492188,
      "step": 3980
    },
    {
      "epoch": 2.8320908768193114,
      "grad_norm": 7.521070957183838,
      "learning_rate": 2.5250000000000004e-06,
      "logits/chosen": 336.3341369628906,
      "logits/rejected": 338.5043029785156,
      "logps/chosen": -189.22000122070312,
      "logps/rejected": -206.09658813476562,
      "loss": 2.8178,
      "nll_loss": 0.8236299753189087,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 2.7337160110473633,
      "rewards/margins": 1.4929640293121338,
      "rewards/rejected": 1.2407519817352295,
      "step": 3990
    },
    {
      "epoch": 2.8391906283280086,
      "grad_norm": 7.069882869720459,
      "learning_rate": 2.5e-06,
      "logits/chosen": 337.4053649902344,
      "logits/rejected": 337.8591613769531,
      "logps/chosen": -187.53591918945312,
      "logps/rejected": -196.6634979248047,
      "loss": 3.0449,
      "nll_loss": 0.8467695116996765,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 1.997327208518982,
      "rewards/margins": 1.1062209606170654,
      "rewards/rejected": 0.8911063075065613,
      "step": 4000
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
